{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matiaszabal/argand/blob/master/demos/Main_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWQkl0Bwxw5l"
      },
      "source": [
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Main_Demo.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jq9jJnImxw5s"
      },
      "source": [
        "# Transformer Lens Main Demo Notebook\n",
        "\n",
        "<b style=\"color: red\">To use this notebook, go to Runtime > Change Runtime Type and select GPU as the hardware accelerator.</b>\n",
        "\n",
        "This is a reference notebook covering the main features of the [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens) library for mechanistic interpretability. See [Callum McDougall's tutorial](https://transformerlens-intro.streamlit.app/TransformerLens_&_induction_circuits) for a more structured and gentler introduction to the library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npyOIsVzxw5t"
      },
      "source": [
        "**Tips for reading this Colab:**\n",
        "* You can run all this code for yourself!\n",
        "* The graphs are interactive!\n",
        "* Use the table of contents pane in the sidebar to navigate\n",
        "* Collapse irrelevant sections with the dropdown arrows\n",
        "* Search the page using the search in the sidebar, not CTRL+F"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHpvOdzKxw5u"
      },
      "source": [
        "# Setup\n",
        "(No need to read)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Btne5MK-xw5w",
        "outputId": "99021993-de60-46f4-ea28-04e9dce9a495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running as a Colab notebook\n",
            "Collecting transformer_lens\n",
            "  Downloading transformer_lens-2.8.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: accelerate>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.34.2)\n",
            "Collecting beartype<0.15.0,>=0.14.1 (from transformer_lens)\n",
            "  Downloading beartype-0.14.1-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting better-abc<0.0.4,>=0.0.3 (from transformer_lens)\n",
            "  Downloading better_abc-0.0.3-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting datasets>=2.7.1 (from transformer_lens)\n",
            "  Downloading datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: einops>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.8.0)\n",
            "Collecting fancy-einsum>=0.0.3 (from transformer_lens)\n",
            "  Downloading fancy_einsum-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting jaxtyping>=0.2.11 (from transformer_lens)\n",
            "  Downloading jaxtyping-0.2.34-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.2.2)\n",
            "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (13.9.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.2.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.66.5)\n",
            "Requirement already satisfied: transformers>=4.37.2 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.44.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (4.12.2)\n",
            "Requirement already satisfied: wandb>=0.13.5 in /usr/local/lib/python3.10/dist-packages (from transformer_lens) (0.18.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (6.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.24.7)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.23.0->transformer_lens) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (16.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (2.32.3)\n",
            "Collecting xxhash (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets>=2.7.1->transformer_lens)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.7.1->transformer_lens) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.7.1->transformer_lens) (3.10.10)\n",
            "Collecting typeguard==2.13.3 (from jaxtyping>=0.2.11->transformer_lens)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->transformer_lens) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=12.6.0->transformer_lens) (2.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->transformer_lens) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10->transformer_lens) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (2024.9.11)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.37.2->transformer_lens) (0.19.1)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (3.20.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (2.17.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.13.5->transformer_lens) (75.1.0)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.7.1->transformer_lens) (4.0.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=12.6.0->transformer_lens) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets>=2.7.1->transformer_lens) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->transformer_lens) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer_lens) (5.0.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets>=2.7.1->transformer_lens) (0.2.0)\n",
            "Downloading transformer_lens-2.8.0-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.9/175.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beartype-0.14.1-py3-none-any.whl (739 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.7/739.7 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading better_abc-0.0.3-py3-none-any.whl (3.5 kB)\n",
            "Downloading datasets-3.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.7/472.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
            "Downloading jaxtyping-0.2.34-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: better-abc, xxhash, typeguard, fancy-einsum, dill, beartype, multiprocess, jaxtyping, datasets, transformer_lens\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.3.0\n",
            "    Uninstalling typeguard-4.3.0:\n",
            "      Successfully uninstalled typeguard-4.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed beartype-0.14.1 better-abc-0.0.3 datasets-3.0.2 dill-0.3.8 fancy-einsum-0.0.3 jaxtyping-0.2.34 multiprocess-0.70.16 transformer_lens-2.8.0 typeguard-2.13.3 xxhash-3.5.0\n",
            "Collecting circuitsvis\n",
            "  Downloading circuitsvis-1.43.2-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: importlib-metadata>=5.1.0 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (8.5.0)\n",
            "Requirement already satisfied: numpy>=1.24 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (1.26.4)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from circuitsvis)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from circuitsvis)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from circuitsvis)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from circuitsvis)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from circuitsvis)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from circuitsvis)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from circuitsvis)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from circuitsvis)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from circuitsvis)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from circuitsvis)\n",
            "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from circuitsvis)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.10/dist-packages (from circuitsvis) (2.5.0+cu121)\n",
            "Collecting triton==2.1.0 (from circuitsvis)\n",
            "  Downloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->circuitsvis) (12.6.77)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.1.0->circuitsvis) (3.16.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5.1.0->circuitsvis) (3.20.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10->circuitsvis) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10->circuitsvis) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10->circuitsvis) (3.0.2)\n",
            "Downloading circuitsvis-1.43.2-py3-none-any.whl (1.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-2.1.0-0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, circuitsvis\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.3.3\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.3.3:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.3.3\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.0.50\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.0.50:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.0.50\n",
            "Successfully installed circuitsvis-1.43.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 triton-2.1.0\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "  \u001b[1m\u001b[33m                            DEPRECATION WARNING                            \u001b[m\n",
            "\n",
            "    \u001b[1m\u001b[4m Node.js 16.x is no longer actively supported!\u001b[m\n",
            "\n",
            "  \u001b[1mYou will not receive security or critical stability updates\u001b[m for this version.\n",
            "\n",
            "  You should migrate to a supported version of Node.js as soon as possible.\n",
            "  Use the installation script that corresponds to the version of Node.js you\n",
            "  wish to install. e.g.\n",
            "  \n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_16.x — Node.js 16 \"Gallium\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_18.x — Node.js 18 \"Hydrogen\" (Maintenance)\u001b[m\n",
            "   * \u001b[31mhttps://deb.nodesource.com/setup_19.x — Node.js 19 \"Nineteen\" \u001b[1m(deprecated)\u001b[m\n",
            "   * \u001b[1m\u001b[32mhttps://deb.nodesource.com/setup_20.x — Node.js 20 LTS \"Iron\" (recommended)\u001b[m\n",
            "   * \u001b[32mhttps://deb.nodesource.com/setup_21.x — Node.js 21 \"Iron\" (current)\u001b[m\n",
            "   \n",
            "\n",
            "\n",
            "  Please see \u001b[1mhttps://github.com/nodejs/Release\u001b[m for details about which\n",
            "  version may be appropriate for you.\n",
            "\n",
            "  The \u001b[32m\u001b[1mNodeSource\u001b[m Node.js distributions repository contains\n",
            "  information both about supported versions of Node.js and supported Linux\n",
            "  distributions. To learn more about usage, see the repository:\n",
            "   \u001b[4m\u001b[1mhttps://github.com/nodesource/distributions\u001b[m\n",
            "\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\u001b[31m================================================================================\u001b[m\n",
            "\n",
            "Continuing in 10 seconds ...\n",
            "\n",
            "\u001b[38;5;79m2024-10-26 12:26:17 - Installing pre-requisites\u001b[0m\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,071 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Ign:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy Release [5,713 B]\n",
            "Get:12 https://r2u.stat.illinois.edu/ubuntu jammy Release.gpg [793 B]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,419 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,451 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [2,654 kB]\n",
            "Get:17 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,600 kB]\n",
            "Fetched 16.6 MB in 4s (3,743 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ca-certificates is already the newest version (20240203~22.04.1).\n",
            "curl is already the newest version (7.81.0-1ubuntu1.18).\n",
            "gnupg is already the newest version (2.2.27-3ubuntu2.1).\n",
            "gnupg set to manually installed.\n",
            "The following NEW packages will be installed:\n",
            "  apt-transport-https\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 1,510 B of archives.\n",
            "After this operation, 170 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 apt-transport-https all 2.4.13 [1,510 B]\n",
            "Fetched 1,510 B in 1s (2,653 B/s)\n",
            "Selecting previously unselected package apt-transport-https.\n",
            "(Reading database ... 123622 files and directories currently installed.)\n",
            "Preparing to unpack .../apt-transport-https_2.4.13_all.deb ...\n",
            "Unpacking apt-transport-https (2.4.13) ...\n",
            "Setting up apt-transport-https (2.4.13) ...\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://deb.nodesource.com/node_16.x nodistro InRelease [12.1 kB]\n",
            "Get:4 https://deb.nodesource.com/node_16.x nodistro/main amd64 Packages [7,253 B]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:6 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Ign:10 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://r2u.stat.illinois.edu/ubuntu jammy Release\n",
            "Hit:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Fetched 147 kB in 1s (98.4 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\u001b[1;32m2024-10-26 12:26:33 - Repository configured successfully. To install Node.js, run: apt-get install nodejs -y\u001b[0m\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  nodejs\n",
            "0 upgraded, 1 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 27.5 MB of archives.\n",
            "After this operation, 128 MB of additional disk space will be used.\n",
            "Get:1 https://deb.nodesource.com/node_16.x nodistro/main amd64 nodejs amd64 16.20.2-1nodesource1 [27.5 MB]\n",
            "Fetched 27.5 MB in 0s (68.4 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package nodejs.\n",
            "(Reading database ... 123626 files and directories currently installed.)\n",
            "Preparing to unpack .../nodejs_16.20.2-1nodesource1_amd64.deb ...\n",
            "Unpacking nodejs (16.20.2-1nodesource1) ...\n",
            "Setting up nodejs (16.20.2-1nodesource1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "DEVELOPMENT_MODE = False\n",
        "# Detect if we're running in Google Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"Running as a Colab notebook\")\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "# Install if in Colab\n",
        "if IN_COLAB:\n",
        "    %pip install transformer_lens\n",
        "    %pip install circuitsvis\n",
        "    # Install a faster Node version\n",
        "    !curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs  # noqa\n",
        "\n",
        "# Hot reload in development mode & not running on the CD\n",
        "if not IN_COLAB:\n",
        "    from IPython import get_ipython\n",
        "    ip = get_ipython()\n",
        "    if not ip.extension_manager.loaded:\n",
        "        ip.extension_manager.load('autoreload')\n",
        "        %autoreload 2\n",
        "\n",
        "IN_GITHUB = os.getenv(\"GITHUB_ACTIONS\") == \"true\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XDGWcLqHxw5z",
        "outputId": "ffe608a8-fe56-403f-c812-366b82d437c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using renderer: colab\n"
          ]
        }
      ],
      "source": [
        "# Plotly needs a different renderer for VSCode/Notebooks vs Colab argh\n",
        "import plotly.io as pio\n",
        "if IN_COLAB or not DEVELOPMENT_MODE:\n",
        "    pio.renderers.default = \"colab\"\n",
        "else:\n",
        "    pio.renderers.default = \"notebook_connected\"\n",
        "print(f\"Using renderer: {pio.renderers.default}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o1tipE5oxw5-",
        "outputId": "2049081b-77d9-4733-ddb8-e8c6d1c9e546",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7c087cdc34f0>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-fb9b3072-9baf\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-fb9b3072-9baf\",\n",
              "      Hello,\n",
              "      {\"name\": \"Neel\"}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "import circuitsvis as cv\n",
        "# Testing that the library works\n",
        "cv.examples.hello(\"Neel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "A5pN69Poxw5_"
      },
      "outputs": [],
      "source": [
        "# Import stuff\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import einops\n",
        "from fancy_einsum import einsum\n",
        "import tqdm.auto as tqdm\n",
        "import plotly.express as px\n",
        "\n",
        "from jaxtyping import Float\n",
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "IObBYOWHxw6A"
      },
      "outputs": [],
      "source": [
        "# import transformer_lens\n",
        "import transformer_lens.utils as utils\n",
        "from transformer_lens.hook_points import (\n",
        "    HookPoint,\n",
        ")  # Hooking utilities\n",
        "from transformer_lens import HookedTransformer, FactoredMatrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqjOv92axw6B"
      },
      "source": [
        "We turn automatic differentiation off, to save GPU memory, as this notebook focuses on model inference not model training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8KXFasoUxw6B",
        "outputId": "6a97663b-c169-4da6-98c9-31191dd70c7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7c07a7b6e2c0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "torch.set_grad_enabled(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OmDXxB8sxw6C"
      },
      "source": [
        "Plotting helper functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6ySxwRy3xw6C"
      },
      "outputs": [],
      "source": [
        "def imshow(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def line(tensor, renderer=None, xaxis=\"\", yaxis=\"\", **kwargs):\n",
        "    px.line(utils.to_numpy(tensor), labels={\"x\":xaxis, \"y\":yaxis}, **kwargs).show(renderer)\n",
        "\n",
        "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
        "    x = utils.to_numpy(x)\n",
        "    y = utils.to_numpy(y)\n",
        "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R08EvzGuxw6C"
      },
      "source": [
        "# Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wH2yPUOIxw6D"
      },
      "source": [
        "This is a demo notebook for [TransformerLens](https://github.com/TransformerLensOrg/TransformerLens), **a library I ([Neel Nanda](https://neelnanda.io)) wrote for doing [mechanistic interpretability](https://distill.pub/2020/circuits/zoom-in/) of GPT-2 Style language models.** The goal of mechanistic interpretability is to take a trained model and reverse engineer the algorithms the model learned during training from its weights. It is a fact about the world today that we have computer programs that can essentially speak English at a human level (GPT-3, PaLM, etc), yet we have no idea how they work nor how to write one ourselves. This offends me greatly, and I would like to solve this! Mechanistic interpretability is a very young and small field, and there are a *lot* of open problems - if you would like to help, please try working on one! **If you want to skill up, check out [my guide to getting started](https://neelnanda.io/getting-started), and if you want to jump into an open problem check out my sequence [200 Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems).**\n",
        "\n",
        "I wrote this library because after I left the Anthropic interpretability team and started doing independent research, I got extremely frustrated by the state of open source tooling. There's a lot of excellent infrastructure like HuggingFace and DeepSpeed to *use* or *train* models, but very little to dig into their internals and reverse engineer how they work. **This library tries to solve that**, and to make it easy to get into the field even if you don't work at an industry org with real infrastructure! The core features were heavily inspired by [Anthropic's excellent Garcon tool](https://transformer-circuits.pub/2021/garcon/index.html). Credit to Nelson Elhage and Chris Olah for building Garcon and showing me the value of good infrastructure for accelerating exploratory research!\n",
        "\n",
        "The core design principle I've followed is to enable exploratory analysis - one of the most fun parts of mechanistic interpretability compared to normal ML is the extremely short feedback loops! The point of this library is to keep the gap between having an experiment idea and seeing the results as small as possible, to make it easy for **research to feel like play** and to enter a flow state. This notebook demonstrates how the library works and how to use it, but if you want to see how well it works for exploratory research, check out [my notebook analysing Indirect Objection Identification](https://neelnanda.io/exploratory-analysis-demo) or [my recording of myself doing research](https://www.youtube.com/watch?v=yo4QvDn-vsU)!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCLOqeBHxw6D"
      },
      "source": [
        "## Loading and Running Models\n",
        "\n",
        "TransformerLens comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. For this demo notebook we'll look at GPT-2 Small, an 80M parameter model, see the Available Models section for info on the rest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0AXAsKW7xw6D"
      },
      "outputs": [],
      "source": [
        "device = utils.get_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cCkAXlOoxw6E",
        "outputId": "b8b9d152-1b72-4756-f541-467be1631fde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487,
          "referenced_widgets": [
            "6976b97b57b4416ab0c9329067b6afe1",
            "6584bf80c7e84a7a9ed846cb8f1a0cb7",
            "7754870511e54c8b9658279c887c491e",
            "1eccf31488ae411f9b04d41211d7470a",
            "8bcb79174ca74a028d8817f5d973471d",
            "9b1e212ab56b4da69d0eecfb0960a744",
            "4f1626d6d6c24ef3b71c17f21f50754a",
            "08bb275b3feb47cfbee470e2cb6bdf27",
            "9accb8b4df984689894bb5f14fba3eec",
            "f9b40c1a69494c8294303e3106307cca",
            "6be4269bc72749eebf73700a031e3967",
            "be8432dd6d73454093c622887643a2b0",
            "2b073f96034048fabfdb5a36b4edf6ad",
            "731ef4285fc440abb434151ede21d1fa",
            "308859b69928415db02b091860b42fb5",
            "70bbad51773b44c1b35ef4c98054e290",
            "bbf4277b9d44402b8f8a20a068f686e6",
            "4a004b3c591e45fc9d220d86376a181b",
            "aea234f4a73b458d8e9dfe4d8b87d48a",
            "c095c849a85844d28fe4b2d0811f23e5",
            "6175776618ae4419bb69d61aef42b717",
            "d9dbc6c8cba549cb88303a463bcd9b88",
            "20f98c63ca6d44989dee31c84a6e8e1d",
            "d9a2bb2eace2478387f823df86511884",
            "d69cf458f9064c0199271aa957f55e78",
            "aa9a23373f0a45febd4212eec3ea3a3e",
            "66dcaea4dcdf4108bb6a77aa1f72e28b",
            "708b232fc6e2486eacb9becc9dbf735a",
            "002fa5aef4e6476897e948acc2d3211b",
            "95b9c5f69c534358b9c456ae0efbec05",
            "a5dcafaaf6114830ade522bcf78bffd5",
            "6fdfd16817ba4964a7f592542c281711",
            "9a68fb9d16cb4b6f8cd9e9cc23f45300",
            "2e702633318344d9a881f3876725e15c",
            "69c1f16350c24877a43909c5f8146c24",
            "f68cc18fadb640c49249cfeff7c542ae",
            "74edbe2b983e448b9f49a78f589ca264",
            "2cce22c56cc0468fa88ced2213a43991",
            "97802f97ee4e40c4932a594625dcd6ea",
            "89bd8138dc204604b6a64afb6253e73e",
            "40caec6ab0dd4bb19cf734e9f332160c",
            "0abe827706924b44a03041a0b0fbf3e1",
            "053ef18e36f04fa09090324482e1b07c",
            "e3c59b8a992942f5adb293af184ec414",
            "d3b03f837ceb4584a67da116b0f01878",
            "af031d2591b6412db3021f13dc9c9ab9",
            "f68009d4ccac4c33b31d380155b62887",
            "8852417c1b2e4b98a0655809ea1e9bb6",
            "cc159dd2ac944a398ebd53cba04052bf",
            "b8cad9989b224ee386b8790a56b3f45d",
            "698bf9671c36498caccbd9149922c9af",
            "d8fcafdd50d94769a0c4321334456a64",
            "d232bfeaec944ce08c4271dacf4e9262",
            "1185f61651ac4545bcb92df59961bc5e",
            "7f8532ef15774fa19ca6a1ce96f94f9c",
            "5066357d505841408fb8f0a9ea703757",
            "5909654f81dc4b3ca797d952a5283080",
            "f61479a84e30431ebaf9e348c132aeaf",
            "478b30389cd746fdb6df48cc06df8667",
            "d56fcb45a6294fafa9f2d87a1b04c872",
            "e8702c826c67456d949666717da4d5ec",
            "032e5471df0f476fade43c7853f30e62",
            "135dfd356acd444b88c66e2f4ac8768a",
            "1641ba5633064faebf0967a89916a9e0",
            "478d2c51935a4efb95681c7359ad9a88",
            "c1f506f6adf74272a852ced0dc372013",
            "2470eb850edd4d1f8daf587fec6cc832",
            "7485e525aabd4ee597067e4bb187600b",
            "a147b2bc69924582ab21a772d142c11e",
            "edbb04213d4048569938e3631b679103",
            "cc32380590aa4c41aeba3db47a5fa11b",
            "d4628f4262e04bccbe8a666044e9cf6b",
            "28a5b81ec1104cddb8c962e6dddc2ac4",
            "340a4c41ce4c4ebc821435ae964d16f9",
            "401c5457171d4de2b6739ad68eaaaeb4",
            "48632d4bf6434681ba493ccec4faad70",
            "5c9253da246f4f229982620d55208094"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning:\n",
            "\n",
            "\n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6976b97b57b4416ab0c9329067b6afe1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be8432dd6d73454093c622887643a2b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "20f98c63ca6d44989dee31c84a6e8e1d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2e702633318344d9a881f3876725e15c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3b03f837ceb4584a67da116b0f01878"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5066357d505841408fb8f0a9ea703757"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2470eb850edd4d1f8daf587fec6cc832"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning:\n",
            "\n",
            "`clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model gpt2-small into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "model = HookedTransformer.from_pretrained(\"gpt2-small\", device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF-ubis7xw6E"
      },
      "source": [
        "To try the model out, let's find the loss on this text! Models can be run on a single string or a tensor of tokens (shape: [batch, position], all integers), and the possible return types are:\n",
        "* \"logits\" (shape [batch, position, d_vocab], floats),\n",
        "* \"loss\" (the cross-entropy loss when predicting the next token),\n",
        "* \"both\" (a tuple of (logits, loss))\n",
        "* None (run the model, but don't calculate the logits - this is faster when we only want to use intermediate activations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "JaQhvAiexw6F",
        "outputId": "69682887-d6c3-4588-918b-7dff1ccf6b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loss: tensor(4.1758, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "model_description_text = \"\"\"## Loading Models\n",
        "\n",
        "HookedTransformer comes loaded with >40 open source GPT-style models. You can load any of them in with `HookedTransformer.from_pretrained(MODEL_NAME)`. See my explainer for documentation of all supported models, and this table for hyper-parameters and the name used to load them. Each model is loaded into the consistent HookedTransformer architecture, designed to be clean, consistent and interpretability-friendly.\n",
        "\n",
        "For this demo notebook we'll look at GPT-2 Small, an 80M parameter model. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
        "loss = model(model_description_text, return_type=\"loss\")\n",
        "print(\"Model loss:\", loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37w4GKJDxw6F"
      },
      "source": [
        "## Caching all Activations\n",
        "\n",
        "The first basic operation when doing mechanistic interpretability is to break open the black box of the model and look at all of the internal activations of a model. This can be done with `logits, cache = model.run_with_cache(tokens)`. Let's try this out on the first line of the abstract of the GPT-2 paper.\n",
        "\n",
        "<details><summary>On `remove_batch_dim`</summary>\n",
        "\n",
        "Every activation inside the model begins with a batch dimension. Here, because we only entered a single batch dimension, that dimension is always length 1 and kinda annoying, so passing in the `remove_batch_dim=True` keyword removes it. `gpt2_cache_no_batch_dim = gpt2_cache.remove_batch_dim()` would have achieved the same effect.\n",
        "</details?>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "DdSChduIxw6G",
        "outputId": "0a9ec0df-31e8-46bf-d303-2f2d06502abb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ],
      "source": [
        "gpt2_text = \"Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspecific datasets.\"\n",
        "gpt2_tokens = model.to_tokens(gpt2_text)\n",
        "print(gpt2_tokens.device)\n",
        "gpt2_logits, gpt2_cache = model.run_with_cache(gpt2_tokens, remove_batch_dim=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qNSYxWcxw6G"
      },
      "source": [
        "Let's visualize the attention pattern of all the heads in layer 0, using [Alan Cooney's CircuitsVis library](https://github.com/alan-cooney/CircuitsVis) (based on [Anthropic's PySvelte library](https://github.com/anthropics/PySvelte)).\n",
        "\n",
        "We look this the attention pattern in `gpt2_cache`, an `ActivationCache` object, by entering in the name of the activation, followed by the layer index (here, the activation is called \"attn\" and the layer index is 0). This has shape [head_index, destination_position, source_position], and we use the `model.to_str_tokens` method to convert the text to a list of tokens as strings, since there is an attention weight between each pair of tokens.\n",
        "\n",
        "This visualization is interactive! Try hovering over a token or head, and click to lock. The grid on the top left and for each head is the attention pattern as a destination position by source position grid. It's lower triangular because GPT-2 has **causal attention**, attention can only look backwards, so information can only move forwards in the network.\n",
        "\n",
        "See the ActivationCache section for more on what `gpt2_cache` can do."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uVYBcF0_xw6H",
        "outputId": "a49725e2-0bd5-45da-9a51-d91affee92fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'transformer_lens.ActivationCache.ActivationCache'>\n",
            "torch.Size([12, 33, 33])\n"
          ]
        }
      ],
      "source": [
        "print(type(gpt2_cache))\n",
        "attention_pattern = gpt2_cache[\"pattern\", 0, \"attn\"]\n",
        "print(attention_pattern.shape)\n",
        "gpt2_str_tokens = model.to_str_tokens(gpt2_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZTJbZcNmxw6H",
        "outputId": "3bf65bd6-581c-4e2d-dea5-c172d78dc22f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer 0 Head Attention Patterns:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0x7c087c98f1f0>"
            ],
            "text/html": [
              "<div id=\"circuits-vis-e449167f-6342\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.2/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-e449167f-6342\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"<|endoftext|>\", \"Natural\", \" language\", \" processing\", \" tasks\", \",\", \" such\", \" as\", \" question\", \" answering\", \",\", \" machine\", \" translation\", \",\", \" reading\", \" comprehension\", \",\", \" and\", \" summar\", \"ization\", \",\", \" are\", \" typically\", \" approached\", \" with\", \" supervised\", \" learning\", \" on\", \" tasks\", \"pe\", \"cific\", \" datasets\", \".\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9639418125152588, 0.03605815768241882, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8389372229576111, 0.11828786134719849, 0.04277484863996506, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4743611216545105, 0.13382023572921753, 0.27371740341186523, 0.11810114979743958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3560643792152405, 0.10184908658266068, 0.23054224252700806, 0.20397403836250305, 0.10757026076316833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6660143733024597, 0.16866372525691986, 0.04535674303770065, 0.03885500878095627, 0.06775479763746262, 0.013355277478694916, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38626962900161743, 0.2851092219352722, 0.07609007507562637, 0.059083789587020874, 0.07223350554704666, 0.039796341210603714, 0.08141742646694183, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3775394856929779, 0.1883881688117981, 0.11723986268043518, 0.08685602992773056, 0.0666918084025383, 0.03500017523765564, 0.09693004935979843, 0.0313543900847435, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4869752824306488, 0.06781316548585892, 0.07952871918678284, 0.0848078578710556, 0.1590261310338974, 0.029577823355793953, 0.025685928761959076, 0.016474612057209015, 0.05011039599776268, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2906550168991089, 0.0401349700987339, 0.14614856243133545, 0.0994059219956398, 0.15389195084571838, 0.039001598954200745, 0.024988990277051926, 0.03184126317501068, 0.10222823172807693, 0.0717034786939621, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.39624106884002686, 0.0969417542219162, 0.027270646765828133, 0.023551346734166145, 0.03723450005054474, 0.006502412725239992, 0.08118753135204315, 0.013088461942970753, 0.06990592181682587, 0.240431010723114, 0.007645339705049992, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.24864791333675385, 0.1380206048488617, 0.09235315024852753, 0.08676131069660187, 0.13819696009159088, 0.05914197489619255, 0.03223859518766403, 0.031582385301589966, 0.030489427968859673, 0.03873484954237938, 0.06671839207410812, 0.0371144637465477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1914844512939453, 0.1617259532213211, 0.07445938885211945, 0.07740951329469681, 0.021961107850074768, 0.03392129763960838, 0.051250215619802475, 0.01951923407614231, 0.031324464827775955, 0.040201541036367416, 0.03874267637729645, 0.21578848361968994, 0.04221168905496597, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3704318404197693, 0.08681412786245346, 0.02458467334508896, 0.02161632478237152, 0.032388728111982346, 0.0054227374494075775, 0.0727522224187851, 0.011272797361016273, 0.06329694390296936, 0.21726815402507782, 0.006367161404341459, 0.029603805392980576, 0.05099845305085182, 0.007182057481259108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.197376549243927, 0.04603995010256767, 0.0439998134970665, 0.1337345838546753, 0.05424821004271507, 0.025475719943642616, 0.02756350487470627, 0.021570924669504166, 0.05171823874115944, 0.0645809918642044, 0.028064632788300514, 0.23551586270332336, 0.019129812717437744, 0.02996351197361946, 0.021017685532569885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08907235413789749, 0.01928834244608879, 0.1665353626012802, 0.07281265407800674, 0.04738640785217285, 0.024487901479005814, 0.028987325727939606, 0.019370373338460922, 0.026673024520277977, 0.0731663629412651, 0.02570459246635437, 0.04242359474301338, 0.058694593608379364, 0.028932709246873856, 0.18119074404239655, 0.0952737107872963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.281672865152359, 0.06441287696361542, 0.018008548766374588, 0.016169609501957893, 0.023183880373835564, 0.003753294702619314, 0.054722439497709274, 0.00790976732969284, 0.04616469517350197, 0.16947276890277863, 0.004361644387245178, 0.021011333912611008, 0.0354907251894474, 0.004932567942887545, 0.0955522358417511, 0.1472633332014084, 0.0059174480848014355, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21305489540100098, 0.059123702347278595, 0.03382088243961334, 0.02747686766088009, 0.028393559157848358, 0.008422904647886753, 0.040085308253765106, 0.011629268527030945, 0.05295189470052719, 0.15404638648033142, 0.009831810370087624, 0.03610190376639366, 0.047372911125421524, 0.011069191619753838, 0.09972472488880157, 0.13971355557441711, 0.013185343705117702, 0.01399493869394064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15871697664260864, 0.04387887939810753, 0.08712150156497955, 0.08998464792966843, 0.030738582834601402, 0.0341489352285862, 0.024917254224419594, 0.03139195218682289, 0.024823857471346855, 0.019790327176451683, 0.03625484183430672, 0.020694414153695107, 0.04284068942070007, 0.03820899873971939, 0.062346599996089935, 0.10919700562953949, 0.041376009583473206, 0.049167610704898834, 0.05440090224146843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10485512763261795, 0.12122289836406708, 0.06487482041120529, 0.0876871645450592, 0.03434053063392639, 0.01748395338654518, 0.03415181487798691, 0.015289152041077614, 0.02331211417913437, 0.0283065102994442, 0.018720479682087898, 0.028111927211284637, 0.04190530255436897, 0.020989568904042244, 0.04678507149219513, 0.08659637719392776, 0.023631839081645012, 0.024273166432976723, 0.16702401638031006, 0.01043822430074215, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22901973128318787, 0.05184384435415268, 0.013585173524916172, 0.012337238527834415, 0.018005413934588432, 0.0027703619562089443, 0.04238126799464226, 0.005856254603713751, 0.036144863814115524, 0.13039223849773407, 0.003153424011543393, 0.01567256823182106, 0.027800407260656357, 0.0035543241538107395, 0.07460813969373703, 0.11298280954360962, 0.004272264428436756, 0.006832204759120941, 0.18569745123386383, 0.018073637038469315, 0.0050163534469902515, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18869926035404205, 0.034387122839689255, 0.022344738245010376, 0.019972728565335274, 0.016354024410247803, 0.006856558378785849, 0.02085905149579048, 0.005695996806025505, 0.03415917605161667, 0.07260987162590027, 0.007857208140194416, 0.018040237948298454, 0.026904450729489326, 0.00902039185166359, 0.06876447796821594, 0.17578737437725067, 0.010720063000917435, 0.009284541010856628, 0.1925639510154724, 0.025180330500006676, 0.012639064341783524, 0.021299371495842934, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1195831298828125, 0.022259406745433807, 0.03294713795185089, 0.02017022855579853, 0.03565330430865288, 0.013459905050694942, 0.017516469582915306, 0.010057876817882061, 0.025856448337435722, 0.059559572488069534, 0.015084503218531609, 0.015008729882538319, 0.053174685686826706, 0.016597606241703033, 0.041555255651474, 0.1312934160232544, 0.019296670332551003, 0.01585504598915577, 0.1792508214712143, 0.01618383079767227, 0.022295527160167694, 0.015463397838175297, 0.10187704861164093, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14615532755851746, 0.02672751247882843, 0.016624556854367256, 0.018987687304615974, 0.06278637051582336, 0.015317166224122047, 0.019792238250374794, 0.014227763749659061, 0.025458162650465965, 0.045303549617528915, 0.016364360228180885, 0.03749304264783859, 0.01328864973038435, 0.017496544867753983, 0.0399458147585392, 0.05881758779287338, 0.01926097460091114, 0.02461603283882141, 0.03821970149874687, 0.021577805280685425, 0.02094990387558937, 0.07973217219114304, 0.05017608404159546, 0.17068099975585938, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11321667581796646, 0.036746375262737274, 0.011786573566496372, 0.01027486938983202, 0.020370664075016975, 0.005243889056146145, 0.01591884344816208, 0.005266785621643066, 0.02489173598587513, 0.06593257933855057, 0.005933661479502916, 0.018209027126431465, 0.02102019637823105, 0.0066674984991550446, 0.034828800708055496, 0.13742125034332275, 0.00792704802006483, 0.008618663996458054, 0.1137719601392746, 0.013557438738644123, 0.009277836419641972, 0.026121364906430244, 0.08499342203140259, 0.19073906540870667, 0.011263743974268436, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1333771049976349, 0.026216598227620125, 0.03827153891324997, 0.07152578234672546, 0.05317767336964607, 0.013925841078162193, 0.007084188517183065, 0.013450146652758121, 0.009841440245509148, 0.011789779178798199, 0.013537580147385597, 0.0381549634039402, 0.04193304851651192, 0.013882286846637726, 0.037071458995342255, 0.13838458061218262, 0.014846335165202618, 0.03156951442360878, 0.05598174408078194, 0.015536683611571789, 0.01595635525882244, 0.04545557126402855, 0.01669965870678425, 0.025325758382678032, 0.036718931049108505, 0.08028540760278702, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.106089748442173, 0.019107718020677567, 0.024468664079904556, 0.027496397495269775, 0.016365811228752136, 0.005011420231312513, 0.01041310466825962, 0.006081143394112587, 0.005301058758050203, 0.011143161915242672, 0.00456538749858737, 0.01896991766989231, 0.004321121610701084, 0.004814981948584318, 0.029409391805529594, 0.028682025149464607, 0.005097249522805214, 0.007234347518533468, 0.0341259203851223, 0.01037058886140585, 0.005643270909786224, 0.007283584680408239, 0.02938956394791603, 0.010038796812295914, 0.009134512394666672, 0.5466631650924683, 0.012777911499142647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1046731024980545, 0.03321941941976547, 0.01534124743193388, 0.009373546577990055, 0.026595454663038254, 0.005787807051092386, 0.01357134897261858, 0.00455488683655858, 0.028058908879756927, 0.026107225567102432, 0.006353436037898064, 0.013315827585756779, 0.026628250256180763, 0.006888875737786293, 0.06204746663570404, 0.05890706181526184, 0.00806804932653904, 0.007557099685072899, 0.0852278470993042, 0.017075752839446068, 0.009256890043616295, 0.019695762544870377, 0.1261781007051468, 0.13061511516571045, 0.011351034976541996, 0.0898437350988388, 0.046381499618291855, 0.007325292564928532, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0856190174818039, 0.02143893390893936, 0.05641256645321846, 0.0570666529238224, 0.01980219967663288, 0.006727498024702072, 0.005809162277728319, 0.004516261164098978, 0.0031647472642362118, 0.017615200951695442, 0.006174598820507526, 0.08767974376678467, 0.012299860827624798, 0.0063504548743367195, 0.017522133886814117, 0.14295214414596558, 0.006585485301911831, 0.007875686511397362, 0.030078932642936707, 0.013907494954764843, 0.007376695517450571, 0.0076847863383591175, 0.022160831838846207, 0.012385021895170212, 0.011890060268342495, 0.08669772744178772, 0.19902540743350983, 0.013594485819339752, 0.029586225748062134, 0.0, 0.0, 0.0, 0.0], [0.14064587652683258, 0.013298701494932175, 0.015702953562140465, 0.01735786721110344, 0.02233150787651539, 0.029672259464859962, 0.04172081872820854, 0.018995430320501328, 0.03827710449695587, 0.048635635524988174, 0.030946897342801094, 0.016023889183998108, 0.020880885422229767, 0.0324382446706295, 0.03055812232196331, 0.022808346897363663, 0.035377588123083115, 0.03145160153508186, 0.03497113287448883, 0.01867910847067833, 0.038219086825847626, 0.022578872740268707, 0.06819561123847961, 0.042140960693359375, 0.028620854020118713, 0.03775002807378769, 0.018578052520751953, 0.03376872465014458, 0.03641696274280548, 0.012956859543919563, 0.0, 0.0, 0.0], [0.07168620824813843, 0.06924445927143097, 0.019306901842355728, 0.014161976985633373, 0.016823193058371544, 0.019380610436201096, 0.019257407635450363, 0.022003665566444397, 0.013706527650356293, 0.03578377515077591, 0.018465181812644005, 0.05207168683409691, 0.020085180178284645, 0.019862134009599686, 0.020662128925323486, 0.04725164547562599, 0.021076710894703865, 0.036787249147892, 0.024324089288711548, 0.0038275509141385555, 0.023920683190226555, 0.008533230051398277, 0.026241615414619446, 0.027380069717764854, 0.0346120186150074, 0.022884158417582512, 0.10047904402017593, 0.06913501024246216, 0.025474555790424347, 0.06495600938796997, 0.03061537630856037, 0.0, 0.0], [0.0691077783703804, 0.0370122492313385, 0.038621146231889725, 0.05933324620127678, 0.015923548489809036, 0.00791856087744236, 0.010371049866080284, 0.006615664344280958, 0.002520076697692275, 0.026019375771284103, 0.007905229926109314, 0.029652005061507225, 0.04000621661543846, 0.008451343514025211, 0.010741148144006729, 0.05027562752366066, 0.009428855963051319, 0.013601029291749, 0.050369225442409515, 0.031767137348651886, 0.010793022811412811, 0.007216807454824448, 0.00647842837497592, 0.01480062399059534, 0.021585963666439056, 0.15769486129283905, 0.0888475850224495, 0.01901693269610405, 0.029729343950748444, 0.033161360770463943, 0.05088368058204651, 0.03415084630250931, 0.0], [0.14375510811805725, 0.01681104302406311, 0.009386666119098663, 0.006830314174294472, 0.011656844057142735, 0.0015672282315790653, 0.019711479544639587, 0.002398042008280754, 0.021235883235931396, 0.046836815774440765, 0.001690514967776835, 0.005827189888805151, 0.011980000883340836, 0.0018251417204737663, 0.0423133485019207, 0.054913751780986786, 0.0021786559373140335, 0.002417010487988591, 0.09604066610336304, 0.00575287826359272, 0.0025577894411981106, 0.007121232803910971, 0.08889927715063095, 0.10852082073688507, 0.005179054569453001, 0.03657733276486397, 0.024719923734664917, 0.003734764875844121, 0.031077083200216293, 0.016887949779629707, 0.09450862556695938, 0.07171520590782166, 0.0033723192755132914]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004246665630489588, 0.9995753169059753, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005621903110295534, 0.016407256945967674, 0.9830306172370911, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011627558851614594, 0.021681953221559525, 0.003762035397812724, 0.9733933210372925, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.7244368286337703e-05, 0.00017202251183334738, 0.0002814393083099276, 0.00274214381352067, 0.9967671632766724, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008268454112112522, 0.0002398560318397358, 7.361917960224673e-05, 6.437734555220231e-05, 0.0001756634155754, 0.9911779761314392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012215046444907784, 0.00540044903755188, 0.0016716319369152188, 0.00040775592788122594, 0.0006163657526485622, 0.0010931179858744144, 0.9895892143249512, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012459800345823169, 0.0009121237671934068, 0.0005976726533845067, 0.00013656896771863103, 0.0003304113633930683, 0.0015722825191915035, 0.0038808276876807213, 0.9913240671157837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00028217487852089107, 0.0040681809186935425, 0.00266051571816206, 0.001309309503994882, 0.008030473254621029, 0.00028790911892428994, 0.00022922920470591635, 0.0003948427038267255, 0.9827372431755066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [3.473936885711737e-05, 0.0003953843843191862, 0.00013272734940983355, 0.0002585231268312782, 0.0010855591390281916, 9.198053157888353e-05, 0.0003267084830440581, 0.0005427459836937487, 0.006105939392000437, 0.9910256266593933, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0033785076811909676, 5.090881313662976e-05, 1.6452062482130714e-05, 1.6926167518249713e-05, 4.181407712167129e-05, 0.49394044280052185, 0.0001298127754125744, 0.0008837333880364895, 3.22120358760003e-05, 2.7252126528765075e-05, 0.5014819502830505, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.416048513026908e-05, 0.0013417217414826155, 0.0012613593135029078, 0.0021450757049024105, 0.004042362794280052, 0.0004830532125197351, 0.00011582656588871032, 0.0001520359655842185, 2.6925310521619394e-05, 0.00012675127072725445, 0.0003128990938421339, 0.9899078607559204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00037822354352101684, 0.0009837576653808355, 0.03934130072593689, 0.002732248278334737, 0.0036680244375020266, 0.00011039190576411784, 0.0001293104432988912, 0.0002174347755499184, 0.00010623304842738435, 0.0007748189964331686, 6.647672125836834e-05, 0.00031486680381931365, 0.9511768817901611, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0021017224062234163, 2.4436934836558066e-05, 7.788786206219811e-06, 8.651628377265297e-06, 2.014003439398948e-05, 0.2997135818004608, 7.525274850195274e-05, 0.000489831087179482, 1.845949918788392e-05, 1.5344572602771223e-05, 0.3283388018608093, 4.175807043793611e-05, 6.469193067459855e-06, 0.3691377341747284, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00014968343020882457, 0.00011296640150249004, 0.00036294953315518796, 0.00018591257685329765, 0.00016460906772408634, 4.1432369471294805e-05, 2.876477265090216e-05, 7.786958303768188e-05, 0.000920100137591362, 0.010340185835957527, 2.7572392355068587e-05, 1.783325569704175e-05, 0.00033054559025913477, 2.4375751308980398e-05, 0.9872152805328369, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010753826063591987, 0.002178190043196082, 0.0020426111295819283, 0.004251929000020027, 0.006989904213696718, 2.5118793928413652e-05, 0.0007779040024615824, 0.0005783546948805451, 0.0029378447216004133, 0.033225372433662415, 1.7199263311340474e-05, 0.0008936485392041504, 0.001523857470601797, 1.4656819985248148e-05, 0.006222638301551342, 0.9382132887840271, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013634881470352411, 1.3226069313532207e-05, 4.013945272163255e-06, 4.80306516692508e-06, 1.0257449503114913e-05, 0.19665956497192383, 4.5272623538039625e-05, 0.0002776258625090122, 1.171444273495581e-05, 9.473308637097944e-06, 0.22919613122940063, 2.6430643629282713e-05, 4.101842932868749e-06, 0.265761137008667, 8.515353329130448e-06, 4.536023880064022e-06, 0.3065996766090393, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008924761787056923, 0.00013490833225660026, 4.779844675795175e-05, 5.803713065688498e-05, 0.00010480182390892878, 0.012799100950360298, 0.0007168257143348455, 0.03257954493165016, 2.644998130563181e-05, 0.00011185094626853243, 0.01188427023589611, 4.0102739149006084e-05, 5.555408642976545e-05, 0.012377867475152016, 0.00010783479228848591, 5.4043754062149674e-05, 0.013122130185365677, 0.9148862957954407, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [5.075319677416701e-06, 4.3961477786069736e-05, 3.39850848831702e-05, 7.940309296827763e-05, 5.477917875396088e-05, 7.921551627987355e-07, 9.313343070971314e-06, 7.727078809693921e-06, 8.597270789323375e-05, 0.00012274044274818152, 5.141489509696839e-07, 1.702795657365641e-06, 3.8341830077115446e-05, 4.450980384262948e-07, 0.00013928250700701028, 0.00032758014276623726, 3.994805410911795e-07, 3.948134690290317e-06, 0.9990440011024475, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [9.346190199721605e-05, 0.0018395757069811225, 0.002523313742130995, 0.018087247386574745, 0.002936379285529256, 0.0002733583969529718, 4.872979479841888e-05, 0.00042127809138037264, 0.0001562437682878226, 0.0009748343145474792, 0.00020533606584649533, 0.0010228840401396155, 0.00195480533875525, 0.0001947038690559566, 0.0011294216383248568, 0.00166561349760741, 0.00018734059995040298, 0.0009503458277322352, 0.0004455179441720247, 0.964889645576477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010859703179448843, 8.512341992172878e-06, 2.53072653322306e-06, 3.0625210456491914e-06, 5.9751241678895894e-06, 0.13292618095874786, 3.3453237847425044e-05, 0.0001889125123852864, 8.477757546643261e-06, 6.540428785228869e-06, 0.16445916891098022, 1.8130021999240853e-05, 3.0627456908405293e-06, 0.1971917301416397, 6.429836503230035e-06, 3.4447398320480715e-06, 0.23317106068134308, 0.002279627602547407, 3.713433443408576e-06, 3.5288030630908906e-05, 0.2685586214065552, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041979606612585485, 0.00011805036047007889, 0.00014240530435927212, 3.7967951357131824e-05, 0.000190431994269602, 0.0017651234520599246, 0.0005709836259484291, 0.0005008860025554895, 8.840770897222683e-05, 0.0001420870394213125, 0.001663984963670373, 3.348117752466351e-05, 2.441400647512637e-05, 0.0017546514282003045, 6.520324677694589e-05, 2.414271693851333e-05, 0.0018299167277291417, 0.0015691055450588465, 3.9748843846609816e-05, 0.00015712430467829108, 0.001855448354035616, 0.9870065450668335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.501792424591258e-05, 0.001437984756194055, 6.345164001686499e-05, 0.00010864849900826812, 0.00015633183647878468, 3.210129079889157e-06, 0.0022032838314771652, 0.00022076598543208092, 5.24030729138758e-05, 4.8815887566888705e-05, 2.264465592816123e-06, 1.532726309960708e-05, 4.157148396188859e-06, 2.022844682869618e-06, 6.296808805927867e-06, 4.848678509006277e-05, 1.992902980418876e-06, 3.2470103178638965e-05, 0.0012695103650912642, 1.96326454897644e-05, 1.8090950106852688e-06, 0.0005810307920910418, 0.9936450719833374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.450171688105911e-05, 0.0006139400647953153, 0.0009361213305965066, 0.0008487811428494751, 0.002850641030818224, 1.0365070920670405e-05, 0.00021614317665807903, 0.00017397581541445106, 0.0020508442539721727, 0.005805313587188721, 8.055246325966436e-06, 8.086615707725286e-05, 0.0007702455040998757, 7.2882048698375e-06, 0.0010576178319752216, 0.0022756007965654135, 6.663274234597338e-06, 0.00011621051089605317, 0.0005972468061372638, 8.736322342883795e-05, 6.3323500398837496e-06, 6.0964699514443055e-05, 6.090595343266614e-05, 0.9812840819358826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005848744767718017, 0.00015909200010355562, 1.0836469300556928e-05, 7.365475175902247e-05, 0.00011349544365657493, 0.0008256662404164672, 0.00031911066616885364, 0.018529994413256645, 1.0226588528894354e-05, 4.958726276527159e-05, 0.000771642429754138, 4.4548189180204645e-05, 9.865023457678035e-06, 0.0008067169692367315, 2.2673904823022895e-05, 1.2464137398637831e-05, 0.0008449098677374423, 0.008790110237896442, 3.579240365070291e-05, 3.662861854536459e-05, 0.0008917527156881988, 0.001079177251085639, 0.00037084624636918306, 0.00010837146692210808, 0.9654977917671204, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.6459913240396418e-05, 0.00017152423970401287, 3.208315320080146e-05, 0.00010234164074063301, 0.002631878713145852, 9.88617648545187e-06, 3.250845838920213e-05, 3.741750697372481e-05, 0.00012631529534701258, 4.991211972082965e-05, 8.302533387904987e-06, 8.443423575954512e-05, 3.1279632821679115e-05, 7.633364475623239e-06, 1.0101344741997309e-05, 5.6673758081160486e-05, 7.442129572154954e-06, 2.7689631679095328e-05, 1.8418324543745257e-05, 2.8794349873351166e-06, 6.840415153419599e-06, 4.279875611246098e-06, 0.00043176536564715207, 0.00017617485718801618, 8.995591633720323e-05, 0.9958258867263794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [2.63680012722034e-05, 0.00018008692131843418, 0.00018082918541040272, 0.0003046466736122966, 0.000393908703699708, 4.674835872719996e-05, 2.7231642889091745e-05, 4.873481884715147e-05, 0.0002913164207711816, 0.0004206156881991774, 3.8046331610530615e-05, 0.00025245067081414163, 5.606727791018784e-05, 3.820365236606449e-05, 0.0015365087892860174, 0.0012537199072539806, 3.5934186598751694e-05, 2.3036598577164114e-05, 0.00018036190886050463, 0.00012266090197954327, 3.517777440720238e-05, 6.92467947374098e-05, 0.00011267283844063058, 0.0008507365128025413, 0.0001436186139471829, 0.00023527958546765149, 0.9930958151817322, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0007048260886222124, 5.675393549608998e-05, 3.35129539053014e-06, 7.472656761819962e-06, 1.7859476429293863e-05, 0.0008156531257554889, 4.952957169734873e-05, 0.0013530976139008999, 3.7417627027025446e-05, 0.00014378019841387868, 0.0007639338728040457, 9.991684237320442e-06, 2.884440846173675e-06, 0.0007552228635177016, 0.0001015961097436957, 3.120549763480085e-06, 0.000806095136795193, 0.0011406766716390848, 1.4343116163217928e-05, 9.910185326589271e-06, 0.0008649189840070903, 8.663273183628917e-05, 3.469543662504293e-05, 0.00010265829769195989, 0.007663473952561617, 4.187890954199247e-05, 3.490865992716863e-06, 0.9844047427177429, 0.0, 0.0, 0.0, 0.0, 0.0], [2.028830931521952e-05, 2.9542690754169598e-05, 5.037496885051951e-05, 0.0009778316598385572, 0.3728255033493042, 6.661310635536211e-06, 1.573362351336982e-05, 3.9812392060412094e-05, 0.00022353223175741732, 0.00012674317986238748, 5.1184383664804045e-06, 0.00024116170243360102, 1.2973822776984889e-05, 4.800690476258751e-06, 2.3321632397710346e-05, 7.723524322500452e-05, 4.593432095134631e-06, 1.9647121007437818e-05, 0.00021129929518792778, 1.1453507795522455e-05, 4.380479822430061e-06, 1.4442666724789888e-05, 3.676741835079156e-05, 0.00011845318658743054, 3.797714816755615e-05, 0.0007802752661518753, 0.00040483620250597596, 1.0429542271594983e-05, 0.6236647963523865, 0.0, 0.0, 0.0, 0.0], [2.0582907382049598e-05, 8.831243758322671e-05, 0.0002045488217845559, 0.00030188958044163883, 8.223887562053278e-05, 1.970439734577667e-05, 0.00014085113070905209, 2.896314617828466e-05, 7.669385013286956e-06, 3.724613634403795e-05, 1.673677070357371e-05, 6.404696614481509e-05, 0.0006910585216246545, 1.6027570381993428e-05, 0.00015603681094944477, 0.00014825914695393294, 1.570006861584261e-05, 9.155381849268451e-05, 8.525091107003391e-05, 4.904512934444938e-06, 1.5784382412675768e-05, 5.293112189974636e-05, 0.0005298354080878198, 0.0005658397567458451, 6.167318497318774e-05, 6.72949172439985e-05, 0.0003077442815992981, 1.0369159099354874e-05, 6.799336551921442e-05, 0.9960988759994507, 0.0, 0.0, 0.0], [1.3371280147111975e-05, 0.0009821506682783365, 0.0004154803173150867, 0.00011442304821684957, 0.00038730716914869845, 5.660844180965796e-06, 0.0012746263528242707, 0.0005708053940907121, 0.0006383609143085778, 0.0005776649340987206, 4.127725333091803e-06, 9.161725756712258e-06, 9.142815542872995e-05, 3.7748570775875123e-06, 1.3575269804277923e-05, 0.0002916174125857651, 3.4474792300898116e-06, 7.899177580839023e-05, 0.003189116483554244, 4.885074758931296e-06, 3.1652775760449003e-06, 1.4087428098719101e-05, 0.00015671398432459682, 0.0003544882347341627, 0.00017265425412915647, 0.0013050604611635208, 0.0002186762576457113, 2.677666998351924e-05, 0.00026460105436854064, 1.3334503819351085e-05, 0.9888005256652832, 0.0, 0.0], [2.7455085728433914e-05, 0.00016438258171547204, 7.996422937139869e-05, 0.0011914964998140931, 0.0007883633370511234, 2.6584166334941983e-06, 3.0057588446652517e-05, 7.457974788849242e-06, 0.00014940994151402265, 2.885715730371885e-05, 1.873829091891821e-06, 0.0003328803286422044, 5.1608600188046694e-05, 1.757746304065222e-06, 0.0001265660102944821, 0.00014267010556068271, 1.6954469401753158e-06, 2.1952593669993803e-05, 0.000230407778872177, 4.429338514455594e-05, 1.6103305142678437e-06, 2.700804907362908e-05, 0.00023884863185230643, 0.00019046032684855163, 9.49614513956476e-06, 0.0004466439422685653, 0.00022095764870755374, 5.3791804930369835e-06, 0.0006956399301998317, 0.00015470779908355325, 0.0002548545890022069, 0.9943285584449768, 0.0], [0.006231049541383982, 9.722825780045241e-05, 6.871602636238094e-06, 2.1151156033738516e-05, 5.828053690493107e-05, 0.0072389086708426476, 2.0987938114558347e-05, 0.00025459096650592983, 6.243877578526735e-05, 2.0924704585922882e-05, 0.007872147485613823, 5.585329927271232e-05, 9.868796041700989e-06, 0.009169407188892365, 7.203016866696998e-05, 7.0687078732589725e-06, 0.010345976799726486, 0.0013096556067466736, 3.803684376180172e-05, 8.022712427191436e-05, 0.012053268030285835, 4.0720067772781476e-05, 3.686071750053088e-06, 3.471352465567179e-05, 0.0005061830161139369, 8.918951061787084e-05, 2.9112090487615205e-05, 0.0012772828340530396, 8.489656465826556e-05, 0.00018447409092914313, 0.0001342574250884354, 6.813074287492782e-05, 0.9425214529037476]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.943029522895813, 0.05697042867541313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9185556173324585, 0.032800041139125824, 0.048644356429576874, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8779289126396179, 0.056434258818626404, 0.04271192476153374, 0.022924983873963356, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.804131805896759, 0.029098203405737877, 0.07556731253862381, 0.056435927748680115, 0.03476677089929581, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49431052803993225, 0.020183544605970383, 0.027966558933258057, 0.018319077789783478, 0.03144204244017601, 0.40777820348739624, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6057478785514832, 0.02924242615699768, 0.09491508454084396, 0.07609346508979797, 0.0661466047167778, 0.08705785870552063, 0.0407966710627079, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4483822286128998, 0.04542430490255356, 0.0740148276090622, 0.06864845007658005, 0.0937662422657013, 0.0877426415681839, 0.06534269452095032, 0.1166786327958107, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.49169260263442993, 0.1378207504749298, 0.03955019265413284, 0.061533186584711075, 0.04539963975548744, 0.040731459856033325, 0.06228704750537872, 0.058618661016225815, 0.06236643344163895, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5404126048088074, 0.044426657259464264, 0.03957851976156235, 0.041888076812028885, 0.07529859244823456, 0.0466950498521328, 0.048475220799446106, 0.055005185306072235, 0.08293059468269348, 0.02528950944542885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28273552656173706, 0.014234177768230438, 0.017647748813033104, 0.011433064937591553, 0.021741703152656555, 0.2666538953781128, 0.01540353987365961, 0.04734928905963898, 0.017767542973160744, 0.013926072046160698, 0.29110750555992126, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34496626257896423, 0.04611676186323166, 0.05771546810865402, 0.11131857335567474, 0.11289367079734802, 0.027930336073040962, 0.0385918915271759, 0.05656527355313301, 0.05864057317376137, 0.06648597866296768, 0.026114359498023987, 0.052660852670669556, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4699217975139618, 0.03201567754149437, 0.10772901028394699, 0.027006756514310837, 0.04465881362557411, 0.022773560136556625, 0.02311706356704235, 0.025491517037153244, 0.04950270429253578, 0.026573944836854935, 0.01970886066555977, 0.06337957829236984, 0.08812078088521957, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20661771297454834, 0.01037929579615593, 0.012261929921805859, 0.008319096639752388, 0.01600707322359085, 0.19527733325958252, 0.011453291401267052, 0.03475671634078026, 0.013073586858808994, 0.010938980616629124, 0.21602486073970795, 0.005866499152034521, 0.023642314597964287, 0.23538129031658173, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3399348556995392, 0.029161641374230385, 0.09540712088346481, 0.033951885998249054, 0.0844045877456665, 0.012559546157717705, 0.02935866452753544, 0.02456415630877018, 0.10622432827949524, 0.04689214751124382, 0.01146959699690342, 0.0063691940158605576, 0.11145273596048355, 0.011318002827465534, 0.0569315142929554, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4040880799293518, 0.02419566921889782, 0.03891005367040634, 0.014727428555488586, 0.024456556886434555, 0.03845001384615898, 0.03923036903142929, 0.03717135637998581, 0.06030002236366272, 0.04198545962572098, 0.037167176604270935, 0.016391228884458542, 0.0392896868288517, 0.03772978484630585, 0.13448573648929596, 0.011421294882893562, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15876437723636627, 0.008203906007111073, 0.009295265190303326, 0.00622171675786376, 0.011793207377195358, 0.15069787204265594, 0.008851954713463783, 0.026313524693250656, 0.010186919942498207, 0.008433728478848934, 0.1676223874092102, 0.004420034121721983, 0.01821179874241352, 0.18350811302661896, 0.02092735469341278, 0.006447791121900082, 0.2001000940799713, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17539212107658386, 0.020569656044244766, 0.018291445448994637, 0.009298025630414486, 0.017377890646457672, 0.042534783482551575, 0.02070159651339054, 0.05044393986463547, 0.025438033044338226, 0.017218228429555893, 0.04311535507440567, 0.013349834829568863, 0.028528602793812752, 0.045972563326358795, 0.03408820554614067, 0.019834207370877266, 0.04992839694023132, 0.36791715025901794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26033347845077515, 0.01714838109910488, 0.03745276853442192, 0.07594799995422363, 0.04674699530005455, 0.018068531528115273, 0.03134646266698837, 0.03741513937711716, 0.07175809890031815, 0.058725375682115555, 0.0170787014067173, 0.04030591621994972, 0.05706356093287468, 0.01711358316242695, 0.10491336137056351, 0.046705346554517746, 0.01723019778728485, 0.024682143703103065, 0.019963981583714485, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30547064542770386, 0.05190497264266014, 0.04346899688243866, 0.021846851333975792, 0.02101719193160534, 0.03390473872423172, 0.04190470278263092, 0.03909287601709366, 0.028871968388557434, 0.023003438487648964, 0.03205801174044609, 0.023334508761763573, 0.0711059644818306, 0.03290089964866638, 0.061641957610845566, 0.03183262050151825, 0.03376762941479683, 0.04571489244699478, 0.035015229135751724, 0.022141894325613976, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1224294900894165, 0.006105297245085239, 0.006670300383120775, 0.00458177737891674, 0.009337784722447395, 0.11381794512271881, 0.006783355958759785, 0.01971990428864956, 0.00758085772395134, 0.006613647565245628, 0.12765926122665405, 0.0035026585683226585, 0.01400233618915081, 0.14000988006591797, 0.015684887766838074, 0.005092611536383629, 0.15336212515830994, 0.03527417778968811, 0.022465627640485764, 0.006954454816877842, 0.17235167324543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20538488030433655, 0.03477851673960686, 0.014682917855679989, 0.031183285638689995, 0.03093125857412815, 0.02195277437567711, 0.03290864825248718, 0.05740532651543617, 0.055875152349472046, 0.04864277318120003, 0.023520756512880325, 0.015108550898730755, 0.027386335656046867, 0.024518460035324097, 0.060604579746723175, 0.034776147454977036, 0.026137806475162506, 0.051684360951185226, 0.06281405687332153, 0.020291464403271675, 0.028601741418242455, 0.09081016480922699, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23978599905967712, 0.031323496252298355, 0.050377532839775085, 0.01586942747235298, 0.039014581590890884, 0.02280554361641407, 0.042853571474552155, 0.028882302343845367, 0.04046262800693512, 0.0341072604060173, 0.022644517943263054, 0.039230696856975555, 0.0723857581615448, 0.02234550379216671, 0.04958105459809303, 0.03193334490060806, 0.023325582966208458, 0.045213595032691956, 0.03055434860289097, 0.022876491770148277, 0.024732304736971855, 0.05549483001232147, 0.014199568890035152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23581695556640625, 0.020558318123221397, 0.04375004768371582, 0.02970486506819725, 0.037038758397102356, 0.014953460544347763, 0.04004308208823204, 0.027184361591935158, 0.0457618273794651, 0.03809260204434395, 0.014181885868310928, 0.03789154067635536, 0.0651824101805687, 0.0141829252243042, 0.05489494279026985, 0.023720964789390564, 0.014592775143682957, 0.025570036843419075, 0.07356179505586624, 0.03918233513832092, 0.014925524592399597, 0.04628865420818329, 0.027801068499684334, 0.01511886715888977, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14254967868328094, 0.012010160833597183, 0.016881301999092102, 0.02074255980551243, 0.032451774924993515, 0.029625995084643364, 0.030295219272375107, 0.056208714842796326, 0.02960873953998089, 0.02948184683918953, 0.032639842480421066, 0.010038231499493122, 0.04078620672225952, 0.034627851098775864, 0.033916372805833817, 0.020155752077698708, 0.03684316202998161, 0.0606469064950943, 0.04744713753461838, 0.03252528980374336, 0.04040035605430603, 0.05947761982679367, 0.03129400312900543, 0.04792550206184387, 0.07141982018947601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2222907692193985, 0.059111371636390686, 0.03702676296234131, 0.04059012606739998, 0.0272544976323843, 0.01917477697134018, 0.03171538934111595, 0.020462151616811752, 0.038113273680210114, 0.019927898421883583, 0.018538910895586014, 0.015436704270541668, 0.04536490514874458, 0.019355764612555504, 0.05035828799009323, 0.03328138589859009, 0.02017974853515625, 0.036794353276491165, 0.0433138906955719, 0.02847641333937645, 0.02131732366979122, 0.04771287366747856, 0.013107037171721458, 0.026336049661040306, 0.03021136112511158, 0.03454800695180893, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28438135981559753, 0.02387010119855404, 0.046418823301792145, 0.010260089300572872, 0.03390985354781151, 0.018301475793123245, 0.0237088892608881, 0.024766823276877403, 0.02576776221394539, 0.02296881377696991, 0.016735460609197617, 0.013406945392489433, 0.045986611396074295, 0.016673235222697258, 0.08106393367052078, 0.05033262073993683, 0.016726162284612656, 0.019904805347323418, 0.03032534569501877, 0.010146318934857845, 0.017318228259682655, 0.019040973857045174, 0.01108111534267664, 0.05204640328884125, 0.033353522419929504, 0.03880883380770683, 0.01269550807774067, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1185436025261879, 0.01335094217211008, 0.013422028161585331, 0.030273206532001495, 0.026162927970290184, 0.020776210352778435, 0.021280206739902496, 0.03798935189843178, 0.035364434123039246, 0.036651816219091415, 0.0220040176063776, 0.01538003422319889, 0.030023114755749702, 0.023299679160118103, 0.030007565394043922, 0.014861379750072956, 0.024521933868527412, 0.03999801352620125, 0.03900155797600746, 0.036007679998874664, 0.02685120515525341, 0.06795869767665863, 0.03893129900097847, 0.05725808069109917, 0.06659836322069168, 0.030756846070289612, 0.023343196138739586, 0.05938267707824707, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2509184777736664, 0.011351886205375195, 0.023033957928419113, 0.018849769607186317, 0.013208834454417229, 0.01643039472401142, 0.03763698786497116, 0.021519407629966736, 0.03823146969079971, 0.031223099678754807, 0.01608108915388584, 0.017179016023874283, 0.0823964774608612, 0.015775414183735847, 0.04969312250614166, 0.03397903963923454, 0.016469132155179977, 0.025656113401055336, 0.053269319236278534, 0.024380967020988464, 0.017032906413078308, 0.031062563881278038, 0.014834264293313026, 0.04310780018568039, 0.027818357571959496, 0.015127940103411674, 0.012749838642776012, 0.0268526803702116, 0.014129594899713993, 0.0, 0.0, 0.0, 0.0], [0.19256950914859772, 0.02283368445932865, 0.014495889656245708, 0.028055019676685333, 0.03290427103638649, 0.01857709139585495, 0.02377672679722309, 0.014988908544182777, 0.027755482122302055, 0.01995215192437172, 0.018426891416311264, 0.026808490976691246, 0.040261946618556976, 0.018957342952489853, 0.019980262964963913, 0.039050325751304626, 0.01949433609843254, 0.03071432374417782, 0.07932325452566147, 0.03619768097996712, 0.02037958987057209, 0.023319298401474953, 0.018723847344517708, 0.056927718222141266, 0.023927533999085426, 0.03924323245882988, 0.021783508360385895, 0.02037421055138111, 0.041788313537836075, 0.008409244939684868, 0.0, 0.0, 0.0], [0.1891939342021942, 0.014352066442370415, 0.02782936580479145, 0.01893605850636959, 0.0545523427426815, 0.024302387610077858, 0.02075256034731865, 0.03050179034471512, 0.01690042018890381, 0.029904039576649666, 0.023111771792173386, 0.021664857864379883, 0.033359821885824203, 0.02305050753057003, 0.027927031740546227, 0.026253478601574898, 0.0242579597979784, 0.024394981563091278, 0.017666665837168694, 0.02208106778562069, 0.025441495701670647, 0.023996729403734207, 0.015941401943564415, 0.021863475441932678, 0.04876274988055229, 0.01023405697196722, 0.025762973353266716, 0.06192328408360481, 0.06737112253904343, 0.01818411983549595, 0.00952550582587719, 0.0, 0.0], [0.2711195647716522, 0.054605741053819656, 0.03970598429441452, 0.03512895852327347, 0.020313765853643417, 0.0081838583573699, 0.022556638345122337, 0.014036435633897781, 0.02619847282767296, 0.032355356961488724, 0.007185027003288269, 0.010813490487635136, 0.05162610113620758, 0.007057544309645891, 0.04232773184776306, 0.018505986779928207, 0.006952994968742132, 0.012550846673548222, 0.037855181843042374, 0.014787380583584309, 0.007130765356123447, 0.018956724554300308, 0.01075897179543972, 0.023540524765849113, 0.016256198287010193, 0.007915408350527287, 0.036523107439279556, 0.014562278985977173, 0.01925145462155342, 0.010911817662417889, 0.0343966968357563, 0.06592901796102524, 0.0], [0.14836537837982178, 0.014506891369819641, 0.007646293379366398, 0.011038761585950851, 0.02630247361958027, 0.013194825500249863, 0.02718489244580269, 0.017392197623848915, 0.01612214371562004, 0.03288080543279648, 0.01405027974396944, 0.007167350966483355, 0.01612005941569805, 0.014647025614976883, 0.018450893461704254, 0.01310212817043066, 0.015283219516277313, 0.014542990364134312, 0.059612173587083817, 0.02238386496901512, 0.016796983778476715, 0.10928262025117874, 0.07263997197151184, 0.08393710106611252, 0.025248991325497627, 0.03774847090244293, 0.01622692495584488, 0.024953879415988922, 0.04216583073139191, 0.00452581187710166, 0.014491363428533077, 0.019145717844367027, 0.022841649129986763]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09646987915039062, 0.9035301804542542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04325238987803459, 0.08177753537893295, 0.8749701380729675, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09995399415493011, 0.025312744081020355, 0.020108040422201157, 0.8546252250671387, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024889377877116203, 0.00320735783316195, 0.001842159079387784, 0.022361507639288902, 0.9476995468139648, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10732381045818329, 0.017841674387454987, 0.019553348422050476, 0.04333319887518883, 0.1021149754524231, 0.7098329663276672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006426358595490456, 0.0004479780327528715, 0.00014756589371245354, 0.0004693667870014906, 0.0014411881566047668, 0.003859696676954627, 0.98720782995224, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010354593396186829, 0.00019901854102499783, 0.00016020439215935767, 6.937277066754177e-05, 0.00038674171082675457, 0.00517159653827548, 0.8964055776596069, 0.09657210856676102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0012883302988484502, 0.00032334504066966474, 0.00026527163572609425, 0.0002549059281591326, 0.0002012980548897758, 0.00010049015691038221, 0.0005700886249542236, 0.0004091299488209188, 0.9965871572494507, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00018741606618277729, 1.619654540263582e-05, 4.2281080823158845e-06, 0.0002875888312701136, 1.1125715900561772e-05, 9.805675290408544e-06, 0.0001556722418172285, 7.632972119608894e-05, 0.0034869108349084854, 0.9957647323608398, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015741514042019844, 0.0006393608637154102, 0.000457152898889035, 0.0009912521345540881, 0.0021140349563211203, 0.0180897768586874, 0.047120351344347, 0.07010912895202637, 0.06152831017971039, 0.27690389752388, 0.5063052773475647, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.000616659817751497, 0.0005207083304412663, 4.61151976196561e-05, 0.001461300067603588, 0.0005623756442219019, 4.44760407845024e-05, 0.0003653968160506338, 0.0002860166132450104, 0.004506129305809736, 0.005816521588712931, 0.0007244543521665037, 0.9850499033927917, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010478552430868149, 3.062814721488394e-05, 0.00017344979278277606, 5.423119000624865e-05, 6.388417386915535e-05, 1.1261127838224638e-05, 1.7169008060591295e-05, 1.3931307876191568e-05, 0.0020760390907526016, 0.00026926834834739566, 0.00015268487913999707, 0.00368442852050066, 0.992405116558075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01074627973139286, 0.00025354354875162244, 0.00015322951367124915, 0.0002928703906945884, 0.0005376800545491278, 0.004423543810844421, 0.009884344413876534, 0.012843048200011253, 0.012738621793687344, 0.05966857820749283, 0.10773001611232758, 0.02474571019411087, 0.0780869871377945, 0.6778956055641174, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00041218000114895403, 2.6218713173875585e-05, 1.7755904991645366e-05, 0.00019181902462150902, 3.2979492061713245e-06, 3.912674856110243e-06, 1.043809788825456e-05, 4.906853973807301e-06, 0.0005868570297025144, 0.003038149792701006, 3.693121107062325e-05, 0.00077243015402928, 0.0096226055175066, 0.00016094396414700896, 0.9851114153862, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00010886572272283956, 3.5845450838678516e-06, 5.191652235225774e-06, 3.0838342354400083e-05, 1.840874392655678e-05, 7.954758416417462e-07, 3.3532105589983985e-06, 6.5743715822463855e-06, 0.0007270936039276421, 0.0018232464790344238, 7.85325846663909e-06, 0.0003062748000957072, 0.006975044962018728, 3.485083652776666e-05, 0.028292691335082054, 0.9616552591323853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006073978263884783, 8.81518644746393e-05, 4.5837728976039216e-05, 8.250468090409413e-05, 0.00012720408267341554, 0.000931250920984894, 0.0016699982807040215, 0.001938195782713592, 0.0021016946993768215, 0.0101316561922431, 0.016047311946749687, 0.0038353847339749336, 0.01224213745445013, 0.10037067532539368, 0.07853126525878906, 0.10997357219457626, 0.655809223651886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002186301862820983, 1.1892930160684045e-05, 1.673597580520436e-05, 2.0815430616494268e-05, 2.1162533812457696e-05, 0.0007714928942732513, 0.0008652113610878587, 0.000556030310690403, 0.00015655900642741472, 0.0019499912159517407, 0.010891204699873924, 0.0003954313579015434, 0.0015144705539569259, 0.06916317343711853, 0.004308106377720833, 0.0040351636707782745, 0.49397045373916626, 0.40916574001312256, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.9798026187345386e-05, 4.972388865098765e-07, 9.165694869750496e-09, 1.3230416584519844e-07, 5.601832953061603e-08, 1.1903900087872898e-08, 6.15311137153185e-07, 4.068558112635401e-08, 4.517454726737924e-06, 1.4017790817888454e-05, 1.6456915830076468e-07, 1.0863833495022845e-06, 7.444054062943906e-06, 1.0056664905278012e-06, 2.759499693638645e-05, 0.00031378009589388967, 6.201137239258969e-06, 8.21336197986966e-06, 0.9995948672294617, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [6.497172307717847e-06, 8.692009600963502e-07, 1.4051375956114498e-06, 3.7704856481468596e-07, 3.329178355215845e-07, 6.104960448283236e-08, 2.5429949701560872e-08, 1.1067756844340693e-07, 3.6708766856463626e-05, 5.704796990357863e-07, 6.172344910737593e-07, 0.0001562793186167255, 0.00014737895980942994, 3.010377895407146e-06, 6.130664405645803e-05, 0.0017769908299669623, 1.8545950297266245e-05, 3.426315379329026e-05, 0.9233513474464417, 0.07440327107906342, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.003649001708254218, 3.749433017219417e-05, 1.7470789316575974e-05, 2.84492016362492e-05, 3.312421540613286e-05, 0.0001956921914825216, 0.0002647591463755816, 0.00024690438294783235, 0.00028033150010742247, 0.0013949173735454679, 0.0017910299357026815, 0.0004246797179803252, 0.0014623699244111776, 0.009717757813632488, 0.008053945377469063, 0.013200579211115837, 0.06315964460372925, 0.07152794301509857, 0.07523113489151001, 0.024205079302191734, 0.725077748298645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0006410913192667067, 3.925716100638965e-06, 1.1607406804614584e-06, 1.5375526345451362e-06, 9.072659281628148e-07, 8.05821309768362e-06, 1.3223983842181042e-05, 4.619937044481048e-06, 3.6788402212550864e-05, 4.5651882828678936e-05, 7.577838550787419e-05, 2.2741820430383086e-05, 5.6684581068111584e-05, 0.0004737513663712889, 0.0003640770446509123, 0.0004240032867528498, 0.0037573371082544327, 0.004363126587122679, 0.007395234890282154, 0.005022631958127022, 0.055756233632564545, 0.9215314984321594, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005377687630243599, 8.12255905202619e-07, 2.301860604347894e-06, 1.4700369774800492e-06, 1.8703681234910619e-06, 6.024516778779798e-07, 4.127833562961314e-06, 1.6705779444237123e-06, 2.0471941297728335e-06, 7.430040568578988e-05, 3.5942293834523298e-06, 7.171522156568244e-06, 3.0528204661095515e-05, 1.892775617307052e-05, 0.000254388025496155, 0.0001949638535734266, 0.00012626551324501634, 0.00018230553541798145, 0.0037352286744862795, 0.0006727128638885915, 0.0015798339154571295, 0.011177700944244862, 0.9813894629478455, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [8.512815838912502e-05, 4.870875613960379e-07, 1.2458991704988875e-06, 2.0811258139019628e-07, 1.9242881421632774e-07, 3.70403121507934e-08, 4.5552476990451396e-07, 5.504545796952698e-08, 1.5320365491788834e-06, 5.083300493424758e-06, 2.140098018799108e-07, 1.4595336779166246e-06, 1.4768359505978879e-05, 1.0635034186634584e-06, 2.9461509257089347e-05, 5.7288274547318e-05, 6.615687198063824e-06, 7.844209903851151e-06, 0.00015063828323036432, 0.00022636979701928794, 7.97358006821014e-05, 0.00013040871999692172, 0.010868420824408531, 0.9883312582969666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0004166323342360556, 2.2503731997858267e-06, 5.270541350910207e-06, 2.7549087462830357e-05, 3.963052586186677e-05, 7.514734079450136e-06, 8.10093024483649e-06, 1.1581339094846044e-05, 1.3205974028096534e-05, 6.750720785930753e-05, 2.5212733817170374e-05, 1.4860710507491603e-05, 7.521700172219425e-05, 0.00011457459913799539, 0.0002574533282313496, 0.0003666859120130539, 0.000690474989823997, 0.001451847143471241, 0.0032460202928632498, 0.0006353401695378125, 0.008745573461055756, 0.015190859325230122, 0.018150201067328453, 0.13303320109844208, 0.8174031376838684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1.673923725320492e-05, 8.245286409191976e-08, 3.257380143395494e-08, 2.8737394686118023e-08, 1.6217649090322084e-07, 1.5275354314780998e-09, 2.3278555971728565e-08, 5.576718198341268e-09, 1.2825766759760882e-07, 1.3429448131319077e-07, 6.160536969446184e-09, 2.523252362607309e-07, 3.205750772394822e-06, 2.6277223952320128e-08, 7.619948405590549e-07, 7.901960088929627e-06, 1.394041220237341e-07, 1.955259563146683e-07, 0.00032022554660215974, 8.173661854016245e-07, 1.5629975678166375e-06, 3.76315961148066e-06, 0.0007450510165654123, 0.0037152196746319532, 3.934420601581223e-05, 0.995144248008728, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00023842266818974167, 5.040105861553457e-06, 1.3208579048296087e-06, 8.599819921073504e-06, 5.166068604012253e-06, 1.3470912563207094e-07, 6.710810112053878e-07, 2.69969319788288e-07, 6.345725523715373e-06, 4.417822856339626e-05, 2.7444932015896484e-07, 2.0171175492578186e-05, 1.6526626495760866e-05, 8.12277562545205e-07, 0.0001077098204405047, 0.00012397429964039475, 3.507592055029818e-06, 8.50583273859229e-06, 6.98026196914725e-05, 0.00026813612203113735, 2.879278690670617e-05, 0.00011957895185332745, 0.0001296166592510417, 0.007425930816680193, 0.0007109703146852553, 0.005815010517835617, 0.9848405718803406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00040899546002037823, 6.095377216297493e-07, 1.9963931663369294e-06, 9.310348104918376e-06, 3.769060640479438e-06, 1.987661789826234e-06, 4.576555738822208e-07, 1.0690733915907913e-06, 3.087182903982466e-06, 9.211432370648254e-06, 4.724378413811792e-06, 1.2070066759406473e-06, 5.095625510875834e-06, 1.804713610908948e-05, 4.857869862462394e-05, 4.1693871025927365e-05, 0.00010537524212850258, 0.000224668241571635, 0.00011528635513968766, 0.00024928964558057487, 0.0013673142530024052, 0.0016190336318686604, 0.0013275156961753964, 0.0034917823504656553, 0.06305663287639618, 0.006469069980084896, 0.09512649476528168, 0.8262877464294434, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00031804663012735546, 1.4181800906953868e-06, 3.18549126632206e-07, 2.782305045911926e-06, 5.388588033383712e-05, 4.300602185480784e-08, 5.386265229390119e-07, 8.497839587562339e-08, 5.999703489578678e-07, 4.110322151973378e-06, 7.099398402488077e-08, 8.454306907879072e-07, 2.52661243393959e-06, 2.1983862552588107e-07, 6.098245648900047e-06, 2.1130004824954085e-05, 9.411792802893615e-07, 9.950375670086942e-07, 3.0413542845053598e-05, 2.976988980663009e-06, 8.453859663859475e-06, 2.6007011911133304e-05, 0.00023055807105265558, 0.0013383382465690374, 0.0002175825648009777, 0.007014391012489796, 0.017924033105373383, 0.0005302673089317977, 0.9722621440887451, 0.0, 0.0, 0.0, 0.0], [1.8505333798657375e-07, 5.565691907349901e-09, 7.262697110377303e-10, 7.745998509278706e-09, 1.507950919688028e-08, 8.228537295984495e-10, 1.7915348093922034e-09, 1.7345679337310571e-09, 1.0962556196147943e-08, 5.003294134553471e-08, 3.9228313930550485e-09, 1.0013925333396401e-07, 2.3337790366895206e-08, 1.6555286919128775e-08, 5.171330030862009e-08, 1.6146056225352368e-07, 9.827939351225723e-08, 2.7074545982941345e-07, 5.411987785919337e-06, 2.508390934963245e-07, 1.180596768790565e-06, 2.800431047944585e-06, 4.61038098364952e-06, 0.00022679209359921515, 5.794253229396418e-05, 0.0004519550420809537, 0.00011976501991739497, 0.00023980966943781823, 0.0018740074010565877, 0.9970145225524902, 0.0, 0.0, 0.0], [4.347453432274051e-05, 2.9688635549973696e-06, 3.919361404314259e-07, 9.117047738982365e-07, 4.364481469565362e-07, 4.686582233404124e-09, 9.240343246119664e-08, 1.2419325123858016e-08, 7.188964445958845e-08, 6.30454337624542e-07, 6.108888506162202e-09, 1.9987159305401292e-07, 1.4578646414520335e-06, 1.4727286945515061e-08, 1.7957326292616926e-07, 2.6422712835483253e-05, 5.112656964456619e-08, 4.710665280072135e-08, 0.001576115726493299, 2.1989392280374886e-06, 3.333979350372829e-07, 2.181479203500203e-06, 0.00016240376862697303, 0.0017777645261958241, 1.1749207260436378e-05, 0.0036160817835479975, 6.199465860845521e-05, 3.516816286719404e-05, 0.0011488657910376787, 0.016085559502243996, 0.9754422307014465, 0.0, 0.0], [0.00115629390347749, 6.1990413087187335e-06, 6.137800596661691e-07, 3.102660230069887e-06, 8.2284321933912e-07, 4.3660275395041026e-08, 9.363272823748048e-08, 2.7735543639550997e-08, 5.10952929744235e-07, 1.2355308172118384e-06, 3.825311623018024e-08, 1.1272317124166875e-06, 1.9008953131560702e-06, 8.71407408453706e-08, 5.398182565841125e-06, 7.393457963189576e-06, 3.128878631741827e-07, 3.0146313179102435e-07, 0.00013595363998319954, 1.3343834325496573e-05, 2.3996453819563612e-06, 3.871276931022294e-05, 0.0008219628361985087, 0.0006131281261332333, 2.1518460926017724e-05, 0.004140728618949652, 0.0008760862983763218, 0.00011684603668982163, 0.002159067429602146, 0.027525248005986214, 0.044349703937768936, 0.9179997444152832, 0.0], [0.003194292774423957, 4.681673090090044e-05, 3.4991320717381313e-05, 2.704309008549899e-05, 1.4000327610119712e-05, 1.70851362781832e-05, 8.051894837990403e-06, 3.909832230419852e-06, 1.0716952601796947e-05, 1.7930766261997633e-05, 1.4207501408236567e-05, 2.6911291570286267e-05, 2.641200444486458e-05, 3.110023681074381e-05, 1.1198572792636696e-05, 5.485507062985562e-05, 0.00011474492930574343, 0.00010493677837075666, 0.0002806306292768568, 0.00020839071657974273, 0.0009329256718046963, 0.0018990020034834743, 0.001126758987084031, 0.00192572723608464, 0.003917159046977758, 0.0074994550086557865, 0.010695934295654297, 0.02319987118244171, 0.030398163944482803, 0.12729352712631226, 0.04325325787067413, 0.17668049037456512, 0.5669295191764832]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2530864179134369, 0.7469136118888855, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.30671584606170654, 0.32906389236450195, 0.3642202615737915, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07416977733373642, 0.1618967354297638, 0.054325904697179794, 0.7096076011657715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1668822169303894, 0.03901783376932144, 0.03822458162903786, 0.21398350596427917, 0.541891872882843, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19483646750450134, 0.21119247376918793, 0.051505617797374725, 0.08703829348087311, 0.22999553382396698, 0.22543160617351532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13900136947631836, 0.02974863164126873, 0.03860693424940109, 0.051332730799913406, 0.1928424835205078, 0.08012371510267258, 0.468344122171402, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08969780802726746, 0.04080599173903465, 0.03473306819796562, 0.08414527028799057, 0.09911051392555237, 0.07059448212385178, 0.1361657679080963, 0.44474709033966064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05986517667770386, 0.020190440118312836, 0.01878531090915203, 0.10584728419780731, 0.057948801666498184, 0.02751770429313183, 0.05666313320398331, 0.08226759731769562, 0.5709145665168762, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.010379280894994736, 0.004698258358985186, 0.004143988247960806, 0.007291416637599468, 0.006256698630750179, 0.003318049944937229, 0.00917502585798502, 0.018754426389932632, 0.03393151983618736, 0.9020513892173767, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07270114123821259, 0.0477648489177227, 0.01050033699721098, 0.016159415245056152, 0.046178217977285385, 0.0524945892393589, 0.05184570327401161, 0.2118951976299286, 0.035158198326826096, 0.17267180979251862, 0.28263059258461, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01512689609080553, 0.004731191787868738, 0.0023226316552609205, 0.006575742270797491, 0.018362468108534813, 0.0033396664075553417, 0.00878423172980547, 0.007409749086946249, 0.006289810407906771, 0.07638946920633316, 0.012003494426608086, 0.8386646509170532, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0323319286108017, 0.010628961026668549, 0.002615162869915366, 0.0011762926587834954, 0.003093285020440817, 0.0015055524418130517, 0.007079715374857187, 0.002834467915818095, 0.005003879778087139, 0.012032576836645603, 0.0039877742528915405, 0.0518723726272583, 0.8658380508422852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05045590549707413, 0.02653883770108223, 0.005783272907137871, 0.008087298832833767, 0.02179938368499279, 0.025670338422060013, 0.02277901954948902, 0.09139907360076904, 0.015017365105450153, 0.07093922793865204, 0.12448636442422867, 0.126683309674263, 0.061021339148283005, 0.34933924674987793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05474130064249039, 0.05296850949525833, 0.00398813234642148, 0.012351631186902523, 0.004415622912347317, 0.003596280235797167, 0.011385717429220676, 0.009828073903918266, 0.014749746769666672, 0.07078829407691956, 0.011209191754460335, 0.051640577614307404, 0.19734399020671844, 0.027129286900162697, 0.4738636314868927, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007163068279623985, 0.004963846877217293, 0.002769225277006626, 0.0019424435449764132, 0.01054474525153637, 0.001414487836882472, 0.0036636630538851023, 0.0031499487813562155, 0.005481294356286526, 0.021614037454128265, 0.003922199830412865, 0.07935076951980591, 0.2247791439294815, 0.009166956879198551, 0.02740265056490898, 0.5926715135574341, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.034611064940690994, 0.015296337194740772, 0.003095125313848257, 0.0038990930188447237, 0.009989402256906033, 0.011446862481534481, 0.009189355187118053, 0.033565156161785126, 0.005761208478361368, 0.025581005960702896, 0.04384687915444374, 0.04521359130740166, 0.020553382113575935, 0.11962336301803589, 0.1567324697971344, 0.1317344605922699, 0.32986125349998474, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01725388504564762, 0.0043975296430289745, 0.004968694411218166, 0.007064319681376219, 0.006634896155446768, 0.0069109550677239895, 0.01138690672814846, 0.016178511083126068, 0.020317766815423965, 0.020396819338202477, 0.023422112688422203, 0.018909139558672905, 0.04024204984307289, 0.06200677528977394, 0.11645364761352539, 0.07975106686353683, 0.16864478588104248, 0.37506014108657837, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002459116280078888, 0.0002491974155418575, 3.400466084713116e-05, 0.0002113294176524505, 0.00020066798606421798, 0.00012589257676154375, 0.00036506837932392955, 0.0003735979844350368, 0.00013798550935462117, 0.0004702211881522089, 0.0002715182490646839, 0.003417078172788024, 0.0006049809162504971, 0.0005454609054140747, 0.0008937670500017703, 0.0015852133510634303, 0.0012150751426815987, 0.002821265487000346, 0.9840186238288879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00015282476670108736, 0.03892366588115692, 0.0004715205868706107, 0.00037318209069781005, 3.2717995054554194e-05, 1.0635622857080307e-05, 3.8245761970756575e-06, 1.3244718502392061e-05, 6.418923294404522e-05, 2.734439476625994e-05, 2.8319980629021302e-05, 0.0022295699454844, 0.0013866395456716418, 7.1635382482782e-05, 0.00014025592827238142, 0.008246451616287231, 0.00019678672833833843, 0.0002054670621873811, 0.8976380228996277, 0.04978379234671593, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02645810693502426, 0.010410883463919163, 0.0021332562901079655, 0.002456017304211855, 0.005542599130421877, 0.0059545692056417465, 0.004195829853415489, 0.013451543636620045, 0.002351952251046896, 0.009471958503127098, 0.01543342974036932, 0.014804965816438198, 0.006865759380161762, 0.037873174995183945, 0.047449320554733276, 0.045472823083400726, 0.1019916981458664, 0.08666389435529709, 0.06470182538032532, 0.10160761326551437, 0.3947087228298187, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02115791290998459, 0.003548436099663377, 0.001744113047607243, 0.0035093105398118496, 0.004201899748295546, 0.0025777805130928755, 0.004015855956822634, 0.004599003586918116, 0.0039551593363285065, 0.006455844733864069, 0.005907895974814892, 0.0037331627681851387, 0.009013410657644272, 0.013927989639341831, 0.02989579178392887, 0.020082326605916023, 0.03804443031549454, 0.0688309296965599, 0.08152897655963898, 0.038340263068675995, 0.1516026258468628, 0.48332679271698, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0014211682137101889, 0.0004069012065883726, 0.000271441851509735, 0.0014869248261675239, 0.0006475152331404388, 0.0002567152550909668, 0.0002729761181399226, 0.0005059848772361875, 0.00017537492385599762, 0.0012059597065672278, 0.0005902894190512598, 0.0004307387862354517, 0.00036999606527388096, 0.0013322844170033932, 0.0007594263297505677, 0.002518306253477931, 0.0035999787505716085, 0.004756712354719639, 0.011892926879227161, 0.003410215023905039, 0.013851101510226727, 0.059073228389024734, 0.8907637596130371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0050588687881827354, 0.0008823552052490413, 0.0015358285745605826, 0.0016909879632294178, 0.0013438755413517356, 0.0004949712310917675, 0.000657226366456598, 0.0005521598504856229, 0.0005812106537632644, 0.0020545623265206814, 0.0008380879298783839, 0.0010067485272884369, 0.0011300863698124886, 0.0016139950603246689, 0.005022874101996422, 0.014576884917914867, 0.0037143349181860685, 0.0046814787201583385, 0.007913828827440739, 0.006778393872082233, 0.012291375547647476, 0.027733033522963524, 0.10214655846357346, 0.7957003712654114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.004004698246717453, 0.00045769751886837184, 0.00156452099326998, 0.003137206891551614, 0.001993746729567647, 0.00037892634281888604, 0.0004957785131409764, 0.0005698017776012421, 0.0010052066063508391, 0.002343225758522749, 0.0005772153963334858, 0.0016756143886595964, 0.0030787375289946795, 0.0012285261182114482, 0.005278327502310276, 0.006328055635094643, 0.0031517327297478914, 0.005319308023899794, 0.02138313092291355, 0.0061477115377783775, 0.012332224287092686, 0.07402163743972778, 0.12114021182060242, 0.5611115097999573, 0.16127519309520721, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0011286529479548335, 4.9889058573171496e-05, 4.129110311623663e-05, 9.249602589989081e-05, 5.513616997632198e-05, 3.8617217796854675e-05, 5.592021989286877e-05, 0.00014896252832841128, 5.5092091315600555e-06, 6.817420216975734e-05, 3.6204415664542466e-05, 4.6239569201134145e-05, 0.0010655007790774107, 5.919874456594698e-05, 7.787238428136334e-05, 0.0003842118021566421, 0.0001169242532341741, 0.00022428217926062644, 0.0005083983996883035, 0.0001562812103657052, 0.0003233142488170415, 0.0007086815894581378, 0.0009207411203533411, 0.0008559702546335757, 0.0044144499115645885, 0.9884169697761536, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0024299679789692163, 0.003659631358459592, 0.0006344971479848027, 0.0006202650256454945, 0.002987674903124571, 0.0003476362908259034, 0.000505915901158005, 0.00041149737080559134, 0.00021321559324860573, 0.0006509347003884614, 0.0003955697757191956, 0.16986443102359772, 0.002188898390159011, 0.0006812378414906561, 0.0008683752967044711, 0.00890512578189373, 0.0014638518914580345, 0.0013394575798884034, 0.006495125591754913, 0.007638712413609028, 0.004619396757334471, 0.0031617905478924513, 0.014200891368091106, 0.04639657586812973, 0.02278606966137886, 0.21939243376255035, 0.47714075446128845, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015610335394740105, 0.0009648071718402207, 0.0010281833820044994, 0.00714851962402463, 0.005316655617207289, 0.000543268455658108, 0.0007839889149181545, 0.0004708300402853638, 0.002298037987202406, 0.00546309957280755, 0.000548307434655726, 0.0008661500178277493, 0.0009035557741299272, 0.0009251973824575543, 0.008375929668545723, 0.0014478126540780067, 0.002061491599306464, 0.003693383652716875, 0.017008865252137184, 0.006138680037111044, 0.007041896227747202, 0.041287053376436234, 0.06922489404678345, 0.2661719024181366, 0.05024212226271629, 0.11445137858390808, 0.13764898478984833, 0.2323346883058548, 0.0, 0.0, 0.0, 0.0, 0.0], [0.02189529314637184, 0.0013514539459720254, 0.001372795202769339, 0.0051577165722846985, 0.01093279104679823, 0.00044522169628180563, 0.0016178288497030735, 0.0005713263526558876, 0.0007700271671637893, 0.003093535313382745, 0.0003616343601606786, 0.0009329012827947736, 0.001903239986859262, 0.0005254388088360429, 0.0007036181050352752, 0.0015780641697347164, 0.0010200472315773368, 0.000934672134462744, 0.005167576018720865, 0.0007855411968193948, 0.0028796817641705275, 0.006337143946439028, 0.049514152109622955, 0.021886879578232765, 0.030046850442886353, 0.06941598653793335, 0.029953880235552788, 0.06111622974276543, 0.6677284836769104, 0.0, 0.0, 0.0, 0.0], [0.00029466566047631204, 8.08511977083981e-05, 0.0001199263206217438, 0.0001715399557724595, 0.00038990037865005434, 8.630252705188468e-05, 5.253727431409061e-05, 6.61636222503148e-05, 0.0001137837243732065, 6.200081406859681e-05, 0.00011238016304560006, 0.0005867312429472804, 9.784991561900824e-05, 0.00021334877237677574, 0.00040444263140670955, 0.00047262359294109046, 0.00047307315981015563, 0.0005199514562264085, 0.0008571151993237436, 0.00022720151173416525, 0.0015976768918335438, 0.0014780628262087703, 0.001650140155106783, 0.009339649230241776, 0.012792689725756645, 0.012606950476765633, 0.02165956050157547, 0.028867457062005997, 0.07784774154424667, 0.8267576694488525, 0.0, 0.0, 0.0], [0.0006396540557034314, 0.0001992022298509255, 0.00033784573315642774, 0.0003228616842534393, 0.00038839777698740363, 2.2511419956572354e-05, 0.00011559657286852598, 1.96836881514173e-05, 8.749761036597192e-05, 0.000166757294209674, 2.135317845386453e-05, 0.00018257681222166866, 0.0028796226251870394, 3.2708412618376315e-05, 6.355984078254551e-05, 0.0009078498114831746, 6.31420043646358e-05, 4.9545087676960975e-05, 0.005010191351175308, 0.00021555769490078092, 0.00018923325114883482, 0.00023579856497235596, 0.002119169570505619, 0.0034752406645566225, 0.0004957507480867207, 0.012673035264015198, 0.00262746075168252, 0.0011926391161978245, 0.028011504560709, 0.1421457678079605, 0.7951083183288574, 0.0, 0.0], [0.005492151249200106, 0.0014179629506543279, 6.310049502644688e-05, 0.0009282379760406911, 0.00046758734970353544, 9.701219823909923e-05, 5.678706293110736e-05, 6.824066076660529e-05, 4.054810051457025e-05, 0.00021011504577472806, 6.53469905955717e-05, 0.00011957788956351578, 9.082329779630527e-05, 9.077359572984278e-05, 0.00013827519433107227, 0.00041228393092751503, 0.00016900584159884602, 0.00013570731971412897, 0.00242832419462502, 0.00020654822583310306, 0.0004959601792506874, 0.0001656197418924421, 0.0018254023743793368, 0.0016808179207146168, 0.0010187356965616345, 0.015071489848196507, 0.0034083742648363113, 0.003384194104000926, 0.018865512683987617, 0.010037439875304699, 0.008259566500782967, 0.9230883717536926, 0.0], [0.009386111982166767, 0.0017380561912432313, 0.0018091686069965363, 0.001435025711543858, 0.0016812827670946717, 0.0019791307859122753, 0.0014143434818834066, 0.0021127827931195498, 0.0012016954133287072, 0.001046765479259193, 0.0012532485416159034, 0.0012125703506171703, 0.0006952427211217582, 0.0016850187676027417, 0.0012904981849715114, 0.0014949431642889977, 0.0030524656176567078, 0.00617640558630228, 0.003993154503405094, 0.002994521986693144, 0.008827604353427887, 0.009542395360767841, 0.010477363131940365, 0.02145143784582615, 0.06221356987953186, 0.026861058548092842, 0.03390643000602722, 0.11987607926130295, 0.05027471110224724, 0.026796855032444, 0.031165704131126404, 0.10728631913661957, 0.44366803765296936]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10520478338003159, 0.8947951793670654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03907207399606705, 0.0020172225777059793, 0.9589106440544128, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015578624792397022, 0.0008392537129111588, 0.0006979762110859156, 0.9828841090202332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008856471627950668, 9.934287845680956e-06, 1.1174832252436318e-05, 0.00030247028917074203, 0.9908198714256287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.35445019602775574, 0.030589278787374496, 0.05988955497741699, 0.022903528064489365, 0.04747588187456131, 0.4846915602684021, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04476897418498993, 0.001566466293297708, 0.00037738465471193194, 0.0002507324970792979, 0.00040889711817726493, 0.0002606558846309781, 0.9523669481277466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09058347344398499, 0.0011470754398033023, 0.006027347408235073, 0.000546847702935338, 0.0017094232607632875, 0.0037850853987038136, 0.0026845417451113462, 0.8935161828994751, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006010726094245911, 2.4289094653795473e-05, 0.00031266745645552874, 1.868293657025788e-05, 0.0002979248820338398, 9.904534636007156e-06, 6.619561190746026e-06, 7.912199180282187e-07, 0.9933184385299683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.00454681646078825, 0.00020019360817968845, 0.0002992021618410945, 0.001336393877863884, 0.00032676520640961826, 8.741358215047512e-07, 1.7415704860468395e-05, 2.783414174700738e-07, 0.0002966524625662714, 0.9929754734039307, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12262559682130814, 0.02392657846212387, 0.038276493549346924, 0.01617196761071682, 0.030366232618689537, 0.293759286403656, 0.10661352425813675, 0.0705995038151741, 0.041900087147951126, 0.017833100631833076, 0.2379276007413864, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0008121058344841003, 0.00011546660971362144, 0.00013500907516572624, 5.539297853829339e-05, 0.0001317415590165183, 1.0027196140072192e-06, 1.3799102589473478e-06, 1.6001615676941583e-07, 1.8972989437315846e-06, 5.419665853878541e-07, 4.753100881771388e-07, 0.9987448453903198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013333025854080915, 0.00010533028398640454, 0.0007669601473025978, 0.0009021891164593399, 3.570828994270414e-06, 8.120475172290753e-07, 1.4038076301403635e-07, 9.5612755046659e-08, 1.686503765085945e-06, 2.9789011023240164e-05, 4.3813361116917804e-07, 1.196578750750632e-06, 0.9968544840812683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08159805834293365, 0.021388869732618332, 0.02887716144323349, 0.012675800360739231, 0.02493160218000412, 0.22996485233306885, 0.1040123775601387, 0.06472097337245941, 0.03460092842578888, 0.015198715031147003, 0.18564161658287048, 0.02052805759012699, 0.005003855563700199, 0.17085716128349304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0013488888507708907, 8.921229164116085e-05, 0.000685997714754194, 0.0006963223568163812, 2.1248662960715592e-05, 3.763401252854237e-07, 6.226750315363461e-07, 4.307224514832342e-07, 7.091887255228357e-06, 0.0013103713281452656, 1.6113781953208672e-07, 9.548780326440465e-07, 0.00016453623538836837, 1.1531959387411916e-07, 0.9956737160682678, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010867505334317684, 0.00040724826976656914, 0.00010700321581680328, 0.0006782714044675231, 0.00011028484004782513, 1.3184263991661282e-07, 2.660271150034532e-07, 4.619576543518633e-07, 8.409714610024821e-06, 0.0007784891058690846, 5.1094499298187657e-08, 8.792078460828634e-07, 4.934295066050254e-05, 3.4893233191723994e-08, 0.000114411988761276, 0.9966580867767334, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05868086218833923, 0.01878575049340725, 0.024067308753728867, 0.011013145558536053, 0.02145637944340706, 0.1911056786775589, 0.09902720898389816, 0.060658685863018036, 0.03016272932291031, 0.014801912009716034, 0.15370336174964905, 0.01661515422165394, 0.00438538147136569, 0.14085331559181213, 0.015014994889497757, 0.005390205420553684, 0.13427796959877014, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07323039323091507, 0.028374575078487396, 0.02105823904275894, 0.007611881010234356, 0.010053585283458233, 0.06553947925567627, 0.14559760689735413, 0.08620841056108475, 0.010241273790597916, 0.007425742223858833, 0.045262712985277176, 0.006621459499001503, 0.0011621782323345542, 0.03923853859305382, 0.008256879635155201, 0.0030656903982162476, 0.0361226461827755, 0.40492868423461914, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [7.944500976009294e-05, 1.838214188865095e-06, 3.7134324060161816e-08, 1.5575307770632207e-05, 3.4723791486612754e-06, 1.3165096790501707e-09, 2.7038710825877388e-08, 1.7186653877843128e-08, 9.2322629541286e-08, 1.350635284325108e-05, 4.4787887287789374e-10, 2.041673052843862e-09, 5.5420287026208825e-08, 3.0638666603799436e-10, 4.217715456888982e-07, 7.065874342515599e-06, 2.424439260462208e-10, 1.4397385506015326e-09, 0.9998784065246582, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.002934493590146303, 0.0005883841076865792, 0.004250304773449898, 0.004028463736176491, 0.00011592944792937487, 4.3316217670508195e-06, 6.773899713152787e-06, 7.076467591105029e-05, 0.0002495265216566622, 0.0003159335465170443, 2.08243977795064e-06, 4.4092124880990013e-05, 0.0003044693439733237, 1.4702574162583915e-06, 0.0001976135972654447, 0.0013599260710179806, 1.2478651569836074e-06, 6.875187864352483e-06, 0.00019261146371718496, 0.9853246808052063, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04056532680988312, 0.017898334190249443, 0.020600974559783936, 0.00982110295444727, 0.0178828202188015, 0.15653996169567108, 0.09208232164382935, 0.05628824606537819, 0.026661338284611702, 0.014471272937953472, 0.12537631392478943, 0.013986768200993538, 0.003927929326891899, 0.11453614383935928, 0.013395375572144985, 0.004846665076911449, 0.10880252718925476, 0.049533966928720474, 0.0051864092238247395, 0.00442087184637785, 0.10317537188529968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024536410346627235, 0.0031243418343365192, 0.000969931366853416, 4.6315548388520256e-05, 0.000134348010760732, 0.0006453952519223094, 0.011668861843645573, 0.00032713511609472334, 0.00045730493729934096, 2.3976115699042566e-05, 0.00034454246633686125, 4.996432107873261e-05, 2.575745020294562e-05, 0.00028217825456522405, 6.525341632368509e-06, 4.981813617632724e-06, 0.0002355406468268484, 0.0002664515923243016, 2.531117388571147e-05, 2.9761116820736788e-05, 0.00018809281755238771, 0.9566067457199097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0020759988110512495, 0.00014591786020901054, 5.28989803569857e-05, 4.218073809170164e-05, 4.738719144370407e-05, 4.1423308516641555e-07, 0.00012964299821760505, 2.4250995920738205e-05, 1.803402483346872e-06, 1.4839280311207403e-06, 1.4489978639176115e-07, 4.19993239120231e-06, 4.106840378881316e-08, 1.0260480820534212e-07, 8.285464332402626e-07, 5.781902245871606e-07, 7.69515864362802e-08, 6.66962165496443e-08, 6.472614768426865e-05, 1.5700886706326855e-06, 5.6418308247430105e-08, 4.403031653055223e-06, 0.997401237487793, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005159119609743357, 0.00011814653407782316, 3.2705673220334575e-05, 0.00021188741084188223, 4.5635246351594105e-05, 2.9248894861666486e-07, 3.057942421946791e-06, 7.607361851569294e-08, 0.000137536961119622, 0.0005283545469865203, 1.1576035774396587e-07, 4.028585408377694e-06, 2.0793006569874706e-06, 8.805425011360057e-08, 0.00010051707067759708, 4.4316235289443284e-05, 6.963725240893837e-08, 9.3730577077622e-08, 3.337771704536863e-05, 1.588891973369755e-05, 5.610686315549174e-08, 7.052654638073363e-08, 9.389286788064055e-06, 0.9981963038444519, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06915222108364105, 0.014032106846570969, 0.0055990926921367645, 0.001257685013115406, 0.0008467997540719807, 0.00960117019712925, 0.008965766057372093, 0.05247688665986061, 0.00025028345407918096, 0.0009063854231499135, 0.005419903434813023, 0.0007309208740480244, 0.0001918794005177915, 0.004396578297019005, 0.00596471456810832, 0.00035585399018600583, 0.003877015318721533, 0.009727217257022858, 0.0011023484403267503, 0.00036442867713049054, 0.0034139559138566256, 0.0030523529276251793, 0.005698245484381914, 0.00029557303059846163, 0.7923206090927124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010461538331583142, 1.9557141058612615e-05, 1.7358943296130747e-06, 3.1030376703711227e-05, 2.7307954951538704e-05, 1.0180698062356441e-08, 4.815767624677392e-07, 1.749424711761094e-07, 7.31240987761339e-08, 7.983068712746899e-07, 3.4643101720632785e-09, 4.906718004349386e-06, 1.0718933651787665e-07, 2.3525483783259915e-09, 2.3834095941310807e-07, 1.3731333865507622e-06, 1.8288636161045702e-09, 6.247621531230152e-09, 9.208338269672822e-06, 1.6384271930292016e-06, 1.2523899695082719e-09, 8.27128976421676e-10, 8.45677095639985e-06, 3.118676431768108e-06, 9.241421849992548e-09, 0.9988435506820679, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0010544898686930537, 0.00021373172057792544, 0.00028157164342701435, 0.0011373355519026518, 0.00014783910592086613, 2.0068473531864583e-06, 4.831345904676709e-06, 3.4823312944354257e-06, 5.1003303269681055e-06, 0.0001242046128027141, 9.301492127633537e-07, 1.058259113051463e-05, 1.1688251106534153e-05, 7.077497912177932e-07, 0.0034115887247025967, 0.00019905219960492104, 5.995600531605305e-07, 4.643032411877357e-07, 1.9585078916861676e-05, 0.00011087769962614402, 4.7500441269221483e-07, 3.2808813443807594e-07, 4.535345397016499e-06, 5.161693843547255e-05, 3.2474670774718106e-07, 1.3071345165371895e-05, 0.9931888580322266, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.024200821295380592, 0.0028201343957334757, 0.004319303669035435, 0.0009108324302360415, 0.0017753969877958298, 0.003809922141954303, 0.002953327028080821, 0.016714811325073242, 0.0013931762659922242, 0.005003190599381924, 0.002276093466207385, 0.0005876422510482371, 0.0009901646990329027, 0.001806696760468185, 0.003131245030090213, 0.00023389424313791096, 0.001608274644240737, 0.009910316206514835, 0.0028539570048451424, 0.0002049517643172294, 0.0013712677173316479, 0.006919012870639563, 0.0010336583945900202, 0.00014528421161230654, 0.017489813268184662, 0.0004655321245081723, 0.00030240899650380015, 0.8847687840461731, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0005256079020909965, 3.5286443562654313e-06, 1.7037654060914065e-06, 9.408161713508889e-05, 0.6647976040840149, 1.6531460289570532e-07, 9.511094845038315e-07, 8.886866567081597e-07, 1.7016682249959558e-05, 3.7421796150738373e-05, 6.832253518496145e-08, 9.810881238081492e-06, 7.54872289121522e-08, 4.9632514986797105e-08, 2.039385208263411e-06, 7.68653171689948e-06, 4.066836467586654e-08, 2.674426546889208e-08, 3.343185017001815e-05, 4.3410742023297644e-07, 3.007982485314642e-08, 3.206050891435552e-08, 4.900570274912752e-06, 3.0609364785050275e-06, 1.4603168452254067e-08, 2.2145499315229245e-05, 9.211144970322493e-06, 3.164266360045076e-08, 0.33442792296409607, 0.0, 0.0, 0.0, 0.0], [0.004677003715187311, 0.0002802134840749204, 8.346093818545341e-05, 3.157015271426644e-06, 4.065350367454812e-07, 1.334351367177078e-07, 2.642356230353471e-05, 1.14399881567806e-07, 2.787234620882373e-07, 3.7496097320399713e-06, 4.652897445112103e-08, 1.721399939924595e-06, 1.8165617632348585e-07, 3.148475968828279e-08, 1.8334264950681245e-07, 5.2147466789165264e-08, 2.5215808108214333e-08, 3.078440968806717e-08, 7.142029545548212e-08, 1.6640139932633247e-08, 1.7768222448921733e-08, 8.634525272555038e-08, 2.80096719507128e-06, 8.454143767266942e-07, 3.098357126418705e-08, 2.927863249624352e-07, 5.67622805647261e-07, 5.055421858912723e-09, 2.914097763095924e-08, 0.9949179887771606, 0.0, 0.0, 0.0], [5.63678695471026e-05, 0.0002002369292313233, 1.6319063433911651e-06, 1.5089314047145308e-06, 1.777969919203315e-05, 5.956430348952324e-10, 6.940362709428882e-06, 5.0340007717863955e-09, 2.168281127978844e-07, 1.7164239807243575e-06, 1.9326229505622905e-10, 1.8911388011133567e-08, 9.538822354215881e-08, 1.294685886277236e-10, 8.077134516781825e-09, 4.386611908557825e-05, 9.768646308527806e-11, 5.256069468551061e-10, 6.932163523742929e-05, 7.50586650610785e-08, 7.069277802029816e-11, 3.9880390545476985e-08, 1.0610256140353158e-05, 2.212068466178607e-06, 8.688617603169746e-10, 9.92846798908431e-06, 5.390084822920471e-09, 1.1354436835198101e-10, 3.060034941881895e-06, 3.894551241501176e-07, 0.9995738863945007, 0.0, 0.0], [0.00035569738247431815, 1.9489476471790113e-05, 9.16096723813098e-06, 1.3085251339362003e-05, 2.3808875994291157e-05, 2.971901658099796e-08, 4.1605944716138765e-05, 1.7756508441379992e-07, 6.896241870890663e-07, 1.050624064191652e-06, 1.2230765733534099e-08, 4.290543984097894e-06, 3.295830310889869e-07, 9.21108966878137e-09, 1.7466394410803332e-06, 4.68278949483647e-06, 7.44272510289079e-09, 9.673818190947259e-09, 3.9665097574470565e-05, 7.324891271309752e-07, 5.5436903956262995e-09, 1.0396705363291403e-07, 1.4401576663658489e-05, 8.87333953869529e-06, 5.98941607421466e-09, 1.5627783795935102e-05, 2.9811244530719705e-06, 6.8743553072181385e-09, 4.8546603466093075e-06, 7.0722649070376065e-06, 6.210685569385532e-06, 0.999423623085022, 0.0], [0.05455271899700165, 0.01642906479537487, 0.01600833795964718, 0.006986881606280804, 0.02488415315747261, 0.07376930862665176, 0.07933779805898666, 0.05594553053379059, 0.02726820483803749, 0.013368779793381691, 0.05590307340025902, 0.007223027292639017, 0.005426580552011728, 0.05012327805161476, 0.00827906746417284, 0.0030609630048274994, 0.04682297259569168, 0.04751850664615631, 0.002844945527613163, 0.00703797210007906, 0.04282715544104576, 0.051381904631853104, 0.02728237770497799, 0.026375338435173035, 0.02615920640528202, 0.011997988447546959, 0.006220120470970869, 0.03648781403899193, 0.011124703101813793, 0.005218563135713339, 0.0025592013262212276, 0.002604026347398758, 0.14697043597698212]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9192656874656677, 0.08073429763317108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.45437392592430115, 0.4265042543411255, 0.11912179738283157, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5267521739006042, 0.22321626543998718, 0.12420628219842911, 0.12582527101039886, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3903488516807556, 0.17099405825138092, 0.06872710585594177, 0.1837182193994522, 0.1862117052078247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19744233787059784, 0.25436845421791077, 0.14488448202610016, 0.18925854563713074, 0.20821937918663025, 0.0058267805725336075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19473569095134735, 0.13241828978061676, 0.14391925930976868, 0.15120740234851837, 0.3002447485923767, 0.02058464102447033, 0.05688997730612755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1269666850566864, 0.21597379446029663, 0.16089318692684174, 0.19698835909366608, 0.1884462833404541, 0.013544930145144463, 0.07520709931850433, 0.021979710087180138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29121237993240356, 0.05954227223992348, 0.11079410463571548, 0.09717856347560883, 0.22345608472824097, 0.016262581571936607, 0.08719439804553986, 0.02476230077445507, 0.08959738910198212, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22981953620910645, 0.03802677243947983, 0.1601383537054062, 0.11780407279729843, 0.1618119776248932, 0.035528186708688736, 0.07561112195253372, 0.02075604349374771, 0.10670627653598785, 0.05379772558808327, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13314425945281982, 0.1885865479707718, 0.10808098316192627, 0.15994973480701447, 0.1773921400308609, 0.00359801365993917, 0.02506207674741745, 0.012862920761108398, 0.07453092187643051, 0.11275241523981094, 0.004039980936795473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.167464017868042, 0.1435522437095642, 0.06118571013212204, 0.17358075082302094, 0.10113829374313354, 0.017553476616740227, 0.03239529952406883, 0.007995500229299068, 0.05453449860215187, 0.07883203774690628, 0.017258208245038986, 0.144509956240654, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26996827125549316, 0.13029064238071442, 0.06605683267116547, 0.061561428010463715, 0.08437129855155945, 0.01984662376344204, 0.016312789171934128, 0.012965924106538296, 0.03231464698910713, 0.052547939121723175, 0.01986861042678356, 0.13695643842220306, 0.09693863242864609, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09820352494716644, 0.13618652522563934, 0.08005780726671219, 0.12152861058712006, 0.1357937753200531, 0.0024323556572198868, 0.017789484933018684, 0.009086490608751774, 0.056375276297330856, 0.08521635085344315, 0.002753338310867548, 0.1520378440618515, 0.0994671881198883, 0.003071404527872801, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1701289564371109, 0.08885712176561356, 0.09089688956737518, 0.08085790276527405, 0.11427339166402817, 0.010901481844484806, 0.014788410626351833, 0.005497373174875975, 0.051512572914361954, 0.05330684408545494, 0.01059581246227026, 0.0944228246808052, 0.13098116219043732, 0.011153684929013252, 0.07182559370994568, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10365854948759079, 0.035885412245988846, 0.08803566545248032, 0.06087937578558922, 0.08348330110311508, 0.030805736780166626, 0.02961592748761177, 0.010918701998889446, 0.04049993306398392, 0.042886074632406235, 0.032192956656217575, 0.15008126199245453, 0.12658774852752686, 0.034902174025774, 0.05825433507561684, 0.07131282240152359, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07047095149755478, 0.0960099920630455, 0.05621575564146042, 0.08699890226125717, 0.0993412658572197, 0.0016298794653266668, 0.012408613227307796, 0.006380433216691017, 0.041014060378074646, 0.06348714977502823, 0.0018482194282114506, 0.11387647688388824, 0.07328981161117554, 0.002071293769404292, 0.07246169447898865, 0.20012779533863068, 0.002367776120081544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.056594450026750565, 0.08906210213899612, 0.047032419592142105, 0.09457877278327942, 0.08793887495994568, 0.0019721658900380135, 0.01776767522096634, 0.0059904372319579124, 0.060148607939481735, 0.08834967762231827, 0.002263767411932349, 0.10461525619029999, 0.0607936829328537, 0.0025566243566572666, 0.07818624377250671, 0.19496023654937744, 0.0029299866873770952, 0.004259060136973858, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15970617532730103, 0.026096448302268982, 0.04515179619193077, 0.0349758043885231, 0.0803067609667778, 0.05469035357236862, 0.040785446763038635, 0.026513049378991127, 0.02725192718207836, 0.03919817507266998, 0.053514350205659866, 0.0484292134642601, 0.0626426562666893, 0.05558209866285324, 0.055596668273210526, 0.047929611057043076, 0.056763261556625366, 0.04892301186919212, 0.035943202674388885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08663123846054077, 0.09557438641786575, 0.03673812374472618, 0.06946706771850586, 0.056814584881067276, 0.008190209977328777, 0.022195829078555107, 0.007642821874469519, 0.031468264758586884, 0.07555205374956131, 0.008965261280536652, 0.05263480544090271, 0.04491107910871506, 0.009935053996741772, 0.04481377825140953, 0.15198467671871185, 0.010933401063084602, 0.007993677631020546, 0.16402563452720642, 0.013528109528124332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.047834526747465134, 0.06669355928897858, 0.03798918053507805, 0.06040370464324951, 0.06899041682481766, 0.0010267295874655247, 0.008172672241926193, 0.004158169962465763, 0.028268281370401382, 0.04407241567969322, 0.0011586470063775778, 0.0783291682600975, 0.05082899332046509, 0.0013004966313019395, 0.04904298111796379, 0.14145006239414215, 0.0014934326754882932, 0.002556685358285904, 0.17534077167510986, 0.12910206615924835, 0.0017870552837848663, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04114091023802757, 0.04766076058149338, 0.03587000072002411, 0.0666610524058342, 0.07969273626804352, 0.0023650776129215956, 0.02034018002450466, 0.004854495171457529, 0.0643620416522026, 0.06737155467271805, 0.0027073693927377462, 0.055960532277822495, 0.056486643850803375, 0.003076725173741579, 0.053543876856565475, 0.1516592800617218, 0.0035397117026150227, 0.004673930816352367, 0.164027139544487, 0.059681568294763565, 0.004154943395406008, 0.010169516317546368, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0662880688905716, 0.040925417095422745, 0.027322685346007347, 0.045053672045469284, 0.06575217097997665, 0.015657564625144005, 0.02788187935948372, 0.013711261563003063, 0.03174294903874397, 0.05280747637152672, 0.015447773970663548, 0.032181113958358765, 0.032901063561439514, 0.016298862174153328, 0.0266366396099329, 0.09772849828004837, 0.01711420528590679, 0.0169194545596838, 0.09847067296504974, 0.04787907376885414, 0.018412543460726738, 0.015331601724028587, 0.17753538489341736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09801430255174637, 0.02632881887257099, 0.035868145525455475, 0.057130590081214905, 0.06943875551223755, 0.012128960341215134, 0.020909082144498825, 0.008747957646846771, 0.026999661698937416, 0.03726678714156151, 0.011716341599822044, 0.08499537408351898, 0.05501335486769676, 0.012196708470582962, 0.035639114677906036, 0.08789660781621933, 0.01297010388225317, 0.010851019993424416, 0.06408388167619705, 0.05963919684290886, 0.01449217926710844, 0.006093734409660101, 0.09761437028646469, 0.05396497994661331, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.027693241834640503, 0.04073772206902504, 0.031223539263010025, 0.058790355920791626, 0.05601824074983597, 0.0015714798355475068, 0.011908036656677723, 0.0033397905062884092, 0.051765505224466324, 0.05291245877742767, 0.001825982122682035, 0.06030035763978958, 0.028357168659567833, 0.0020878103096038103, 0.05086478590965271, 0.07898837327957153, 0.0023987048771232367, 0.002904826309531927, 0.11135736107826233, 0.04586018994450569, 0.0028849169611930847, 0.011431248858571053, 0.1234055683016777, 0.1348847597837448, 0.006487556267529726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15390776097774506, 0.023786790668964386, 0.053202446550130844, 0.039638858288526535, 0.05711061879992485, 0.015628937631845474, 0.020206067711114883, 0.009252368472516537, 0.02131185680627823, 0.029029950499534607, 0.01474190317094326, 0.0612383633852005, 0.10112591087818146, 0.015157820656895638, 0.04335401952266693, 0.04090718552470207, 0.0157326590269804, 0.020073413848876953, 0.05374934524297714, 0.03468615934252739, 0.016989367082715034, 0.006368496920913458, 0.04042016342282295, 0.031060412526130676, 0.013937164098024368, 0.06738193333148956, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08555092662572861, 0.03505741059780121, 0.05885254591703415, 0.03497907146811485, 0.051787443459033966, 0.0025119909550994635, 0.004151215776801109, 0.0020859164651483297, 0.014081118628382683, 0.024491356685757637, 0.0023760043550282717, 0.0953511968255043, 0.07766133546829224, 0.0024908813647925854, 0.04572675749659538, 0.05774116516113281, 0.0026603781152516603, 0.0033477565739303827, 0.047998279333114624, 0.026788819581270218, 0.002958715660497546, 0.004655787721276283, 0.036070987582206726, 0.021599194034934044, 0.004788634832948446, 0.22052207589149475, 0.033713050186634064, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.020706715062260628, 0.037194058299064636, 0.019723709672689438, 0.038942236453294754, 0.03182700276374817, 0.0012253682361915708, 0.008815746754407883, 0.0024052909575402737, 0.034579578787088394, 0.04729808494448662, 0.0013953758170828223, 0.05148205906152725, 0.020486745983362198, 0.0015608397079631686, 0.038261182606220245, 0.0486375130712986, 0.0017825296381488442, 0.0025446084327995777, 0.06541350483894348, 0.0418856218457222, 0.002096058102324605, 0.009401388466358185, 0.0846002995967865, 0.09019993990659714, 0.0054032769985497, 0.22932566702365875, 0.05692271143198013, 0.0058829206973314285, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08582810312509537, 0.03967174515128136, 0.014841817319393158, 0.05653620511293411, 0.059606119990348816, 0.006987516302615404, 0.010110092349350452, 0.0028877267614006996, 0.0153228510171175, 0.025928765535354614, 0.006830443628132343, 0.033548954874277115, 0.02109353058040142, 0.007213154342025518, 0.01932339556515217, 0.05298227071762085, 0.007658609189093113, 0.0051578436978161335, 0.0652318149805069, 0.018170004710555077, 0.008534704335033894, 0.00436816643923521, 0.02691243216395378, 0.049627941101789474, 0.004404332488775253, 0.1938866823911667, 0.03933223336935043, 0.005363552365452051, 0.11263895779848099, 0.0, 0.0, 0.0, 0.0], [0.07040347158908844, 0.059261634945869446, 0.015334844589233398, 0.0241390448063612, 0.015728846192359924, 0.01949210837483406, 0.01731151156127453, 0.017303064465522766, 0.020563246682286263, 0.045155856758356094, 0.021815823391079903, 0.07079729437828064, 0.03006395325064659, 0.023540621623396873, 0.020684488117694855, 0.02116367220878601, 0.026445116847753525, 0.02354004979133606, 0.05663725733757019, 0.033694788813591, 0.030707282945513725, 0.015993358567357063, 0.015474077314138412, 0.0308036208152771, 0.03180558979511261, 0.07969609647989273, 0.034374888986349106, 0.03453715518116951, 0.030624374747276306, 0.062906913459301, 0.0, 0.0, 0.0], [0.05338500067591667, 0.029621528461575508, 0.021030085161328316, 0.02369570918381214, 0.033436402678489685, 0.01839382015168667, 0.024060703814029694, 0.02281002141535282, 0.013972364366054535, 0.028813553974032402, 0.019059734418988228, 0.015371961519122124, 0.025335321202874184, 0.019971955567598343, 0.014075742103159428, 0.0388445183634758, 0.021346205845475197, 0.019321443513035774, 0.05632658302783966, 0.021359993144869804, 0.023394571617245674, 0.023136651143431664, 0.06416381150484085, 0.06724690645933151, 0.0346951000392437, 0.04349018633365631, 0.03032725304365158, 0.03285714238882065, 0.05327507480978966, 0.0659981295466423, 0.041182469576597214, 0.0, 0.0], [0.18177087604999542, 0.01953315921127796, 0.028002941980957985, 0.029110200703144073, 0.04134833812713623, 0.018019484356045723, 0.01047173049300909, 0.008382915519177914, 0.015335788019001484, 0.021839458495378494, 0.016893334686756134, 0.03806137666106224, 0.03643865883350372, 0.017464254051446915, 0.02612907811999321, 0.040115050971508026, 0.01831720396876335, 0.01248822920024395, 0.05136970430612564, 0.019443845376372337, 0.01988975703716278, 0.0035764502827078104, 0.026232954114675522, 0.018429197371006012, 0.011723745614290237, 0.032729849219322205, 0.0348081961274147, 0.012035045772790909, 0.06030292063951492, 0.007873311638832092, 0.042272940278053284, 0.07959001511335373, 0.0], [0.015003406442701817, 0.02033485285937786, 0.007813435979187489, 0.016553577035665512, 0.016466092318296432, 0.00023809658887330443, 0.0019598924554884434, 0.00068982585798949, 0.006483219563961029, 0.01073408406227827, 0.0002443529083393514, 0.014634677208960056, 0.009247622452676296, 0.00026059203082695603, 0.009339921176433563, 0.04272656515240669, 0.00028863936313427985, 0.0003811671631410718, 0.05474938452243805, 0.09452768415212631, 0.0003421127621550113, 0.0017270202515646815, 0.04745931923389435, 0.02661379799246788, 0.0010238660033792257, 0.1653798371553421, 0.014187103137373924, 0.0013092354638502002, 0.047706522047519684, 0.011198497377336025, 0.22050756216049194, 0.139426127076149, 0.00044186273589730263]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9333657622337341, 0.06663426756858826, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.32452353835105896, 0.5923718810081482, 0.08310452848672867, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14159750938415527, 0.5143810510635376, 0.28144124150276184, 0.0625801756978035, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25262272357940674, 0.05834071338176727, 0.10458876192569733, 0.4411158859729767, 0.14333191514015198, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.18051555752754211, 0.09828909486532211, 0.10873951762914658, 0.122626893222332, 0.0999554768204689, 0.38987353444099426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17192305624485016, 0.023321006447076797, 0.12332706898450851, 0.060765016824007034, 0.05971711501479149, 0.3475918471813202, 0.2133549153804779, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09627038985490799, 0.04683620482683182, 0.028257310390472412, 0.03239251673221588, 0.0586504265666008, 0.15829351544380188, 0.3099648654460907, 0.2693347632884979, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09948233515024185, 0.06464185565710068, 0.028671834617853165, 0.07305675745010376, 0.02978719212114811, 0.1396002173423767, 0.20754706859588623, 0.265802264213562, 0.09141051769256592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05632038041949272, 0.029885873198509216, 0.013419919647276402, 0.002407554304227233, 0.013245483860373497, 0.04564544931054115, 0.0552256777882576, 0.10027099400758743, 0.6579986214637756, 0.025580093264579773, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04266995191574097, 0.010426480323076248, 0.010652214288711548, 0.013446636497974396, 0.009353146888315678, 0.04015978425741196, 0.0710517168045044, 0.13737653195858002, 0.10423264652490616, 0.21736642718315125, 0.3432644307613373, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.029683906584978104, 0.0025616411585360765, 0.004407484084367752, 0.0342487134039402, 0.014238744974136353, 0.02800183929502964, 0.02228802815079689, 0.07105959206819534, 0.04026231914758682, 0.5543042421340942, 0.17333045601844788, 0.025613006204366684, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04039590805768967, 0.008631582371890545, 0.005494220182299614, 0.003864138852804899, 0.02336309663951397, 0.027207026258111, 0.025677349418401718, 0.05048520863056183, 0.05105610564351082, 0.05041782185435295, 0.14164340496063232, 0.511528491973877, 0.0602356381714344, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.028706423938274384, 0.004808463156223297, 0.004723660182207823, 0.005382605362683535, 0.003456041682511568, 0.014470180496573448, 0.024037392809987068, 0.041626233607530594, 0.03567291423678398, 0.07060736417770386, 0.10830995440483093, 0.05811615660786629, 0.20621225237846375, 0.39387041330337524, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.05342648923397064, 0.011923294514417648, 0.015572263859212399, 0.002112326677888632, 0.005851034075021744, 0.02217094972729683, 0.03818470612168312, 0.027411576360464096, 0.05464286729693413, 0.0491083487868309, 0.1232837438583374, 0.05287173017859459, 0.07545652985572815, 0.37015295028686523, 0.09783122688531876, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008346715942025185, 0.0002785271208267659, 0.0011785998940467834, 0.002139551565051079, 0.0024761699605733156, 0.002918292535468936, 0.004576892592012882, 0.00396559527143836, 0.004973019473254681, 0.011347760446369648, 0.013014075346291065, 0.0055459714494645596, 0.020895585417747498, 0.03838541731238365, 0.8750316500663757, 0.004926192108541727, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021700292825698853, 0.00267866556532681, 0.0023839252535253763, 0.002815628657117486, 0.001556234317831695, 0.0061394087970256805, 0.009039806202054024, 0.013740871101617813, 0.01241220161318779, 0.02468651905655861, 0.03406905010342598, 0.017561480402946472, 0.06082956865429878, 0.12004051357507706, 0.11516807973384857, 0.1266368180513382, 0.428540974855423, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019681399688124657, 0.0028661908581852913, 0.002752863336354494, 0.0023642026353627443, 0.002220575697720051, 0.004776976071298122, 0.00501539371907711, 0.007020775228738785, 0.006603001616895199, 0.015824897214770317, 0.021779123693704605, 0.02237590402364731, 0.03905554488301277, 0.07342635840177536, 0.07227571308612823, 0.0810362920165062, 0.2556319832801819, 0.36529284715652466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03443866968154907, 0.002429508138448, 0.0027038801927119493, 0.0010108943097293377, 0.002821240806952119, 0.009310664609074593, 0.007474072743207216, 0.010526394471526146, 0.01934260129928589, 0.0065833935514092445, 0.03052525781095028, 0.008166545070707798, 0.023945637047290802, 0.08047980815172195, 0.04428938031196594, 0.04886513203382492, 0.23266316950321198, 0.3870972990989685, 0.04732641950249672, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0036976842675358057, 0.006450955290347338, 0.0004921724321320653, 0.00030695926398038864, 0.00012400784180499613, 0.001072736456990242, 0.000885879504494369, 0.001380637171678245, 0.0008200182928703725, 0.00027311884332448244, 0.002783067524433136, 0.03529432415962219, 0.003561380784958601, 0.007148327771574259, 0.0016474088188260794, 0.016731666401028633, 0.01917281746864319, 0.022339215502142906, 0.8733667135238647, 0.002450962085276842, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.013628792949020863, 0.0014384448295459151, 0.0012188645778223872, 0.0012915857369080186, 0.0006118026794865727, 0.0021400393452495337, 0.002746958052739501, 0.0033360461238771677, 0.0030918740667402744, 0.0059889210388064384, 0.007237222045660019, 0.0035477462224662304, 0.012891962192952633, 0.022229157388210297, 0.020824270322918892, 0.026295337826013565, 0.07648159563541412, 0.162614643573761, 0.12638668715953827, 0.10034441947937012, 0.4056536853313446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.021433012560009956, 0.0007291650981642306, 0.0010889684781432152, 0.0008559622219763696, 0.0010556617053225636, 0.0023542488925158978, 0.0018633351428434253, 0.0024869900662451982, 0.004011370707303286, 0.00364562775939703, 0.006636614911258221, 0.00245916610583663, 0.008106647059321404, 0.019501417875289917, 0.013945517130196095, 0.01683160662651062, 0.06727857887744904, 0.1020374596118927, 0.07506173104047775, 0.03785506263375282, 0.3474157154560089, 0.2633461356163025, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01837441883981228, 0.0016340133734047413, 0.0002648659865371883, 0.0006277092033997178, 0.0007212881464511156, 0.0022947099059820175, 0.0014375781174749136, 0.0024335701018571854, 0.0010225052246823907, 0.002173095243051648, 0.005665970500558615, 0.0005857062060385942, 0.004730303306132555, 0.015789635479450226, 0.0091210613027215, 0.006447893567383289, 0.049651872366666794, 0.07221094518899918, 0.04530426114797592, 0.022536201402544975, 0.2338051199913025, 0.2810095250606537, 0.22215774655342102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01601029559969902, 0.0004190771433059126, 0.0016793134855106473, 0.002033165656030178, 0.0011126038152724504, 0.0023041246458888054, 0.0016414874698966742, 0.0020452288445085287, 0.0008826451958157122, 0.0035318168811500072, 0.004660747945308685, 0.0011461275862529874, 0.004025280009955168, 0.011729467660188675, 0.006906019523739815, 0.0059789856895804405, 0.0341360978782177, 0.05391989275813103, 0.07536924630403519, 0.015544163063168526, 0.15307274460792542, 0.21672502160072327, 0.23267339169979095, 0.15245306491851807, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016415517777204514, 0.001088100136257708, 0.0013027014210820198, 0.0012335635256022215, 0.0010325235780328512, 0.0013605313142761588, 0.001135275699198246, 0.000971320434473455, 0.0017580223502591252, 0.002354996744543314, 0.0022677977103739977, 0.002617006190121174, 0.003284963546320796, 0.005564447026699781, 0.007287747226655483, 0.006582668982446194, 0.016911085695028305, 0.023348139598965645, 0.033363766968250275, 0.012060868553817272, 0.08410526067018509, 0.10776983201503754, 0.12741325795650482, 0.25009581446647644, 0.28867483139038086, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.031117742881178856, 0.0015063059981912374, 0.0010839333990588784, 0.0024215239100158215, 0.0013826872454956174, 0.0037937278393656015, 0.001633930834941566, 0.0031195227056741714, 0.001281263306736946, 0.0020685256458818913, 0.004760121461004019, 0.0008757328032515943, 0.008592117577791214, 0.009353645145893097, 0.011993257328867912, 0.005963009782135487, 0.022028164938092232, 0.034113284200429916, 0.009586768224835396, 0.013681805692613125, 0.08417056500911713, 0.08917810767889023, 0.10806842148303986, 0.1556078940629959, 0.37236839532852173, 0.020249489694833755, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.014838478527963161, 0.0005757309845648706, 0.004743654280900955, 0.00045677347225137055, 0.0007412285194732249, 0.0015000004786998034, 0.0008866074495017529, 0.0008452078909613192, 0.00010359274165239185, 0.0009065137710422277, 0.001809678040444851, 0.06029113009572029, 0.0015377546660602093, 0.0033079427666962147, 0.0013713676016777754, 0.002082675229758024, 0.00864398293197155, 0.00908886082470417, 0.007760951295495033, 0.005808333866298199, 0.03386512026190758, 0.039871860295534134, 0.053745534271001816, 0.03694774582982063, 0.1225944235920906, 0.5718704462051392, 0.013804461807012558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01857003942131996, 0.001214318908751011, 0.0012880443828180432, 0.0010612577898427844, 0.0007490054122172296, 0.00104856479447335, 0.0008687893277965486, 0.0005973864463157952, 0.001293829525820911, 0.001404253882355988, 0.0011055117938667536, 0.0005003456026315689, 0.0020262643229216337, 0.0021463159937411547, 0.0028737951070070267, 0.0026413712184876204, 0.005802985280752182, 0.008191375993192196, 0.00833908375352621, 0.005543312523514032, 0.026558667421340942, 0.03308920934796333, 0.03250737488269806, 0.09199848771095276, 0.10410472005605698, 0.16861790418624878, 0.20895421504974365, 0.2669035494327545, 0.0, 0.0, 0.0, 0.0, 0.0], [0.016654422506690025, 0.0007248655892908573, 0.0008980649872682989, 0.0031616862397640944, 0.0005522817373275757, 0.001660726498812437, 0.0007486108806915581, 0.0009652801672928035, 0.0003842795267701149, 0.0022577804047614336, 0.0015545624773949385, 0.000703699653968215, 0.0014688166556879878, 0.002799883484840393, 0.0030139803420752287, 0.005369036458432674, 0.006552345585078001, 0.00870156567543745, 0.0071388608776032925, 0.00651632621884346, 0.02618558146059513, 0.03929201140999794, 0.0315500944852829, 0.02434304729104042, 0.1067076027393341, 0.15159794688224792, 0.13674215972423553, 0.32013967633247375, 0.09161478281021118, 0.0, 0.0, 0.0, 0.0], [0.03722686320543289, 0.0007442747009918094, 0.0019180356757715344, 0.0014290646649897099, 0.002559736603870988, 0.00329283787868917, 0.0009007269982248545, 0.0015445102471858263, 0.00035572159686125815, 0.0004492738808039576, 0.0026688207872211933, 0.0014046673895791173, 0.0017281032633036375, 0.004542735870927572, 0.0012941038003191352, 0.004677667748183012, 0.009138188324868679, 0.008992953225970268, 0.005343664437532425, 0.0020318396855145693, 0.030930884182453156, 0.021215267479419708, 0.03639974817633629, 0.05679469183087349, 0.11195951700210571, 0.011458112858235836, 0.03353290632367134, 0.26588523387908936, 0.24695421755313873, 0.09262565523386002, 0.0, 0.0, 0.0], [0.044088784605264664, 0.0011082937708124518, 0.0033875901717692614, 0.004853192251175642, 0.002864320995286107, 0.00450086547061801, 0.001451809424906969, 0.002192495157942176, 0.0007902366924099624, 0.0006717380019836128, 0.0035771613474935293, 0.0005131777143105865, 0.012861722148954868, 0.0051168520003557205, 0.0030142557807266712, 0.005887469742447138, 0.010453404858708382, 0.013818339444696903, 0.00869105663150549, 0.011229275725781918, 0.03140093758702278, 0.023181643337011337, 0.030444398522377014, 0.035206835716962814, 0.09999856352806091, 0.006090160924941301, 0.14714236557483673, 0.16393059492111206, 0.12749522924423218, 0.19357727468013763, 0.0004599906678777188, 0.0, 0.0], [0.037174027413129807, 0.005006894003599882, 0.0016112340381368995, 0.0028301484417170286, 0.000511850172188133, 0.0027071270160377026, 0.002097034128382802, 0.0012328779557719827, 0.0006310886819846928, 0.0017632486997172236, 0.0017868793802335858, 0.0002528328914195299, 0.0010720754507929087, 0.002644835039973259, 0.0015661607030779123, 0.003808412002399564, 0.005276739131659269, 0.006930261384695768, 0.013310829177498817, 0.0035816438030451536, 0.018304521217942238, 0.026684733107686043, 0.019971519708633423, 0.032155781984329224, 0.07432040572166443, 0.023922255262732506, 0.08761473745107651, 0.18007546663284302, 0.027492547407746315, 0.059722479432821274, 0.19122697412967682, 0.16271239519119263, 0.0], [0.008116938173770905, 0.0008723060018382967, 0.0003707293653860688, 0.0004734859394375235, 0.00017833002493716776, 0.0003994709986727685, 0.0002951171773020178, 0.000183119424036704, 0.00016714591765776277, 0.0002370249858358875, 0.00025333603844046593, 0.00012855058594141155, 0.00020213202515151352, 0.0003994496655650437, 0.00016511858848389238, 0.00046228745486587286, 0.0008780215284787118, 0.0011140485294163227, 0.0020708804950118065, 0.0019636773504316807, 0.0035278566647320986, 0.00447522196918726, 0.004463483579456806, 0.007312552537769079, 0.014446231536567211, 0.03503046929836273, 0.02001413330435753, 0.043885767459869385, 0.01943674124777317, 0.11325742304325104, 0.07277625054121017, 0.16196832060813904, 0.48047444224357605]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.947374701499939, 0.052625250071287155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8785883784294128, 0.055394671857357025, 0.06601690500974655, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.727077066898346, 0.13709872961044312, 0.04866095632314682, 0.08716326951980591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4651746451854706, 0.13429315388202667, 0.1535816341638565, 0.1747255027294159, 0.07222513109445572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1703597605228424, 0.011841950938105583, 0.023650867864489555, 0.021745821461081505, 0.025856319814920425, 0.7465452551841736, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14214575290679932, 0.043832745403051376, 0.050211820751428604, 0.0451650433242321, 0.058721255511045456, 0.5111533999443054, 0.14877000451087952, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0847335234284401, 0.020369812846183777, 0.037461645901203156, 0.03195912018418312, 0.034195996820926666, 0.43500685691833496, 0.11894059181213379, 0.2373325079679489, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.342307984828949, 0.035936351865530014, 0.07259215414524078, 0.10352760553359985, 0.08196526765823364, 0.07694564014673233, 0.14196324348449707, 0.09896711260080338, 0.04579460248351097, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.37114858627319336, 0.06278739124536514, 0.058069512248039246, 0.055662769824266434, 0.13124839961528778, 0.07535631209611893, 0.10726627707481384, 0.07924022525548935, 0.03010733053088188, 0.02911323867738247, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.06430108100175858, 0.0051691061817109585, 0.01101299561560154, 0.009054884314537048, 0.011748056858778, 0.3188501298427582, 0.036849480122327805, 0.0831955149769783, 0.012068147771060467, 0.014676216058433056, 0.43307435512542725, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23777928948402405, 0.038129985332489014, 0.019743366166949272, 0.0750802755355835, 0.1442079246044159, 0.06244928389787674, 0.07018386572599411, 0.06523600965738297, 0.04883219674229622, 0.03460035100579262, 0.06439768522977829, 0.13935980200767517, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29014477133750916, 0.040857672691345215, 0.06965631991624832, 0.06467737257480621, 0.11515595018863678, 0.07279438525438309, 0.05406038835644722, 0.04095999896526337, 0.036461241543293, 0.03709695488214493, 0.08112158626317978, 0.06249445676803589, 0.03451891243457794, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04191605746746063, 0.0033880730625241995, 0.007082369644194841, 0.005899208597838879, 0.007586185354739428, 0.20389790832996368, 0.023296769708395004, 0.05173072591423988, 0.00781681016087532, 0.009731383062899113, 0.277601957321167, 0.0083867646753788, 0.016172712668776512, 0.33549317717552185, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1512935310602188, 0.04240793734788895, 0.04383380711078644, 0.09706761687994003, 0.14943543076515198, 0.04439884424209595, 0.0617450512945652, 0.04199514165520668, 0.018608801066875458, 0.03141245245933533, 0.05092647299170494, 0.06660285592079163, 0.09416218847036362, 0.05761292949318886, 0.04849693551659584, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2995801866054535, 0.07432065904140472, 0.030061958357691765, 0.016736479476094246, 0.038564808666706085, 0.05106877163052559, 0.0940866693854332, 0.056067921221256256, 0.05458230525255203, 0.045220427215099335, 0.05638071149587631, 0.015378049574792385, 0.04082851856946945, 0.06084698066115379, 0.030811063945293427, 0.03546450659632683, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.030439967289566994, 0.0024933922104537487, 0.005298207979649305, 0.004223392810672522, 0.005517445504665375, 0.14508455991744995, 0.01603415049612522, 0.035986483097076416, 0.005758048966526985, 0.007398167625069618, 0.19613467156887054, 0.0060908910818398, 0.011465114541351795, 0.23738010227680206, 0.008031780831515789, 0.0058614895679056644, 0.2768022119998932, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015668945387005806, 0.0019133489113301039, 0.0067479368299245834, 0.005610876716673374, 0.006710356567054987, 0.10858530551195145, 0.013436987064778805, 0.030674809589982033, 0.00869804434478283, 0.0059587713330984116, 0.15696412324905396, 0.00640126271173358, 0.014357191510498524, 0.19220469892024994, 0.009938815608620644, 0.008154560811817646, 0.2286139577627182, 0.1793600469827652, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2751207649707794, 0.046356067061424255, 0.02578277513384819, 0.0203710924834013, 0.04519130662083626, 0.04741503298282623, 0.058008357882499695, 0.05449456721544266, 0.02185584418475628, 0.028674190863966942, 0.05054796487092972, 0.03578946739435196, 0.014343996532261372, 0.05505191534757614, 0.019970901310443878, 0.025070670992136, 0.05983668938279152, 0.10591265559196472, 0.010205721482634544, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12210459262132645, 0.029006361961364746, 0.02792610414326191, 0.030763672664761543, 0.06431954354047775, 0.05075869336724281, 0.05746712163090706, 0.03854454308748245, 0.028814468532800674, 0.0364103689789772, 0.05530695244669914, 0.027555696666240692, 0.050623830407857895, 0.06039685383439064, 0.03790910542011261, 0.03416259586811066, 0.06550321727991104, 0.08224612474441528, 0.08903136849403381, 0.011148831807076931, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.01992272213101387, 0.001599126379005611, 0.003536272794008255, 0.0027606128714978695, 0.0036747471895068884, 0.09198576211929321, 0.009868195280432701, 0.021762728691101074, 0.0036746179684996605, 0.004800301510840654, 0.12327180057764053, 0.003948226571083069, 0.007727705407887697, 0.1490194946527481, 0.00509450351819396, 0.0038495471235364676, 0.17433799803256989, 0.14503759145736694, 0.0031391787342727184, 0.0039015680085867643, 0.21708735823631287, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.025169160217046738, 0.0025891438126564026, 0.0079044783487916, 0.002818176057189703, 0.008317483589053154, 0.06284765154123306, 0.016097374260425568, 0.02483358606696129, 0.007658039685338736, 0.011317077092826366, 0.08451005816459656, 0.012135406024754047, 0.022048380225896835, 0.10017254203557968, 0.015103290788829327, 0.020152248442173004, 0.11906809359788895, 0.141489639878273, 0.006576651707291603, 0.007074057590216398, 0.14850656688213348, 0.15361090004444122, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08679644018411636, 0.01581868715584278, 0.009913153946399689, 0.005941125564277172, 0.01174909621477127, 0.04402247816324234, 0.04941156879067421, 0.04721157252788544, 0.02244850993156433, 0.028144165873527527, 0.05249371379613876, 0.013664888218045235, 0.038044523447752, 0.05856490880250931, 0.016008717939257622, 0.028531761839985847, 0.06752399355173111, 0.100040502846241, 0.0260744821280241, 0.018165268003940582, 0.08061444759368896, 0.14588390290737152, 0.03293200954794884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12203321605920792, 0.02679692953824997, 0.03471270203590393, 0.016600845381617546, 0.05098597705364227, 0.033623453229665756, 0.03376290947198868, 0.03289441019296646, 0.02276359312236309, 0.03469543159008026, 0.03710822016000748, 0.027503052726387978, 0.030508041381835938, 0.040704939514398575, 0.019409826025366783, 0.03338811546564102, 0.04603790119290352, 0.08141941577196121, 0.025792943313717842, 0.017713351175189018, 0.05326375365257263, 0.06955214589834213, 0.07340101152658463, 0.03532780706882477, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.012632705271244049, 0.003196730511263013, 0.008999625220894814, 0.003787106368690729, 0.005590212065726519, 0.060187455266714096, 0.010173022747039795, 0.02606339193880558, 0.008280332200229168, 0.005998438689857721, 0.08480244874954224, 0.007755734026432037, 0.01480766199529171, 0.10079346597194672, 0.011636026203632355, 0.007885104976594448, 0.12061367183923721, 0.12819863855838776, 0.006487111561000347, 0.003230573143810034, 0.15047506988048553, 0.10557690262794495, 0.015480595640838146, 0.01902633346617222, 0.0783216580748558, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11176053434610367, 0.018635569140315056, 0.05622373893857002, 0.0467727966606617, 0.0373649075627327, 0.022993413731455803, 0.0313652828335762, 0.026408890262246132, 0.04335922747850418, 0.05663558095693588, 0.0217863991856575, 0.02382214553654194, 0.030641676858067513, 0.023289253935217857, 0.05430492013692856, 0.06881187111139297, 0.02448936179280281, 0.04777087643742561, 0.03627174720168114, 0.022222528234124184, 0.026998938992619514, 0.021766116842627525, 0.03442489728331566, 0.0282402653247118, 0.05891922488808632, 0.024719836190342903, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10639801621437073, 0.037107910960912704, 0.08273959904909134, 0.017856869846582413, 0.020949997007846832, 0.01830524392426014, 0.022620104253292084, 0.018192270770668983, 0.02185118943452835, 0.012518536299467087, 0.019214091822504997, 0.030340084806084633, 0.0718761458992958, 0.02078801579773426, 0.03963524103164673, 0.061515890061855316, 0.02317928895354271, 0.0439804382622242, 0.0461922362446785, 0.02066798135638237, 0.027080867439508438, 0.04386550933122635, 0.0327674001455307, 0.04369066655635834, 0.05080844461917877, 0.04029489681124687, 0.025562994182109833, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.015084557235240936, 0.003822385100647807, 0.005877269431948662, 0.0049718525260686874, 0.005370146129280329, 0.05223643779754639, 0.016127673909068108, 0.031829893589019775, 0.008211132138967514, 0.011473819613456726, 0.0670468658208847, 0.010528383776545525, 0.010598218068480492, 0.07938902080059052, 0.007211726158857346, 0.006271465681493282, 0.09142371267080307, 0.10866504162549973, 0.003973815590143204, 0.005621671676635742, 0.1098332405090332, 0.09237755835056305, 0.02296048402786255, 0.019314922392368317, 0.08864141255617142, 0.018464695662260056, 0.011022248305380344, 0.0916503444314003, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09854131191968918, 0.03967056795954704, 0.05052144452929497, 0.04794393479824066, 0.019531866535544395, 0.015683403238654137, 0.025074752047657967, 0.014997916296124458, 0.027723463252186775, 0.016418172046542168, 0.016389023512601852, 0.026316555216908455, 0.03435926139354706, 0.017758004367351532, 0.023362673819065094, 0.03763517364859581, 0.019405588507652283, 0.034421686083078384, 0.04902298003435135, 0.03019052930176258, 0.022159064188599586, 0.03754063695669174, 0.03879312425851822, 0.040324147790670395, 0.0423126257956028, 0.06829199939966202, 0.02531410939991474, 0.04330074042081833, 0.036995261907577515, 0.0, 0.0, 0.0, 0.0], [0.10688817501068115, 0.036595750600099564, 0.005083092022687197, 0.010160422883927822, 0.013297352008521557, 0.041752081364393234, 0.026246804744005203, 0.03012857399880886, 0.013482393696904182, 0.018223188817501068, 0.045826248824596405, 0.02555878646671772, 0.015618832781910896, 0.05039896070957184, 0.011657016351819038, 0.011659123934805393, 0.055155135691165924, 0.0509166419506073, 0.019206780940294266, 0.013998408801853657, 0.06383473426103592, 0.029088910669088364, 0.01671043410897255, 0.02609526738524437, 0.05484984442591667, 0.038066718727350235, 0.038960687816143036, 0.053752351552248, 0.023679161444306374, 0.05310811847448349, 0.0, 0.0, 0.0], [0.10871606320142746, 0.06286413967609406, 0.023045117035508156, 0.012493222951889038, 0.009688264690339565, 0.02372078225016594, 0.02561735175549984, 0.028282862156629562, 0.01952310837805271, 0.015187137760221958, 0.024615760892629623, 0.018855810165405273, 0.013071931898593903, 0.02569747157394886, 0.010639796033501625, 0.007336434442549944, 0.02848823182284832, 0.04087509214878082, 0.023693926632404327, 0.028460830450057983, 0.031781136989593506, 0.03399211913347244, 0.016904516145586967, 0.04699750244617462, 0.05480921268463135, 0.06048174574971199, 0.02113782800734043, 0.05147770792245865, 0.015304342843592167, 0.07868865132331848, 0.03755192831158638, 0.0, 0.0], [0.16510620713233948, 0.013307325541973114, 0.02282033860683441, 0.032224953174591064, 0.028327813372015953, 0.011912120506167412, 0.021759120747447014, 0.012591326609253883, 0.02537134662270546, 0.01592349447309971, 0.011745062656700611, 0.021340150386095047, 0.02265850082039833, 0.012097008526325226, 0.058773938566446304, 0.04114294424653053, 0.012866126373410225, 0.02189669758081436, 0.027385761961340904, 0.015412716194987297, 0.014822257682681084, 0.01319876965135336, 0.029060106724500656, 0.04031303524971008, 0.02303694561123848, 0.050357893109321594, 0.046500690281391144, 0.03221074864268303, 0.04574137553572655, 0.011448166333138943, 0.05148479714989662, 0.0471622534096241, 0.0], [0.019862744957208633, 0.0006941378233022988, 0.0017670635133981705, 0.001903820433653891, 0.0023115784861147404, 0.059243880212306976, 0.005164954345673323, 0.008714546449482441, 0.0024906687904149294, 0.0030579601880162954, 0.07585158199071884, 0.0023905497509986162, 0.0031773506198078394, 0.08945124596357346, 0.003065296448767185, 0.0016209169989451766, 0.10312025249004364, 0.0625915676355362, 0.0020582969300448895, 0.0022322209551930428, 0.12742051482200623, 0.024703850969672203, 0.003510191338136792, 0.0049941809847950935, 0.028317134827375412, 0.005874201655387878, 0.00621532928198576, 0.03686566650867462, 0.005438116379082203, 0.004061868879944086, 0.004735518712550402, 0.0045343851670622826, 0.29255834221839905]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9726406335830688, 0.027359366416931152, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8850566744804382, 0.08160645514726639, 0.033336855471134186, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7844979166984558, 0.09045999497175217, 0.1072097048163414, 0.017832353711128235, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6679065823554993, 0.10135099291801453, 0.10997918248176575, 0.0699087455868721, 0.050854478031396866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.586279034614563, 0.06960931420326233, 0.06798023730516434, 0.06058963015675545, 0.08339764922857285, 0.13214410841464996, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5015711188316345, 0.06227874755859375, 0.07209988683462143, 0.05590919032692909, 0.08146876841783524, 0.12033167481422424, 0.10634061694145203, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40016093850135803, 0.05525398999452591, 0.0634768158197403, 0.05413787066936493, 0.07119617611169815, 0.11230532824993134, 0.12489722669124603, 0.11857165396213531, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.40185338258743286, 0.08579418808221817, 0.056448809802532196, 0.07181121408939362, 0.08318912237882614, 0.07845646888017654, 0.09191881865262985, 0.07768876105546951, 0.05283927917480469, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3827159106731415, 0.07976947724819183, 0.06207752227783203, 0.06360235065221786, 0.0821102038025856, 0.07804955542087555, 0.08597437292337418, 0.07506487518548965, 0.0632784441113472, 0.027357226237654686, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.34041672945022583, 0.045351963490247726, 0.04658910259604454, 0.040391698479652405, 0.05489042028784752, 0.08179009705781937, 0.08906516432762146, 0.09645896404981613, 0.05564970150589943, 0.06398676335811615, 0.08540938794612885, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31186187267303467, 0.09539998322725296, 0.07292012870311737, 0.0697687417268753, 0.07777827978134155, 0.06735040247440338, 0.06161407008767128, 0.05481074005365372, 0.052520133554935455, 0.050225213170051575, 0.07299349457025528, 0.01275696326047182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.36652860045433044, 0.06308673322200775, 0.039478451013565063, 0.04609527066349983, 0.05740750953555107, 0.0634833574295044, 0.0523846372961998, 0.05501618981361389, 0.04584016650915146, 0.062286920845508575, 0.0658990740776062, 0.05806361138820648, 0.024429505690932274, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28564438223838806, 0.038040269166231155, 0.03942389786243439, 0.03423863649368286, 0.046393975615501404, 0.06771664321422577, 0.0732807144522667, 0.07855430245399475, 0.047896645963191986, 0.055936548858881, 0.07124947011470795, 0.03568926081061363, 0.04956043139100075, 0.07637479901313782, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2977541983127594, 0.052595462650060654, 0.043479397892951965, 0.05845862999558449, 0.04568728804588318, 0.05259407311677933, 0.04456197842955589, 0.045974720269441605, 0.06316150724887848, 0.0776875913143158, 0.0549914613366127, 0.03466472774744034, 0.05020100250840187, 0.058861445635557175, 0.01932654157280922, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.28853145241737366, 0.046169113367795944, 0.028233064338564873, 0.038242388516664505, 0.043306220322847366, 0.05174916982650757, 0.043182745575904846, 0.04393119737505913, 0.05616341158747673, 0.06773821264505386, 0.05490176007151604, 0.08139307051897049, 0.04325690492987633, 0.05904814973473549, 0.03989904001355171, 0.014254072681069374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.23721367120742798, 0.03161582350730896, 0.03324566408991814, 0.02923194319009781, 0.038618121296167374, 0.05549168959259987, 0.05966498330235481, 0.06321782618761063, 0.040736984461545944, 0.0475267618894577, 0.05837821587920189, 0.03039967454969883, 0.042871568351984024, 0.06284618377685547, 0.05321291461586952, 0.04736899212002754, 0.06835904717445374, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20986966788768768, 0.027291269972920418, 0.03115660883486271, 0.026615019887685776, 0.03165113925933838, 0.052732281386852264, 0.05274500697851181, 0.056359004229307175, 0.040765464305877686, 0.04278238117694855, 0.056191232055425644, 0.030678272247314453, 0.04398960992693901, 0.06091475114226341, 0.0501369833946228, 0.041573166847229004, 0.06652859598398209, 0.07801954448223114, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2385382503271103, 0.04414580762386322, 0.04643506184220314, 0.0345127172768116, 0.0357218012213707, 0.04369329661130905, 0.04304973781108856, 0.03498825430870056, 0.04371807724237442, 0.03952197730541229, 0.04457853361964226, 0.024599453434348106, 0.0625118613243103, 0.047534845769405365, 0.04375609755516052, 0.04995930939912796, 0.05090804770588875, 0.052662450820207596, 0.019164472818374634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17729148268699646, 0.04221460595726967, 0.030818721279501915, 0.030886098742485046, 0.03386848792433739, 0.04521186277270317, 0.04290102794766426, 0.032215576618909836, 0.04018864780664444, 0.04926897585391998, 0.04801623895764351, 0.03814244642853737, 0.05126514658331871, 0.05206845700740814, 0.04744117707014084, 0.03924534469842911, 0.056304752826690674, 0.05462944135069847, 0.0599185973405838, 0.02810293436050415, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19048276543617249, 0.025203485041856766, 0.02678746171295643, 0.0236726775765419, 0.03110402822494507, 0.043453432619571686, 0.0464932881295681, 0.04820645600557327, 0.03323279321193695, 0.03892754390835762, 0.04549147188663483, 0.02444273605942726, 0.03570157289505005, 0.04907767102122307, 0.04303564131259918, 0.03905564546585083, 0.053717464208602905, 0.0665895864367485, 0.043208252638578415, 0.031764693558216095, 0.060351256281137466, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1497536301612854, 0.02347457781434059, 0.025508396327495575, 0.02894243597984314, 0.035171594470739365, 0.038801904767751694, 0.04594280570745468, 0.03962726891040802, 0.03708779439330101, 0.038723018020391464, 0.04190719500184059, 0.021688060835003853, 0.04328256845474243, 0.04592543840408325, 0.03893952816724777, 0.040076106786727905, 0.05060020089149475, 0.06083051487803459, 0.04372159391641617, 0.03023521788418293, 0.05728613957762718, 0.06247401982545853, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.17513407766819, 0.02751927822828293, 0.029513996094465256, 0.02071533352136612, 0.026873521506786346, 0.0345461405813694, 0.03853078559041023, 0.033037811517715454, 0.04181556776165962, 0.04010029882192612, 0.03696895390748978, 0.030468935146927834, 0.03995395451784134, 0.040237050503492355, 0.0448262095451355, 0.03708262741565704, 0.04420143738389015, 0.04931039363145828, 0.04125744104385376, 0.028610683977603912, 0.049973443150520325, 0.05269284546375275, 0.03662917762994766, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13285991549491882, 0.040708061307668686, 0.04111677035689354, 0.03484426438808441, 0.04087603837251663, 0.027567215263843536, 0.028293699026107788, 0.022520409896969795, 0.0387541726231575, 0.040378037840127945, 0.029089411720633507, 0.029609229415655136, 0.0567011795938015, 0.03118187189102173, 0.03766118362545967, 0.05688638985157013, 0.03396708145737648, 0.03781306371092796, 0.04951411113142967, 0.03194558247923851, 0.03759903088212013, 0.04326637089252472, 0.04305670037865639, 0.033790223300457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14709368348121643, 0.01821870729327202, 0.022143613547086716, 0.02162139117717743, 0.027072882279753685, 0.033854179084300995, 0.03787611424922943, 0.03801964595913887, 0.027932509779930115, 0.030901841819286346, 0.03606923297047615, 0.01902313157916069, 0.03465800732374191, 0.03916987031698227, 0.0337555930018425, 0.026136629283428192, 0.04297832027077675, 0.053137436509132385, 0.03463505208492279, 0.02014029212296009, 0.048783592879772186, 0.04990804195404053, 0.04624391719698906, 0.047156691551208496, 0.06346962600946426, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1760278344154358, 0.014882152900099754, 0.026751166209578514, 0.024088066071271896, 0.03566749021410942, 0.027094289660453796, 0.02498425543308258, 0.02147187851369381, 0.026359375566244125, 0.023845124989748, 0.027566984295845032, 0.016869543120265007, 0.077774278819561, 0.029109222814440727, 0.04799698665738106, 0.029002496972680092, 0.031323350965976715, 0.03615600988268852, 0.03959561139345169, 0.017008014023303986, 0.034839075058698654, 0.034437187016010284, 0.041492193937301636, 0.09124381840229034, 0.040522992610931396, 0.0038906014524400234, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.185017392039299, 0.027787020429968834, 0.02509763091802597, 0.027018999680876732, 0.029199205338954926, 0.030337022617459297, 0.032221779227256775, 0.023015081882476807, 0.026792852208018303, 0.02279384434223175, 0.030674848705530167, 0.021220846101641655, 0.053888075053691864, 0.0325930155813694, 0.030737662687897682, 0.025725245475769043, 0.034866053611040115, 0.03793581947684288, 0.028672004118561745, 0.026148973032832146, 0.03875334560871124, 0.04179506003856659, 0.038631584495306015, 0.053371548652648926, 0.03982074186205864, 0.025711605325341225, 0.010172725655138493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.12446325272321701, 0.016768906265497208, 0.020105108618736267, 0.01926703006029129, 0.024457808583974838, 0.030203362926840782, 0.03127392753958702, 0.03254605829715729, 0.023186001926660538, 0.02350839227437973, 0.031733188778162, 0.0170805174857378, 0.029082059860229492, 0.03428218513727188, 0.03579128533601761, 0.025820568203926086, 0.037531156092882156, 0.04618250951170921, 0.029500003904104233, 0.017913803458213806, 0.04274729639291763, 0.0424346923828125, 0.03900239244103432, 0.041418373584747314, 0.05949501320719719, 0.03595736250281334, 0.03098485991358757, 0.05726282671093941, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14491020143032074, 0.025843989104032516, 0.031176969408988953, 0.01946275681257248, 0.012575723230838776, 0.025274598971009254, 0.022020692005753517, 0.02126728743314743, 0.03165540471673012, 0.027664173394441605, 0.02625158056616783, 0.02209104597568512, 0.03851795569062233, 0.028266891837120056, 0.0288776196539402, 0.03686538711190224, 0.030699966475367546, 0.032045044004917145, 0.034116264432668686, 0.02035541832447052, 0.03446315973997116, 0.03542865067720413, 0.0307284165173769, 0.044418979436159134, 0.037935975939035416, 0.05734866112470627, 0.038896989077329636, 0.04111207276582718, 0.019728196784853935, 0.0, 0.0, 0.0, 0.0], [0.13168424367904663, 0.025460103526711464, 0.02796240895986557, 0.024109849706292152, 0.01686881110072136, 0.03140678629279137, 0.02324734255671501, 0.022071681916713715, 0.02736249938607216, 0.0263704601675272, 0.03204534202814102, 0.028775818645954132, 0.04614202305674553, 0.034559790045022964, 0.03132110834121704, 0.02943773753941059, 0.037490684539079666, 0.035974230617284775, 0.0306710172444582, 0.026778316125273705, 0.04166237264871597, 0.032743994146585464, 0.03034878335893154, 0.03265199810266495, 0.03805650770664215, 0.034575607627630234, 0.022936103865504265, 0.03690328449010849, 0.025966184213757515, 0.014414896257221699, 0.0, 0.0, 0.0], [0.1656370609998703, 0.022809257730841637, 0.029107756912708282, 0.024944674223661423, 0.024352876469492912, 0.02503182366490364, 0.018486667424440384, 0.018573671579360962, 0.02844364009797573, 0.029199935495853424, 0.0253182090818882, 0.03220498934388161, 0.025753291323781013, 0.026890527456998825, 0.03127394616603851, 0.0330515019595623, 0.028835462406277657, 0.029910437762737274, 0.0275588221848011, 0.024624653160572052, 0.032053619623184204, 0.026493774726986885, 0.02170960046350956, 0.03164015710353851, 0.037074778228998184, 0.04799467325210571, 0.027932140976190567, 0.034756116569042206, 0.03804945573210716, 0.02153567411005497, 0.008750852197408676, 0.0, 0.0], [0.16794218122959137, 0.025983478873968124, 0.032223377376794815, 0.019469384104013443, 0.02373526431620121, 0.023115742951631546, 0.019973624497652054, 0.016550235450267792, 0.02979678101837635, 0.02849465236067772, 0.023108845576643944, 0.02208707109093666, 0.04216556251049042, 0.024390194565057755, 0.020749149844050407, 0.03873588517308235, 0.02626980096101761, 0.02728910557925701, 0.019617388024926186, 0.020242856815457344, 0.029203204438090324, 0.03041335754096508, 0.02576262876391411, 0.040849797427654266, 0.0333266519010067, 0.021795306354761124, 0.026310516521334648, 0.03101348876953125, 0.0368926040828228, 0.01937716454267502, 0.04355604574084282, 0.009558666497468948, 0.0], [0.11396829038858414, 0.01775287464261055, 0.016061952337622643, 0.015585053712129593, 0.01839611865580082, 0.024367084726691246, 0.02605387754738331, 0.023999113589525223, 0.021919483318924904, 0.026251116767525673, 0.024730538949370384, 0.015323018655180931, 0.025614572688937187, 0.026337891817092896, 0.024982871487736702, 0.02464262768626213, 0.028590325266122818, 0.03295151889324188, 0.027568623423576355, 0.01848755031824112, 0.03220851346850395, 0.03191469609737396, 0.036307256668806076, 0.034154012799263, 0.03678558021783829, 0.03297772631049156, 0.026278894394636154, 0.038098905235528946, 0.02980194427073002, 0.018183257430791855, 0.036320678889751434, 0.03568095713853836, 0.057703081518411636]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8058414459228516, 0.19415856897830963, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.6373865008354187, 0.09672049432992935, 0.26589304208755493, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5870264768600464, 0.09922722727060318, 0.07913830876350403, 0.2346079796552658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4194737374782562, 0.06312594562768936, 0.08123067766427994, 0.08381503820419312, 0.35235464572906494, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5308531522750854, 0.0959072932600975, 0.07779338955879211, 0.06661548465490341, 0.07293295115232468, 0.15589767694473267, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.38503068685531616, 0.07478093355894089, 0.06978149712085724, 0.04760653153061867, 0.05144915729761124, 0.08776707202196121, 0.2835841774940491, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29629573225975037, 0.05328270047903061, 0.06944748759269714, 0.04097547382116318, 0.06660831719636917, 0.1021856889128685, 0.10869501531124115, 0.2625095844268799, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.304749995470047, 0.06337985396385193, 0.05753423646092415, 0.04057719185948372, 0.073001429438591, 0.07375828176736832, 0.07239888608455658, 0.05693604424595833, 0.25766411423683167, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.29880765080451965, 0.05552826076745987, 0.05443597584962845, 0.05285302549600601, 0.06568751484155655, 0.07554221898317337, 0.06968102604150772, 0.05411387234926224, 0.09120789170265198, 0.18214260041713715, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.26933014392852783, 0.06352431327104568, 0.05952122062444687, 0.05242469906806946, 0.060521576553583145, 0.12185832113027573, 0.07608655095100403, 0.09753073751926422, 0.04232607036828995, 0.05058327317237854, 0.10629311949014664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.22074297070503235, 0.06960076093673706, 0.048723477870225906, 0.06675716489553452, 0.06954211741685867, 0.06483785808086395, 0.046523746103048325, 0.0393008328974247, 0.018016090616583824, 0.0358063206076622, 0.05302286893129349, 0.26712581515312195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15080073475837708, 0.04732475057244301, 0.12551116943359375, 0.06240082532167435, 0.053546320647001266, 0.05578393489122391, 0.04542611911892891, 0.03888600692152977, 0.0301998108625412, 0.033370546996593475, 0.04645953327417374, 0.023437919095158577, 0.2868523597717285, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.20448839664459229, 0.04972049593925476, 0.048385459929704666, 0.04385358840227127, 0.05115717649459839, 0.1007489264011383, 0.06420684605836868, 0.08302560448646545, 0.038804519921541214, 0.047957729548215866, 0.09582381695508957, 0.03239700198173523, 0.04441104084253311, 0.0950193703174591, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16236735880374908, 0.028519175946712494, 0.04784310609102249, 0.041354820132255554, 0.040284886956214905, 0.05200536176562309, 0.04226505756378174, 0.03821169212460518, 0.059868812561035156, 0.06849399954080582, 0.047342803329229355, 0.019715171307325363, 0.06202229857444763, 0.045721933245658875, 0.24398350715637207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1312893182039261, 0.039628107100725174, 0.05951940640807152, 0.039663225412368774, 0.04406355321407318, 0.04348496347665787, 0.037265483289957047, 0.03240034729242325, 0.037205737084150314, 0.06481601297855377, 0.04047452658414841, 0.025914229452610016, 0.06507597863674164, 0.03922512009739876, 0.07744193822145462, 0.2225320190191269, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1581333875656128, 0.03911251574754715, 0.038564957678318024, 0.03587969020009041, 0.04187793657183647, 0.08161000907421112, 0.05245806649327278, 0.0681268647313118, 0.03444806858897209, 0.043427519500255585, 0.08275997638702393, 0.02933339774608612, 0.04157378897070885, 0.08478686958551407, 0.048816002905368805, 0.03235285356640816, 0.08673813939094543, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13890598714351654, 0.03169633075594902, 0.03251555934548378, 0.03538898751139641, 0.03800032287836075, 0.06974424421787262, 0.059424541890621185, 0.06768238544464111, 0.027843810617923737, 0.03905467316508293, 0.07273104041814804, 0.030109865590929985, 0.04163092002272606, 0.07565009593963623, 0.040188319981098175, 0.0274836216121912, 0.07795905321836472, 0.09399017691612244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09691289812326431, 0.03068731538951397, 0.030817965045571327, 0.044734321534633636, 0.04171942174434662, 0.03603677079081535, 0.04101703315973282, 0.03210476413369179, 0.043440625071525574, 0.04885552451014519, 0.03457901254296303, 0.016025086864829063, 0.04994165152311325, 0.0346352681517601, 0.06065686419606209, 0.03497787192463875, 0.03454342111945152, 0.037827931344509125, 0.25048622488975525, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1205921471118927, 0.04121064394712448, 0.05098516866564751, 0.05289152264595032, 0.028861289843916893, 0.047061994671821594, 0.029212825000286102, 0.03817001357674599, 0.021046485751867294, 0.029787804931402206, 0.04406720772385597, 0.026503335684537888, 0.04127003625035286, 0.044307366013526917, 0.030801547691226006, 0.04064902290701866, 0.04474509507417679, 0.042122453451156616, 0.028442276641726494, 0.1972716897726059, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11388303339481354, 0.028255395591259003, 0.028351297602057457, 0.026958664879202843, 0.03131084889173508, 0.05977548286318779, 0.0391821414232254, 0.050720393657684326, 0.027684012427926064, 0.035564228892326355, 0.06452133506536484, 0.024267081171274185, 0.03616494685411453, 0.06838167458772659, 0.04139300435781479, 0.0290946364402771, 0.072300486266613, 0.07349380105733871, 0.03700019791722298, 0.0352863147854805, 0.0764109417796135, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0845385268330574, 0.017416616901755333, 0.018949147313833237, 0.016560645774006844, 0.02229611948132515, 0.04174060747027397, 0.05894865095615387, 0.03893361985683441, 0.030214643105864525, 0.03464234247803688, 0.0483190156519413, 0.016358427703380585, 0.02567455731332302, 0.05309674143791199, 0.020546523854136467, 0.02046983689069748, 0.05704639106988907, 0.06604910641908646, 0.037746451795101166, 0.021413881331682205, 0.06129930540919304, 0.20773881673812866, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1124844029545784, 0.024394849315285683, 0.024523165076971054, 0.02748955972492695, 0.02610466443002224, 0.03731505572795868, 0.06748531758785248, 0.03890376165509224, 0.017981436103582382, 0.028454389423131943, 0.03756532818078995, 0.018326066434383392, 0.02008865401148796, 0.03865170478820801, 0.0232856422662735, 0.02422662265598774, 0.03960612043738365, 0.048331890255212784, 0.04500093683600426, 0.01736215129494667, 0.04009140655398369, 0.05208286643028259, 0.19024400413036346, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08183357119560242, 0.019828449934720993, 0.026873398572206497, 0.029252557083964348, 0.02518444135785103, 0.03192773088812828, 0.029049793258309364, 0.024972522631287575, 0.03350626677274704, 0.04007429629564285, 0.033517319709062576, 0.01603599451482296, 0.032044555991888046, 0.03448064252734184, 0.028517091646790504, 0.03532731533050537, 0.035832274705171585, 0.040583960711956024, 0.029941106215119362, 0.02109791710972786, 0.03671329468488693, 0.039212584495544434, 0.03543241694569588, 0.23876051604747772, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10145693272352219, 0.014237052761018276, 0.016984183341264725, 0.018636569380760193, 0.0285362359136343, 0.036538027226924896, 0.02957051806151867, 0.04198319837450981, 0.014166045002639294, 0.030081413686275482, 0.04016641154885292, 0.02007502317428589, 0.030370105057954788, 0.04353440925478935, 0.030393030494451523, 0.020717334002256393, 0.0467711016535759, 0.0549510195851326, 0.02880917303264141, 0.020043687894940376, 0.050925418734550476, 0.04084465652704239, 0.041858021169900894, 0.038489777594804764, 0.15986067056655884, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07937925308942795, 0.020674321800470352, 0.020799757912755013, 0.027988232672214508, 0.04565475508570671, 0.026562588289380074, 0.02539670839905739, 0.021243257448077202, 0.017763793468475342, 0.02520063705742359, 0.027576463297009468, 0.030607089400291443, 0.034379992634058, 0.028568314388394356, 0.022726934403181076, 0.01605195179581642, 0.0297127403318882, 0.03276180848479271, 0.025702400133013725, 0.012878884561359882, 0.030626125633716583, 0.020369650796055794, 0.03741392120718956, 0.027850383892655373, 0.03571850806474686, 0.27639153599739075, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.09605435281991959, 0.02309289015829563, 0.024199651554226875, 0.024974137544631958, 0.0368296355009079, 0.030014393851161003, 0.02106921188533306, 0.018117522820830345, 0.022569257766008377, 0.02834322303533554, 0.030505135655403137, 0.021707670763134956, 0.02821178175508976, 0.03163941577076912, 0.03916612267494202, 0.03627365455031395, 0.03311571106314659, 0.03514396399259567, 0.02574523165822029, 0.015889007598161697, 0.03467545658349991, 0.026770077645778656, 0.0271434485912323, 0.040450792759656906, 0.037603847682476044, 0.03232335299253464, 0.17837105691432953, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.07476940751075745, 0.011021518148481846, 0.010706564411520958, 0.015325456857681274, 0.01990356110036373, 0.032858677208423615, 0.021936073899269104, 0.029454147443175316, 0.01642150804400444, 0.022476593032479286, 0.03722343593835831, 0.01758023537695408, 0.021954143419861794, 0.04046213626861572, 0.031415410339832306, 0.010417782701551914, 0.044297393411397934, 0.051181256771087646, 0.029565563425421715, 0.015394337475299835, 0.04906425252556801, 0.032021939754486084, 0.030905118212103844, 0.04132053256034851, 0.06578274071216583, 0.03978404402732849, 0.0204996969550848, 0.16625647246837616, 0.0, 0.0, 0.0, 0.0, 0.0], [0.051242049783468246, 0.01139003038406372, 0.020265808328986168, 0.02452964521944523, 0.12732438743114471, 0.02008391171693802, 0.017692742869257927, 0.020381985232234, 0.018548613414168358, 0.023206070065498352, 0.021026063710451126, 0.02052122913300991, 0.025210734456777573, 0.021994246169924736, 0.01719047501683235, 0.02080591209232807, 0.023035312071442604, 0.02645805850625038, 0.031086131930351257, 0.011454468593001366, 0.024357985705137253, 0.02252495288848877, 0.02460077591240406, 0.024588007479906082, 0.028380820527672768, 0.04660611227154732, 0.04362708330154419, 0.020300468429923058, 0.21156594157218933, 0.0, 0.0, 0.0, 0.0], [0.07929296046495438, 0.023537393659353256, 0.022847291082143784, 0.01993604190647602, 0.015462877228856087, 0.025110293179750443, 0.02142905257642269, 0.015073494985699654, 0.009924094192683697, 0.015724753960967064, 0.027188703417778015, 0.020747290924191475, 0.03497635945677757, 0.02910233475267887, 0.021219035610556602, 0.01814761757850647, 0.031058188527822495, 0.03380950540304184, 0.020137561485171318, 0.012323117814958096, 0.0336926244199276, 0.024336127564311028, 0.031084522604942322, 0.03377701714634895, 0.043554436415433884, 0.032963529229164124, 0.03314928337931633, 0.025364909321069717, 0.02216368541121483, 0.22286593914031982, 0.0, 0.0, 0.0], [0.10059653967618942, 0.03096376359462738, 0.025578510016202927, 0.020224066451191902, 0.027132989838719368, 0.0294907595962286, 0.0407448410987854, 0.021403610706329346, 0.016392601653933525, 0.02252068743109703, 0.02755517140030861, 0.013599206693470478, 0.027306709438562393, 0.027806580066680908, 0.011214185506105423, 0.023586537688970566, 0.02839917689561844, 0.030668916180729866, 0.021664205938577652, 0.017032310366630554, 0.02905159443616867, 0.026549924165010452, 0.032975535839796066, 0.026790330186486244, 0.0320606529712677, 0.02729833498597145, 0.017307177186012268, 0.01876881904900074, 0.028226524591445923, 0.017085103318095207, 0.18000467121601105, 0.0, 0.0], [0.08361604809761047, 0.016581891104578972, 0.015823306515812874, 0.02200516313314438, 0.02406255155801773, 0.021028298884630203, 0.022811299189925194, 0.014412397518754005, 0.01557208877056837, 0.01510483305901289, 0.020917732268571854, 0.021798159927129745, 0.02598598226904869, 0.022013207897543907, 0.02202506922185421, 0.018091216683387756, 0.02311510033905506, 0.025451799854636192, 0.025943521410226822, 0.011241882108151913, 0.02446616441011429, 0.02286989986896515, 0.03161344677209854, 0.029542677104473114, 0.02381790615618229, 0.029349012300372124, 0.025922654196619987, 0.017268184572458267, 0.0318446047604084, 0.012037733569741249, 0.027524923905730247, 0.2561412453651428, 0.0], [0.05258442088961601, 0.012508383952081203, 0.01273767463862896, 0.012144193984568119, 0.014467819593846798, 0.024812452495098114, 0.01710914634168148, 0.025162572041153908, 0.016298966482281685, 0.015160084702074528, 0.029820043593645096, 0.014290272258222103, 0.024094797670841217, 0.033742766827344894, 0.02163226716220379, 0.018924107775092125, 0.03819217160344124, 0.041151825338602066, 0.024165771901607513, 0.020635638386011124, 0.044185325503349304, 0.03793709725141525, 0.02963634766638279, 0.03152840584516525, 0.045423079282045364, 0.03596360236406326, 0.030482526868581772, 0.04609914869070053, 0.03206764906644821, 0.017662938684225082, 0.03169601410627365, 0.044629115611314774, 0.10305341333150864]], [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7707713842391968, 0.22922858595848083, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.7813623547554016, 0.10978526622056961, 0.108852319419384, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5350390076637268, 0.11194941401481628, 0.15013688802719116, 0.20287469029426575, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.41803574562072754, 0.1603638082742691, 0.10740301758050919, 0.10625778138637543, 0.20793955028057098, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.4349866509437561, 0.0957985520362854, 0.08251801133155823, 0.10028504580259323, 0.15332908928394318, 0.13308262825012207, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.44621357321739197, 0.05624215304851532, 0.05040297284722328, 0.07084295153617859, 0.09360909461975098, 0.11472619324922562, 0.16796308755874634, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.3609195649623871, 0.07294464856386185, 0.05191003903746605, 0.07159044593572617, 0.09321669489145279, 0.09543666243553162, 0.14539919793605804, 0.10858277231454849, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.31714072823524475, 0.07683128863573074, 0.0555228516459465, 0.06445364654064178, 0.08586592227220535, 0.10643254220485687, 0.145211324095726, 0.09439336508512497, 0.05414833128452301, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19288603961467743, 0.11343871057033539, 0.04530506581068039, 0.08361203968524933, 0.057632721960544586, 0.11914195865392685, 0.11441230773925781, 0.12364514917135239, 0.07640960812568665, 0.07351641356945038, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.25174087285995483, 0.06019410863518715, 0.049302082508802414, 0.05922326445579529, 0.08453336358070374, 0.07307681441307068, 0.12308555841445923, 0.08293969184160233, 0.06380271911621094, 0.07185839116573334, 0.08024311810731888, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2479359656572342, 0.048557721078395844, 0.061716966331005096, 0.06616785377264023, 0.0878860279917717, 0.05920383706688881, 0.09128588438034058, 0.06866814941167831, 0.060628656297922134, 0.08399353921413422, 0.0656941756606102, 0.05826116353273392, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15039604902267456, 0.0707230269908905, 0.03618801385164261, 0.03812884911894798, 0.054965753108263016, 0.09552794694900513, 0.1278020292520523, 0.09101752936840057, 0.04133947566151619, 0.06619425117969513, 0.11493084579706192, 0.03526816889643669, 0.0775180459022522, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21730749309062958, 0.0522487573325634, 0.042796868830919266, 0.051309894770383835, 0.070210762321949, 0.06084863469004631, 0.10094166547060013, 0.06729137897491455, 0.05347270518541336, 0.05803246423602104, 0.06386599689722061, 0.04143684729933739, 0.05429811030626297, 0.06593846529722214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14158986508846283, 0.08735613524913788, 0.0410962738096714, 0.07771319895982742, 0.06641592085361481, 0.060846131294965744, 0.07890864461660385, 0.0646718218922615, 0.041567541658878326, 0.05314025282859802, 0.06033195182681084, 0.04990347474813461, 0.06147687882184982, 0.06152058765292168, 0.05346131697297096, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277391016483307, 0.051402706652879715, 0.03480072692036629, 0.04410994052886963, 0.049271054565906525, 0.08066023141145706, 0.09371129423379898, 0.07634276151657104, 0.03460072726011276, 0.0555649995803833, 0.09000369906425476, 0.02795092575252056, 0.05808687210083008, 0.09759879112243652, 0.058530546724796295, 0.03459078073501587, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19136790931224823, 0.04588799551129341, 0.037184182554483414, 0.04478847235441208, 0.05845542252063751, 0.0516231432557106, 0.08451797068119049, 0.05661727115511894, 0.04477925971150398, 0.04681588336825371, 0.05177520960569382, 0.034743111580610275, 0.043655913323163986, 0.052577536553144455, 0.04571910947561264, 0.055239398032426834, 0.05425221472978592, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1780986338853836, 0.03651318699121475, 0.03537803143262863, 0.04660060629248619, 0.05606747046113014, 0.055425312370061874, 0.06580902636051178, 0.05869591236114502, 0.04460206627845764, 0.0384533517062664, 0.05522070452570915, 0.028129274025559425, 0.038876283913850784, 0.05635210499167442, 0.04307204484939575, 0.04859212785959244, 0.05801298841834068, 0.05610084533691406, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.11277125775814056, 0.044163405895233154, 0.016790850088000298, 0.03922898322343826, 0.030570246279239655, 0.08429381996393204, 0.058298323303461075, 0.07985575497150421, 0.027740230783820152, 0.024607930332422256, 0.0856802761554718, 0.012135535478591919, 0.021223613992333412, 0.08979953825473785, 0.02439563162624836, 0.018000084906816483, 0.0979786142706871, 0.08564861863851547, 0.04681730270385742, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15648673474788666, 0.04359336942434311, 0.02946913242340088, 0.02338279038667679, 0.039893947541713715, 0.06601446866989136, 0.07239893823862076, 0.04959877207875252, 0.025720084086060524, 0.028729893267154694, 0.07268747687339783, 0.02010437659919262, 0.03894991800189018, 0.07793489843606949, 0.031850170344114304, 0.029572609812021255, 0.08162926882505417, 0.04983030632138252, 0.04757082462310791, 0.014582022093236446, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16675153374671936, 0.040216755121946335, 0.03194625675678253, 0.03915555030107498, 0.048679765313863754, 0.04351935535669327, 0.07027735561132431, 0.04676977917551994, 0.037370454519987106, 0.03785952180624008, 0.04185349866747856, 0.029438789933919907, 0.03496701642870903, 0.04187152907252312, 0.0366595983505249, 0.044189490377902985, 0.042446985840797424, 0.04309000074863434, 0.05540825054049492, 0.02402997389435768, 0.04349849000573158, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.21311698853969574, 0.034521471709012985, 0.026512043550610542, 0.03728468343615532, 0.042002324014902115, 0.05378073453903198, 0.06410718709230423, 0.040195900946855545, 0.029513955116271973, 0.030562082305550575, 0.0481405034661293, 0.01964574120938778, 0.023855973035097122, 0.04712359234690666, 0.027805238962173462, 0.025632815435528755, 0.04690322279930115, 0.042115021497011185, 0.04245338961482048, 0.016209978610277176, 0.04720154032111168, 0.04131560027599335, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.16099101305007935, 0.03149211406707764, 0.025506004691123962, 0.032036278396844864, 0.0381193645298481, 0.05386464670300484, 0.052892014384269714, 0.06297368556261063, 0.03872942551970482, 0.030703028663992882, 0.04861500486731529, 0.016964141279459, 0.020984867587685585, 0.04743489623069763, 0.02617856301367283, 0.03281702846288681, 0.04874100536108017, 0.03702306002378464, 0.05028446391224861, 0.014425937086343765, 0.04926920309662819, 0.027485152706503868, 0.052469104528427124, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13924188911914825, 0.047321975231170654, 0.02292008139193058, 0.03782675787806511, 0.03733159974217415, 0.05628197267651558, 0.06773107498884201, 0.0638374611735344, 0.028824562206864357, 0.02836860716342926, 0.05008407682180405, 0.014775186777114868, 0.021058905869722366, 0.04819711670279503, 0.017685122787952423, 0.01545623131096363, 0.04842798784375191, 0.03709953650832176, 0.04247325286269188, 0.018426822498440742, 0.048613280057907104, 0.022673960775136948, 0.05998953804373741, 0.025352967903017998, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.19562353193759918, 0.03233326971530914, 0.022874077782034874, 0.03839076682925224, 0.03449878841638565, 0.04616907238960266, 0.05553750321269035, 0.03960668668150902, 0.023098398000001907, 0.024249300360679626, 0.04043306037783623, 0.016078554093837738, 0.02162494696676731, 0.03903057053685188, 0.02652089111506939, 0.028113434091210365, 0.038236308842897415, 0.03542611375451088, 0.041745733469724655, 0.021097134798765182, 0.03767954558134079, 0.03728693351149559, 0.04423920810222626, 0.02292151190340519, 0.03718467801809311, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.058196526020765305, 0.038897398859262466, 0.02600524015724659, 0.023567896336317062, 0.022979984059929848, 0.05384150892496109, 0.05806104466319084, 0.06858770549297333, 0.037459831684827805, 0.029159100726246834, 0.05474673584103584, 0.01359295379370451, 0.02764704078435898, 0.055754028260707855, 0.030779872089624405, 0.01613735593855381, 0.05745426192879677, 0.03968729451298714, 0.03406553342938423, 0.013110975734889507, 0.059776559472084045, 0.0160437673330307, 0.029699286445975304, 0.0205665472894907, 0.08347288519144058, 0.03070860542356968, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15561480820178986, 0.03032318875193596, 0.02106756903231144, 0.038600414991378784, 0.025089256465435028, 0.0471951924264431, 0.04255649447441101, 0.05166257917881012, 0.030368098989129066, 0.02013363502919674, 0.042556967586278915, 0.018511783331632614, 0.01867171935737133, 0.041430287063121796, 0.022022126242518425, 0.02106102555990219, 0.04166616499423981, 0.02724921703338623, 0.040481600910425186, 0.015536419115960598, 0.042196210473775864, 0.01700734533369541, 0.06220948323607445, 0.015703167766332626, 0.05443187057971954, 0.04092409089207649, 0.015729229897260666, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15218868851661682, 0.032320477068424225, 0.026277612894773483, 0.03215136006474495, 0.037080537527799606, 0.038433343172073364, 0.042185213416814804, 0.034409210085868835, 0.02929617650806904, 0.02475227601826191, 0.03461231663823128, 0.021795090287923813, 0.023419685661792755, 0.03386645019054413, 0.02858060598373413, 0.03440326824784279, 0.03315696492791176, 0.026710402220487595, 0.04213567078113556, 0.019021354615688324, 0.0327858105301857, 0.026840008795261383, 0.03304455056786537, 0.02330264262855053, 0.03390033543109894, 0.03944925218820572, 0.021334245800971985, 0.04254644364118576, 0.0, 0.0, 0.0, 0.0, 0.0], [0.10210391879081726, 0.048305340111255646, 0.027957914397120476, 0.028134850785136223, 0.043688926845788956, 0.037659600377082825, 0.04012180492281914, 0.035895805805921555, 0.02449178323149681, 0.01976804807782173, 0.034674081951379776, 0.01543145440518856, 0.032616548240184784, 0.03414340317249298, 0.027461383491754532, 0.020323211327195168, 0.034458402544260025, 0.015827571973204613, 0.030705831944942474, 0.020360933616757393, 0.03558044880628586, 0.034790292382240295, 0.03518148139119148, 0.02857261151075363, 0.043333832174539566, 0.03896389529109001, 0.01758768782019615, 0.045533787459135056, 0.04632510244846344, 0.0, 0.0, 0.0, 0.0], [0.11841738224029541, 0.026689784601330757, 0.028547639027237892, 0.03516455739736557, 0.03519093990325928, 0.030704868957400322, 0.04254688322544098, 0.023103512823581696, 0.025463126599788666, 0.02967854216694832, 0.028395213186740875, 0.019178252667188644, 0.023833580315113068, 0.027640027925372124, 0.03381752967834473, 0.0396401472389698, 0.027574418112635612, 0.021856175735592842, 0.03966764360666275, 0.039418332278728485, 0.027115609496831894, 0.030498076230287552, 0.03493282571434975, 0.0323205403983593, 0.027840545400977135, 0.03877577185630798, 0.021124785766005516, 0.038611430674791336, 0.03277180716395378, 0.01947997324168682, 0.0, 0.0, 0.0], [0.054337915033102036, 0.019247831776738167, 0.011686460115015507, 0.014118606224656105, 0.013909782283008099, 0.057368069887161255, 0.034546371549367905, 0.04665059223771095, 0.013026447966694832, 0.013271293602883816, 0.059527769684791565, 0.009063140489161015, 0.01736419089138508, 0.061355650424957275, 0.012634651735424995, 0.015145537443459034, 0.06425534933805466, 0.04627063125371933, 0.019556360319256783, 0.012543458491563797, 0.06913556903600693, 0.034823689609766006, 0.030005957931280136, 0.012261825613677502, 0.07985592633485794, 0.018996428698301315, 0.010722920298576355, 0.08654540777206421, 0.017174089327454567, 0.02214415743947029, 0.02245396189391613, 0.0, 0.0], [0.05849645286798477, 0.03437736630439758, 0.013603093102574348, 0.02417043410241604, 0.01900586113333702, 0.0654640644788742, 0.030622955411672592, 0.03573206439614296, 0.01885944977402687, 0.012241488322615623, 0.0628219023346901, 0.011835751123726368, 0.009552357718348503, 0.06431795656681061, 0.02158958464860916, 0.010912975296378136, 0.06665908545255661, 0.023997467011213303, 0.02659674920141697, 0.006153558846563101, 0.06984329968690872, 0.037238702178001404, 0.03004671074450016, 0.021686825901269913, 0.04364059865474701, 0.021209610626101494, 0.013490451499819756, 0.04632723331451416, 0.02043449878692627, 0.013362252153456211, 0.018568983301520348, 0.04714025929570198, 0.0], [0.1352868676185608, 0.029733378440141678, 0.02611132338643074, 0.03753575310111046, 0.0388815812766552, 0.0331667922437191, 0.048243895173072815, 0.03046831302344799, 0.026038208976387978, 0.02412370778620243, 0.027892740443348885, 0.02270994521677494, 0.02418527938425541, 0.026114562526345253, 0.023209672421216965, 0.02517528645694256, 0.024614781141281128, 0.021123159676790237, 0.029685042798519135, 0.018167469650506973, 0.023064401000738144, 0.02059808000922203, 0.034411393105983734, 0.021083397790789604, 0.02253883332014084, 0.0322815477848053, 0.01398724876344204, 0.024144932627677917, 0.027002297341823578, 0.012929441407322884, 0.03616536781191826, 0.02684023603796959, 0.032485030591487885]]]}\n",
              "    )\n",
              "    </script>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "print(\"Layer 0 Head Attention Patterns:\")\n",
        "cv.attention.attention_patterns(tokens=gpt2_str_tokens, attention=attention_pattern)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVTS6Q9Mxw6I"
      },
      "source": [
        "## Hooks: Intervening on Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mx5i_Qx6xw6I"
      },
      "source": [
        "One of the great things about interpreting neural networks is that we have *full control* over our system. From a computational perspective, we know exactly what operations are going on inside (even if we don't know what they mean!). And we can make precise, surgical edits and see how the model's behaviour and other internals change. This is an extremely powerful tool, because it can let us eg set up careful counterfactuals and causal intervention to easily understand model behaviour.\n",
        "\n",
        "Accordingly, being able to do this is a pretty core operation, and this is one of the main things TransformerLens supports! The key feature here is **hook points**. Every activation inside the transformer is surrounded by a hook point, which allows us to edit or intervene on it.\n",
        "\n",
        "We do this by adding a **hook function** to that activation. The hook function maps `current_activation_value, hook_point` to `new_activation_value`. As the model is run, it computes that activation as normal, and then the hook function is applied to compute a replacement, and that is substituted in for the activation. The hook function can be an arbitrary Python function, so long as it returns a tensor of the correct shape.\n",
        "\n",
        "<details><summary>Relationship to PyTorch hooks</summary>\n",
        "\n",
        "[PyTorch hooks](https://blog.paperspace.com/pytorch-hooks-gradient-clipping-debugging/) are a great and underrated, yet incredibly janky, feature. They can act on a layer, and edit the input or output of that layer, or the gradient when applying autodiff. The key difference is that **Hook points** act on *activations* not layers. This means that you can intervene within a layer on each activation, and don't need to care about the precise layer structure of the transformer. And it's immediately clear exactly how the hook's effect is applied. This adjustment was shamelessly inspired by [Garcon's use of ProbePoints](https://transformer-circuits.pub/2021/garcon/index.html).\n",
        "\n",
        "They also come with a range of other quality of life improvements, like the model having a `model.reset_hooks()` method to remove all hooks, or helper methods to temporarily add hooks for a single forward pass - it is *incredibly* easy to shoot yourself in the foot with standard PyTorch hooks!\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBo0cGlNxw6I"
      },
      "source": [
        "As a basic example, let's [ablate](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=fh-HJyz1CgUVrXuoiban6bYx) head 7 in layer 0 on the text above.\n",
        "\n",
        "We define a `head_ablation_hook` function. This takes the value tensor for attention layer 0, and sets the component with `head_index==7` to zero and returns it (Note - we return by convention, but since we're editing the activation in-place, we don't strictly *need* to).\n",
        "\n",
        "We then use the `run_with_hooks` helper function to run the model and *temporarily* add in the hook for just this run. We enter in the hook as a tuple of the activation name (also the hook point name - found with `utils.get_act_name`) and the hook function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "pp3JQYv3xw6J",
        "outputId": "aad52266-a258-48d8-c3a0-3d3de3dd5a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of the value tensor: torch.Size([1, 33, 12, 64])\n",
            "Original Loss: 3.999\n",
            "Ablated Loss: 5.453\n"
          ]
        }
      ],
      "source": [
        "layer_to_ablate = 0\n",
        "head_index_to_ablate = 8\n",
        "\n",
        "# We define a head ablation hook\n",
        "# The type annotations are NOT necessary, they're just a useful guide to the reader\n",
        "#\n",
        "def head_ablation_hook(\n",
        "    value: Float[torch.Tensor, \"batch pos head_index d_head\"],\n",
        "    hook: HookPoint\n",
        ") -> Float[torch.Tensor, \"batch pos head_index d_head\"]:\n",
        "    print(f\"Shape of the value tensor: {value.shape}\")\n",
        "    value[:, :, head_index_to_ablate, :] = 0.\n",
        "    return value\n",
        "\n",
        "original_loss = model(gpt2_tokens, return_type=\"loss\")\n",
        "ablated_loss = model.run_with_hooks(\n",
        "    gpt2_tokens,\n",
        "    return_type=\"loss\",\n",
        "    fwd_hooks=[(\n",
        "        utils.get_act_name(\"v\", layer_to_ablate),\n",
        "        head_ablation_hook\n",
        "        )]\n",
        "    )\n",
        "print(f\"Original Loss: {original_loss.item():.3f}\")\n",
        "print(f\"Ablated Loss: {ablated_loss.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MY57YbSDxw6J"
      },
      "source": [
        "**Gotcha:** Hooks are global state - they're added in as part of the model, and stay there until removed. `run_with_hooks` tries to create an abstraction where these are local state, by removing all hooks at the end of the function. But you can easily shoot yourself in the foot if there's, eg, an error in one of your hooks so the function never finishes. If you start getting bugs, try `model.reset_hooks()` to clean things up. Further, if you *do* add hooks of your own that you want to keep, which you can do with `add_perma_hook` on the relevant HookPoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mR6Zf_Hqxw6K"
      },
      "source": [
        "### Activation Patching on the Indirect Object Identification Task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu0PJzdHxw6K"
      },
      "source": [
        "For a somewhat more involved example, let's use hooks to apply **[activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** on the **[Indirect Object Identification](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=iWsV3s5Kdd2ca3zNgXr5UPHa)** (IOI) task.\n",
        "\n",
        "The IOI task is the task of identifying that a sentence like \"After John and Mary went to the store, Mary gave a bottle of milk to\" continues with \" John\" rather than \" Mary\" (ie, finding the indirect object), and Redwood Research have [an excellent paper studying the underlying circuit in GPT-2 Small](https://arxiv.org/abs/2211.00593).\n",
        "\n",
        "**[Activation patching](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=qeWBvs-R-taFfcCq-S_hgMqx)** is a technique from [Kevin Meng and David Bau's excellent ROME paper](https://rome.baulab.info/). The goal is to identify which model activations are important for completing a task. We do this by setting up a **clean prompt** and a **corrupted prompt** and a **metric** for performance on the task. We then pick a specific model activation, run the model on the corrupted prompt, but then *intervene* on that activation and patch in its value when run on the clean prompt. We then apply the metric, and see how much this patch has recovered the clean performance.\n",
        "(See [a more detailed demonstration of activation patching here](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/demos/Exploratory_Analysis_Demo.ipynb))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PB4AFAIExw6K"
      },
      "source": [
        "Here, our clean prompt is \"After John and Mary went to the store, **Mary** gave a bottle of milk to\", our corrupted prompt is \"After John and Mary went to the store, **John** gave a bottle of milk to\", and our metric is the difference between the correct logit ( John) and the incorrect logit ( Mary) on the final token.\n",
        "\n",
        "We see that the logit difference is significantly positive on the clean prompt, and significantly negative on the corrupted prompt, showing that the model is capable of doing the task!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FHvRNquKxw6L",
        "outputId": "746f01d4-f978-42c7-ab4e-e6f6612711eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clean logit difference: 4.276\n",
            "Corrupted logit difference: -2.738\n"
          ]
        }
      ],
      "source": [
        "clean_prompt = \"After John and Mary went to the store, Mary gave a bottle of milk to\"\n",
        "corrupted_prompt = \"After John and Mary went to the store, John gave a bottle of milk to\"\n",
        "\n",
        "clean_tokens = model.to_tokens(clean_prompt)\n",
        "corrupted_tokens = model.to_tokens(corrupted_prompt)\n",
        "\n",
        "def logits_to_logit_diff(logits, correct_answer=\" John\", incorrect_answer=\" Mary\"):\n",
        "    # model.to_single_token maps a string value of a single token to the token index for that token\n",
        "    # If the string is not a single token, it raises an error.\n",
        "    correct_index = model.to_single_token(correct_answer)\n",
        "    incorrect_index = model.to_single_token(incorrect_answer)\n",
        "    return logits[0, -1, correct_index] - logits[0, -1, incorrect_index]\n",
        "\n",
        "# We run on the clean prompt with the cache so we store activations to patch in later.\n",
        "clean_logits, clean_cache = model.run_with_cache(clean_tokens)\n",
        "clean_logit_diff = logits_to_logit_diff(clean_logits)\n",
        "print(f\"Clean logit difference: {clean_logit_diff.item():.3f}\")\n",
        "\n",
        "# We don't need to cache on the corrupted prompt.\n",
        "corrupted_logits = model(corrupted_tokens)\n",
        "corrupted_logit_diff = logits_to_logit_diff(corrupted_logits)\n",
        "print(f\"Corrupted logit difference: {corrupted_logit_diff.item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xa55CcWmxw6L"
      },
      "source": [
        "We now setup the hook function to do activation patching. Here, we'll patch in the [residual stream](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=DHp9vZ0h9lA9OCrzG2Y3rrzH) at the start of a specific layer and at a specific position. This will let us see how much the model is using the residual stream at that layer and position to represent the key information for the task.\n",
        "\n",
        "We want to iterate over all layers and positions, so we write the hook to take in an position parameter. Hook functions must have the input signature (activation, hook), but we can use `functools.partial` to set the position parameter before passing it to `run_with_hooks`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PZApBM59xw6M",
        "outputId": "7016192a-47de-4ac3-e98d-7d789f93df3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "ac7606cb16bf44559715f401eeaf7c2e",
            "36f4233a7b9148aaa19bdde280fa36de",
            "44f2bb66fd344523b70bf9763af47b9c",
            "bfa4c8b8bc39427399873df843c5f252",
            "eab9ede2e2a646e5aadc70d98b57b978",
            "984890a40a62468d850aeec8a1f96b94",
            "f0be004de1504e529cdb3fe30013bab8",
            "a6007cab1c704b2a805a9e8e7214187e",
            "945b70c9bbee4fc0a2c3afc914b3e297",
            "12e3bd8f408c4d98bae34f54da9a7c0a",
            "7487cacba3524818b479bac823036791"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/12 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac7606cb16bf44559715f401eeaf7c2e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# We define a residual stream patching hook\n",
        "# We choose to act on the residual stream at the start of the layer, so we call it resid_pre\n",
        "# The type annotations are a guide to the reader and are not necessary\n",
        "def residual_stream_patching_hook(\n",
        "    resid_pre: Float[torch.Tensor, \"batch pos d_model\"],\n",
        "    hook: HookPoint,\n",
        "    position: int\n",
        ") -> Float[torch.Tensor, \"batch pos d_model\"]:\n",
        "    # Each HookPoint has a name attribute giving the name of the hook.\n",
        "    clean_resid_pre = clean_cache[hook.name]\n",
        "    resid_pre[:, position, :] = clean_resid_pre[:, position, :]\n",
        "    return resid_pre\n",
        "\n",
        "# We make a tensor to store the results for each patching run. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "num_positions = len(clean_tokens[0])\n",
        "ioi_patching_result = torch.zeros((model.cfg.n_layers, num_positions), device=model.cfg.device)\n",
        "\n",
        "for layer in tqdm.tqdm(range(model.cfg.n_layers)):\n",
        "    for position in range(num_positions):\n",
        "        # Use functools.partial to create a temporary hook function with the position fixed\n",
        "        temp_hook_fn = partial(residual_stream_patching_hook, position=position)\n",
        "        # Run the model with the patching hook\n",
        "        patched_logits = model.run_with_hooks(corrupted_tokens, fwd_hooks=[\n",
        "            (utils.get_act_name(\"resid_pre\", layer), temp_hook_fn)\n",
        "        ])\n",
        "        # Calculate the logit difference\n",
        "        patched_logit_diff = logits_to_logit_diff(patched_logits).detach()\n",
        "        # Store the result, normalizing by the clean and corrupted logit difference so it's between 0 and 1 (ish)\n",
        "        ioi_patching_result[layer, position] = (patched_logit_diff - corrupted_logit_diff)/(clean_logit_diff - corrupted_logit_diff)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tSQffuexw6M"
      },
      "source": [
        "We can now visualize the results, and see that this computation is extremely localised within the model. Initially, the second subject (Mary) token is all that matters (naturally, as it's the only different token), and all relevant information remains here until heads in layer 7 and 8 move this to the final token where it's used to predict the indirect object.\n",
        "(Note - the heads are in layer 7 and 8, not 8 and 9, because we patched in the residual stream at the *start* of each layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "PfQqeQPGxw6M",
        "outputId": "50406b42-fc5e-440a-939f-935e31b650b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"e9b1a391-b00b-4f7a-b96a-3f8d0c049add\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e9b1a391-b00b-4f7a-b96a-3f8d0c049add\")) {                    Plotly.newPlot(                        \"e9b1a391-b00b-4f7a-b96a-3f8d0c049add\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"x\":[\"\\u003c|endoftext|\\u003e_0\",\"After_1\",\" John_2\",\" and_3\",\" Mary_4\",\" went_5\",\" to_6\",\" the_7\",\" store_8\",\",_9\",\" Mary_10\",\" gave_11\",\" a_12\",\" bottle_13\",\" of_14\",\" milk_15\",\" to_16\"],\"z\":[[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9981473088264465,0.0015995140420272946,0.00014956353697925806,-0.00037173336022533476,-2.1754694898845628e-05,-0.0006292545585893095,-0.0005155862891115248],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9980566501617432,0.002284243004396558,0.0001816517033148557,-0.0005052527994848788,-0.00026867049746215343,-5.2483203035080805e-05,-0.0012827112805098295],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9967369437217712,0.004081724677234888,0.0009727068245410919,4.3509389797691256e-05,-0.0001593531487742439,-0.00033611003891564906,-0.0019443259807303548],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9905893206596375,0.01998685486614704,0.0018959217704832554,0.0010137688368558884,-6.798342656111345e-05,0.0009104339987970889,-0.0019008165691047907],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.961650550365448,0.08534720540046692,0.0052037229761481285,0.0030521838925778866,0.00019660805992316455,0.0011062262346968055,-0.0022847868967801332],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.9630994200706482,0.08437205106019974,0.004122514743357897,0.0007176329963840544,0.00010170320456381887,0.0010012598941102624,-0.0042152442038059235],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.935917854309082,0.11111700534820557,0.007705241441726685,0.0003747246228158474,0.0003646630793809891,0.0013267644681036472,0.01874411851167679],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.7701539993286133,0.037418074905872345,0.00206778384745121,-8.348364644916728e-05,0.00013433524873107672,0.0017235158011317253,0.4499058723449707],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.09650518745183945,0.025925613939762115,0.001971247373148799,0.00032903975807130337,0.0004228568868711591,0.0018845004960894585,0.8994719386100769],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.023322122171521187,0.018536904826760292,0.0015859173145145178,0.0005261917249299586,0.0002526263997424394,0.0008729071705602109,0.9612753987312317],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,-0.008559385314583778,0.006338774226605892,0.0005803065141662955,-0.0003429084026720375,0.00010986121196765453,0.0006480179727077484,0.9495814442634583]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Position: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Position\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e9b1a391-b00b-4f7a-b96a-3f8d0c049add');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Add the index to the end of the label, because plotly doesn't like duplicate labels\n",
        "token_labels = [f\"{token}_{index}\" for index, token in enumerate(model.to_str_tokens(clean_tokens))]\n",
        "imshow(ioi_patching_result, x=token_labels, xaxis=\"Position\", yaxis=\"Layer\", title=\"Normalized Logit Difference After Patching Residual Stream on the IOI Task\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIAqfvpNxw6M"
      },
      "source": [
        "## Hooks: Accessing Activations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOUTrUjsxw6S"
      },
      "source": [
        "Hooks can also be used to just **access** an activation - to run some function using that activation value, *without* changing the activation value. This can be achieved by just having the hook return nothing, and not editing the activation in place.\n",
        "\n",
        "This is useful for eg extracting activations for a specific task, or for doing some long-running calculation across many inputs, eg finding the text that most activates a specific neuron. (Note - everything this can do *could* be done with `run_with_cache` and post-processing, but this workflow can be more intuitive and memory efficient.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9OEnUElxw6S"
      },
      "source": [
        "To demonstrate this, let's look for **[induction heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)** in GPT-2 Small.\n",
        "\n",
        "Induction circuits are a very important circuit in generative language models, which are used to detect and continue repeated subsequences. They consist of two heads in separate layers that compose together, a **previous token head** which always attends to the previous token, and an **induction head** which attends to the token *after* an earlier copy of the current token.\n",
        "\n",
        "To see why this is important, let's say that the model is trying to predict the next token in a news article about Michael Jordan. The token \" Michael\", in general, could be followed by many surnames. But an induction head will look from that occurrence of \" Michael\" to the token after previous occurrences of \" Michael\", ie \" Jordan\" and can confidently predict that that will come next."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmNQL98Yxw6T"
      },
      "source": [
        "An interesting fact about induction heads is that they generalise to arbitrary sequences of repeated tokens. We can see this by generating sequences of 50 random tokens, repeated twice, and plotting the average loss at predicting the next token, by position. We see that the model goes from terrible to very good at the halfway point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "xaFyk1g8xw6T",
        "outputId": "912261a8-2fae-4d12-e5e5-9704e738ef0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"598dbc83-6edc-42d7-9831-18c316f48ad9\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"598dbc83-6edc-42d7-9831-18c316f48ad9\")) {                    Plotly.newPlot(                        \"598dbc83-6edc-42d7-9831-18c316f48ad9\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98],\"xaxis\":\"x\",\"y\":[12.078295707702637,12.682364463806152,13.805269241333008,13.55078125,11.781356811523438,11.4011812210083,12.712279319763184,11.084616661071777,12.244002342224121,12.352217674255371,12.138893127441406,12.64035701751709,11.52483081817627,11.634940147399902,11.6737642288208,12.07756519317627,12.48275375366211,12.714024543762207,11.962589263916016,11.958287239074707,13.356219291687012,11.230696678161621,11.3945951461792,10.751550674438477,12.92697811126709,12.188307762145996,11.768603324890137,11.694145202636719,13.649161338806152,11.30235767364502,11.34436321258545,11.051169395446777,11.330540657043457,11.664444923400879,11.976541519165039,10.63212776184082,11.12783432006836,11.94363784790039,11.330827713012695,11.011725425720215,11.75753116607666,11.398600578308105,12.105847358703613,13.252827644348145,10.558650016784668,11.2716646194458,10.945937156677246,11.198719024658203,10.919024467468262,10.599017143249512,2.9086716175079346,1.1501058340072632,0.8891825079917908,0.23086440563201904,0.3340914845466614,0.44336533546447754,0.4026036262512207,0.189300537109375,0.2844475209712982,0.10050588846206665,0.32038769125938416,0.19408421218395233,0.14262168109416962,0.15458276867866516,0.17843185365200043,0.12232418358325958,0.18602284789085388,0.10958316177129745,0.06615480035543442,0.04475858807563782,0.05702311545610428,0.06448263674974442,0.1285271942615509,0.10778085142374039,0.10960779339075089,0.048902496695518494,0.013613897375762463,0.1814366728067398,0.04385815188288689,0.07113543897867203,0.06199754402041435,0.07070144265890121,0.3004054129123688,0.07664182037115097,0.08114221692085266,0.04763083532452583,0.013504673726856709,0.03448133543133736,0.6930354237556458,0.04613105580210686,0.053738515824079514,0.006666829343885183,0.06809559464454651,0.07047063112258911,0.1294652819633484,0.06014933064579964,0.13455985486507416,0.13417039811611176,0.1208818182349205],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Loss by position on random repeated tokens\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('598dbc83-6edc-42d7-9831-18c316f48ad9');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "batch_size = 10\n",
        "seq_len = 50\n",
        "size = (batch_size, seq_len)\n",
        "input_tensor = torch.randint(1000, 10000, size)\n",
        "\n",
        "random_tokens = input_tensor.to(model.cfg.device)\n",
        "repeated_tokens = einops.repeat(random_tokens, \"batch seq_len -> batch (2 seq_len)\")\n",
        "repeated_logits = model(repeated_tokens)\n",
        "correct_log_probs = model.loss_fn(repeated_logits, repeated_tokens, per_token=True)\n",
        "loss_by_position = einops.reduce(correct_log_probs, \"batch position -> position\", \"mean\")\n",
        "line(loss_by_position, xaxis=\"Position\", yaxis=\"Loss\", title=\"Loss by position on random repeated tokens\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLtSaoLUxw6T"
      },
      "source": [
        "The induction heads will be attending from the second occurrence of each token to the token *after* its first occurrence, ie the token `50-1==49` places back. So by looking at the average attention paid 49 tokens back, we can identify induction heads! Let's define a hook to do this!\n",
        "\n",
        "<details><summary>Technical details</summary>\n",
        "\n",
        "* We attach the hook to the attention pattern activation. There's one big pattern activation per layer, stacked across all heads, so we need to do some tensor manipulation to get a per-head score.\n",
        "* Hook functions can access global state, so we make a big tensor to store the induction head score for each head, and then we just add the score for each head to the appropriate position in the tensor.\n",
        "* To get a single hook function that works for each layer, we use the `hook.layer()` method to get the layer index (internally this is just inferred from the hook names).\n",
        "* As we want to add this to *every* activation pattern hook point, rather than giving the string for an activation name, this time we give a **name filter**. This is a Boolean function on hook point names, and it adds the hook function to every hook point where the function evaluates as true.\n",
        "    * `run_with_hooks` allows us to enter a list of (act_name, hook_function) pairs to all be added at once, so we could also have done this by inputting a list with a hook for each layer.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FVVS_v9xw6T",
        "outputId": "f45694aa-b4bc-40b7-ff18-c3078d6ead22"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"190ab42e-4456-4833-a298-6f585a1583e4\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"190ab42e-4456-4833-a298-6f585a1583e4\")) {                    Plotly.newPlot(                        \"190ab42e-4456-4833-a298-6f585a1583e4\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.009955878369510174,9.966958168661222e-05,0.010546973906457424,4.0583410054750857e-07,0.00022813043324276805,0.00019768899073824286,0.00977946724742651,0.0006674872129224241,0.00908320676535368,0.00915559846907854,0.006828702986240387,0.015242615714669228],[0.0011627675266936421,0.00045248764217831194,0.0021361575927585363,0.01417490839958191,0.004926139954477549,0.010640118271112442,0.015927109867334366,0.013070465996861458,0.012896527536213398,0.016126573085784912,0.006526595447212458,0.000517632404807955],[0.0044746194034814835,0.01877586357295513,0.003041735850274563,0.0019074507290497422,0.012237360700964928,0.002584304893389344,0.0039876471273601055,0.008248553611338139,0.004771647043526173,0.0017633740790188313,0.0006906316848471761,0.010382029227912426],[0.015542104840278625,0.007110548205673695,0.002217961009591818,0.012544052675366402,0.021509619429707527,0.011987114325165749,0.00174334819894284,0.0009274697513319552,0.005935505498200655,0.01233423687517643,0.009232483804225922,0.006464063189923763],[0.01664578728377819,0.014668889343738556,0.013992691412568092,0.008478098548948765,0.01899615488946438,0.012697082944214344,0.008333329111337662,0.0017152393702417612,0.01665916107594967,0.014090241864323616,0.018890956416726112,8.906972381872436e-11],[0.451614111661911,0.9170698523521423,0.01424565352499485,0.0065706996247172356,0.011130396276712418,0.9321417212486267,0.008963020518422127,0.018100803717970848,0.02871188521385193,0.029120853170752525,0.02137076109647751,0.01733485981822014],[0.008789685554802418,0.017398007214069366,0.01834423653781414,0.015153961256146431,0.02248268947005272,0.011032403446733952,0.03012258931994438,0.01068038959056139,0.009857730939984322,0.9169892072677612,0.036462243646383286,0.01406988874077797],[0.01107383705675602,0.17768746614456177,0.8614926934242249,0.019131189212203026,0.018100876361131668,0.016298996284604073,0.04784739762544632,0.08873092383146286,0.01723749376833439,0.019047973677515984,0.9243332743644714,0.06009266525506973],[0.015750497579574585,0.40704065561294556,0.014495478942990303,0.050178349018096924,0.017805716022849083,0.012079598382115364,0.15166832506656647,0.013180013746023178,0.032852329313755035,0.03178909420967102,0.06760691851377487,0.022921957075595856],[0.25689446926116943,0.19054049253463745,0.10555234551429749,0.012684683315455914,0.0927107185125351,0.026271803304553032,0.4618716239929199,0.029983991757035255,0.05182349309325218,0.4789004623889923,0.016641730442643166,0.03995012864470482],[0.339070200920105,0.5105082392692566,0.038450296968221664,0.14799615740776062,0.05797654390335083,0.01543364953249693,0.3008923828601837,0.47816023230552673,0.05431150645017624,0.015494456514716148,0.16141793131828308,0.2569926977157593],[0.017057929188013077,0.053864460438489914,0.03378748893737793,0.009234139695763588,0.03453892469406128,0.1011928990483284,0.04960957169532776,0.07048070430755615,0.009171898476779461,0.30352190136909485,0.40838193893432617,0.022866230458021164]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('190ab42e-4456-4833-a298-6f585a1583e4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "induction_score_store = torch.zeros((model.cfg.n_layers, model.cfg.n_heads), device=model.cfg.device)\n",
        "def induction_score_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
        "    # (This only has entries for tokens with index>=seq_len)\n",
        "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
        "    # Get an average score per head\n",
        "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
        "    # Store the result.\n",
        "    induction_score_store[hook.layer(), :] = induction_score\n",
        "\n",
        "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
        "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
        "\n",
        "model.run_with_hooks(\n",
        "    repeated_tokens,\n",
        "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(\n",
        "        pattern_hook_names_filter,\n",
        "        induction_score_hook\n",
        "    )]\n",
        ")\n",
        "\n",
        "imshow(induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drau4Kzrxw6U"
      },
      "source": [
        "Head 5 in Layer 5 scores extremely highly on this score, and we can feed in a shorter repeated random sequence, visualize the attention pattern for it and see this directly - including the \"induction stripe\" at `seq_len-1` tokens back.\n",
        "\n",
        "This time we put in a hook on the attention pattern activation to visualize the pattern of the relevant head."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cjiBdliIxw6U",
        "outputId": "c1b068e3-936a-4b26-ac3a-f8c07ddb3c11"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div id=\"circuits-vis-fcf89ad6-45d6\" style=\"margin: 15px 0;\"/>\n",
              "    <script crossorigin type=\"module\">\n",
              "    import { render, AttentionPatterns } from \"https://unpkg.com/circuitsvis@1.43.0/dist/cdn/esm.js\";\n",
              "    render(\n",
              "      \"circuits-vis-fcf89ad6-45d6\",\n",
              "      AttentionPatterns,\n",
              "      {\"tokens\": [\"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\", \"use\", \" advice\", \" Social\", \"\\u00f6\", \"\\u00b7\", \" fought\", \" Le\", \" allegedly\", \" NO\", \"alth\", \"car\", \" prepared\", \"new\", \"rant\", \"roll\", \" hours\", \" published\", \"66\", \"ension\", \" 44\"], \"attention\": [[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9737270474433899, 0.0262729711830616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9820428490638733, 0.017020266503095627, 0.0009368456667289138, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9895542860031128, 0.00866580568253994, 0.0004119748482480645, 0.0013679902767762542, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8543053865432739, 0.0780181884765625, 0.0008415378979407251, 0.00013599172234535217, 0.06669897586107254, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9374335408210754, 0.033002182841300964, 0.0015577428275719285, 2.5352785542054335e-06, 0.0010925536043941975, 0.026911530643701553, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.976921021938324, 0.0038436956238001585, 2.234029489045497e-05, 3.521895996527746e-05, 0.005183499306440353, 0.01217629387974739, 0.0018179028993472457, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9473506212234497, 0.013174930587410927, 0.0013492131838575006, 1.180242543341592e-05, 0.0009449435747228563, 0.011318957433104515, 0.018021011725068092, 0.007828536443412304, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847127199172974, 0.0010781448800116777, 0.002173440996557474, 5.48224352314719e-06, 0.0004914223100058734, 0.0013570792507380247, 0.0001018581388052553, 0.00028538500191643834, 0.009794448502361774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9915198683738708, 0.0044833519496023655, 0.00012727153080049902, 0.0001670209167059511, 0.0016301727155223489, 0.0011521612759679556, 0.0003231288574170321, 0.00012646260438486934, 0.00039313812158070505, 7.735053804935887e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8908807635307312, 0.024311939254403114, 1.7341229977319017e-05, 4.1577197407605127e-05, 0.0008967601461336017, 0.07334909588098526, 0.0009482800960540771, 0.004280842375010252, 0.005168660078197718, 7.830293725419324e-06, 9.693214815342799e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.817081093788147, 0.13517087697982788, 0.011989914812147617, 1.1421690032875631e-05, 0.0003511958639137447, 0.00945067685097456, 0.01946328766644001, 0.0006557486485689878, 0.0005761014763265848, 2.9927012292318977e-05, 1.658979817875661e-05, 0.005203105043619871, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9082697033882141, 0.006068143527954817, 0.013871830888092518, 0.0008237074362114072, 0.011908311396837234, 0.01554207131266594, 0.008354817517101765, 0.0020781648345291615, 0.0013173273764550686, 0.0021398114040493965, 0.003944162279367447, 0.0012376609956845641, 0.02444424293935299, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9479592442512512, 0.0021026760805398226, 0.01193847507238388, 0.00012338522356003523, 3.537495786076761e-06, 0.00014498857490252703, 0.0005875465576536953, 2.5534713131492026e-05, 0.0013609088491648436, 0.0003395720850676298, 0.01007620245218277, 0.0157905463129282, 0.006346344482153654, 0.003201034851372242, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9393549561500549, 0.006392289884388447, 0.0018427352188155055, 6.116198164818343e-06, 0.0003358719404786825, 0.0020515176001936197, 0.003801520448178053, 0.0012357976520434022, 0.0002194812404923141, 0.0003869338543154299, 5.012214751332067e-05, 0.008153197355568409, 0.026924636214971542, 0.002938011661171913, 0.0063067772425711155, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9339620471000671, 0.0017828113632276654, 0.005864645820111036, 0.000199502072064206, 7.227147580124438e-05, 0.001453535514883697, 0.0025924306828528643, 0.0004859396431129426, 0.002229833509773016, 0.00015120525495149195, 0.012292936444282532, 0.005057854112237692, 0.012368598021566868, 0.003944497089833021, 0.0062751127406954765, 0.011266660876572132, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8931334614753723, 0.0015468199271708727, 0.013001665472984314, 7.96635686128866e-06, 5.864337435923517e-05, 0.0008863371913321316, 0.0032020823564380407, 3.214758908143267e-05, 0.00018022512085735798, 1.1455734238552395e-05, 7.600105163874105e-05, 0.0004202726122457534, 0.001612616004422307, 0.028539085760712624, 0.010535502806305885, 0.025432026013731956, 0.021323613822460175, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9847024083137512, 0.00045824647531844676, 0.0001722048327792436, 6.160975090097054e-07, 4.7827966227487195e-06, 0.0005806126864627004, 0.00044618724496103823, 0.00041201553540304303, 0.0013038743054494262, 0.00031760730780661106, 6.99415395502001e-05, 0.0013941085198894143, 5.5830587371019647e-05, 0.0009110421524383128, 0.0001955802144948393, 0.000396028597606346, 0.0011691706022247672, 0.007409737445414066, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.8922598958015442, 0.010283716022968292, 0.007569305133074522, 0.015225780196487904, 0.000603529391810298, 0.0014377714833244681, 0.018397411331534386, 0.000181866911589168, 0.0021135706920176744, 3.8036650948924944e-05, 0.009962501004338264, 0.003998196218162775, 0.0012666822876781225, 0.002186268102377653, 0.003267065854743123, 0.0015871906653046608, 0.019133716821670532, 0.008779392577707767, 0.0017080693505704403, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.5637850761413574, 2.2041742340661585e-05, 0.00038083098479546607, 1.3938017673353897e-07, 4.306914647145277e-08, 0.0001288325438508764, 5.202714601182379e-05, 4.098215413250728e-06, 0.00043821678264066577, 1.0102498890773859e-05, 2.0490140741458163e-05, 0.00021747533173765987, 2.5249997634091415e-05, 2.1293963072821498e-05, 0.002207203535363078, 5.8927667851094157e-05, 0.002418374177068472, 0.0032775455620139837, 0.4260479211807251, 0.0008841017843224108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.14634987711906433, 0.4510916769504547, 0.027205228805541992, 0.003008269937708974, 0.0007913715671747923, 0.08009303361177444, 0.005927639082074165, 0.0006846353644505143, 0.0021268511191010475, 0.0027747598942369223, 0.00023907265858724713, 0.002550537697970867, 0.005493414122611284, 0.015832215547561646, 0.0003449993673712015, 0.0005726668750867248, 0.0021751606836915016, 0.03904319554567337, 0.1698266863822937, 0.041207652539014816, 0.0026610144414007664, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.1588301807641983, 0.09413877129554749, 0.6926900744438171, 4.7764006012585014e-05, 8.085336048679892e-06, 0.009355566464364529, 0.0008445510757155716, 2.443790663164691e-06, 0.0001377410371787846, 1.1189789574928e-06, 4.677354354498675e-06, 0.0003472109674476087, 0.0026314801070839167, 0.0004504164680838585, 0.006463209632784128, 0.0005723321228288114, 0.001266839331947267, 0.006402328610420227, 0.0018093092367053032, 0.006555440369993448, 0.0003791518392972648, 0.01706133596599102, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0507238395512104, 0.004356134217232466, 0.00013167195720598102, 0.93964684009552, 0.0005500880652107298, 0.002771187573671341, 1.4556246242136694e-05, 5.017395324102836e-06, 1.5498708307859488e-05, 7.02077898040443e-08, 8.694883035786916e-06, 3.654152897070162e-05, 3.6079711662750924e-06, 2.594179386505857e-05, 7.59087424739846e-06, 7.100912853275076e-07, 4.6297875087475404e-05, 7.143527909647673e-05, 0.00012089155643479899, 0.000561000662855804, 1.3380984455579892e-05, 0.0007342093158513308, 0.00015471279039047658, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04466324299573898, 0.0028326697647571564, 7.648682367289439e-05, 0.00015513764810748398, 0.7502217888832092, 0.1919575184583664, 9.640491043683141e-05, 0.00016210104513447732, 0.00012769455497618765, 1.1226586138946004e-05, 8.733231879887171e-06, 0.0002813311293721199, 5.207761569181457e-05, 0.008386502042412758, 4.340233772381907e-06, 6.482672324636951e-05, 3.802950232056901e-05, 7.603670383105054e-05, 0.00012636416067834944, 9.22799008549191e-05, 4.0301836179423844e-07, 0.00011281618208158761, 2.522413069527829e-06, 0.00044938692008145154, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0136062391102314, 0.006971819791942835, 3.188595292158425e-05, 1.8455398276273627e-06, 0.0023010680451989174, 0.9711790680885315, 0.0003632439475040883, 8.45976173877716e-05, 0.00010611514881020412, 4.505663468989951e-07, 2.987568166190613e-07, 0.0008592635276727378, 8.84485270944424e-05, 0.0003481197636574507, 9.285117812396493e-07, 3.160546111757867e-05, 1.2802072888007388e-05, 5.803379099234007e-05, 0.00010517534974496812, 6.438309355871752e-05, 1.8867468725147774e-06, 0.0009238768252544105, 4.681064638134558e-06, 8.993229130282998e-06, 0.002845223993062973, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.019611306488513947, 0.004386154469102621, 6.198722985573113e-05, 4.885768589701911e-08, 4.2524367017904297e-05, 0.0036122521851211786, 0.9598399996757507, 0.005622244905680418, 0.002344567561522126, 5.173993713469827e-07, 1.962153874046635e-06, 0.0016548263374716043, 0.0005915339570492506, 0.001169586437754333, 5.784231689176522e-06, 8.118995174299926e-05, 4.500300929066725e-05, 0.0001849783438956365, 5.086977398605086e-05, 0.000111328401544597, 6.848466000519693e-06, 3.85396160709206e-05, 4.853071914112661e-06, 1.2763491952227923e-07, 3.953082341467962e-06, 0.0005269552930258214, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.008729123510420322, 0.00017810783174354583, 2.8806312002416234e-07, 4.138274221077154e-07, 6.864992610644549e-05, 0.0009331199107691646, 0.0001488830748712644, 0.9844523668289185, 0.004786375444382429, 0.0001132896650233306, 7.25545532986871e-07, 7.424702926073223e-05, 1.4996358004282229e-05, 0.00019790712394751608, 2.995068371092202e-07, 4.872013960266486e-06, 5.296111794450553e-06, 4.536831511359196e-06, 0.00011268968228250742, 3.4171025617979467e-06, 8.272540071629919e-06, 1.237986271007685e-05, 3.665547154696469e-08, 9.025117719829723e-07, 1.6053079889388755e-05, 0.00011404424003558233, 1.8653661754797213e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.04082169756293297, 0.003618433838710189, 4.8210502427536994e-05, 1.9615818303009291e-07, 5.380281072575599e-05, 0.0021802405826747417, 0.003327243495732546, 0.0018782124388962984, 0.9307870268821716, 0.004815405700355768, 1.4430276678467635e-05, 0.0028288080357015133, 0.0001046408069669269, 0.0029309175442904234, 0.0009514765115454793, 6.522196053992957e-05, 0.0002954130177386105, 0.00012317558866925538, 0.001551239751279354, 0.0005327718099579215, 0.00022083611111156642, 0.0004432721179910004, 1.939156027219724e-05, 5.825709763485065e-07, 1.663282819208689e-05, 0.0004773263353854418, 0.0011258200975134969, 0.000767689838539809, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.13800935447216034, 0.0003385838062968105, 0.00015972652181517333, 3.422568184419106e-08, 1.2696329577011056e-05, 0.00024196661252062768, 3.8219157431740314e-05, 3.751519398065284e-05, 0.004743278957903385, 0.8406777381896973, 0.0001887540565803647, 0.00015232608711812645, 1.2507432074926328e-05, 0.0002236285072285682, 0.00013282443978823721, 6.470834341598675e-05, 0.00013950421998742968, 9.763532580109313e-05, 0.0004387960070744157, 4.4860902562504634e-05, 6.358889368129894e-05, 0.00034255790524184704, 5.2226645493647084e-05, 5.293432536745968e-07, 4.435891696630279e-06, 6.54347168165259e-05, 2.914482593041612e-06, 3.872663910442498e-06, 0.013709748163819313, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.007798762992024422, 0.00022834629635326564, 4.6384946017496986e-07, 6.367677087837365e-07, 1.5816745872143656e-05, 4.7439083573408425e-05, 5.239070105744759e-06, 7.306558018171927e-06, 1.2522126780822873e-05, 3.3302333690699015e-07, 0.9909055233001709, 0.00045220478205010295, 5.365327069739578e-06, 7.535887561971322e-05, 8.799969691608567e-06, 7.89504611020675e-06, 0.00023918120132293552, 2.256896095786942e-06, 7.641861884621903e-05, 5.5141779739642516e-05, 4.378313406050438e-06, 2.181060699513182e-05, 4.4351477157533736e-08, 1.258427687389485e-06, 2.069825995931751e-06, 1.2951696589880157e-05, 3.9528120510112785e-07, 1.1202276937183342e-06, 7.9817673395155e-06, 2.9978505153849255e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.042284343391656876, 0.011305336840450764, 7.640699664079875e-07, 2.2586050363315735e-06, 9.786370355868712e-05, 0.038269199430942535, 0.00023640785366296768, 0.0014555181842297316, 0.0029497782234102488, 1.2863498568549403e-06, 2.827169737429358e-05, 0.8946184515953064, 0.000523496069945395, 0.001179973711259663, 0.0009106355137191713, 0.00036046106833964586, 0.00020461619715206325, 2.910214607254602e-05, 0.0013425356009975076, 0.0003398243279661983, 0.00033255034941248596, 8.43034649733454e-05, 7.937682511283128e-08, 5.809831236547325e-06, 4.910861207463313e-06, 0.0023872887250036, 2.6967012672685087e-05, 0.00020931517065037042, 0.0007688838522881269, 5.801371116831433e-06, 3.4147673432016745e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.006102928426116705, 0.016550440341234207, 4.6485070924973115e-05, 8.233602954987873e-08, 7.398419256787747e-06, 0.0005482262931764126, 0.000593138684052974, 1.573847112013027e-05, 3.5032899177167565e-05, 3.3504232987979776e-07, 1.8657554790024733e-07, 0.000460667914012447, 0.8416212201118469, 0.12311417609453201, 0.00635922746732831, 0.002699504140764475, 0.00016676213999744505, 0.0012130774557590485, 0.00013198891247157007, 8.468204759992659e-05, 4.615942543750862e-06, 6.99491283739917e-05, 4.916110356134595e-06, 3.4761166034513735e-07, 3.71195625348264e-07, 6.107363878982142e-05, 6.7285327531863e-05, 2.275831548104179e-06, 2.060149927274324e-05, 7.198155458354449e-07, 2.7881066344548344e-08, 1.652937862672843e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0404171422123909, 0.0013464416842907667, 0.0002881725085899234, 4.343583896115888e-06, 0.0006837462424300611, 0.0021492778323590755, 0.0012713986216112971, 0.00021145936625543982, 0.00014913539052940905, 2.368190689594485e-05, 9.255170880351216e-05, 7.46091318433173e-05, 0.0030381649266928434, 0.9153454899787903, 0.0020634918473660946, 0.002670771675184369, 0.0006971447728574276, 0.022915314882993698, 0.0016386568313464522, 0.00029437849298119545, 8.30199132906273e-06, 0.00011940939293708652, 3.610887142713182e-05, 1.2593977771757636e-05, 0.000383078760933131, 0.0011952179484069347, 0.00018445361638441682, 7.125888805603608e-05, 0.00012850709026679397, 6.062284592189826e-05, 4.517687557381578e-05, 6.895808724038943e-07, 0.0023790940176695585, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.03775651007890701, 0.0016132266027852893, 0.0003177846665494144, 8.171087984010228e-07, 4.6314994506246876e-07, 7.222019485197961e-05, 0.00012490902736317366, 4.997585165256169e-06, 0.0003066718054469675, 5.749355295847636e-06, 0.0002466128207743168, 0.003777747042477131, 0.0013358069118112326, 0.002113186754286289, 0.8997160792350769, 0.04417850449681282, 0.00033094992977567017, 0.001384939532727003, 0.0003935607383027673, 0.002321055391803384, 0.0004642207932192832, 0.00019271507335361093, 0.0005703868810087442, 5.92765218243585e-06, 2.4687210498086642e-08, 3.108325699940906e-06, 7.16592330718413e-06, 2.9240155186016636e-07, 7.98414257587865e-05, 1.2546398465929087e-05, 0.0001265132159460336, 0.00023837975459173322, 0.0008907333249226213, 0.0014062307309359312, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.08771783858537674, 0.007821416482329369, 5.662468174705282e-05, 1.4731131869893943e-08, 1.0490747627045494e-05, 0.0011058712843805552, 0.0004291172663215548, 5.523042636923492e-05, 3.919887603842653e-05, 2.7502044304128503e-06, 2.546168616390787e-06, 0.002755208173766732, 0.005722646601498127, 0.0011191918747499585, 0.0015876393299549818, 0.8757357597351074, 0.0010800447780638933, 0.003532156115397811, 0.0015019910642877221, 0.0006949505768716335, 4.3340980482753366e-05, 0.00023435073671862483, 6.934305019967724e-06, 2.7577918615406816e-08, 9.912458835970028e-07, 0.00019156669441144913, 2.9515418646042235e-05, 5.4682345762557816e-06, 2.4805774501146516e-06, 1.4659882481282693e-06, 7.256012395373546e-07, 8.567833720007911e-05, 0.004263886250555515, 0.0007048699189908803, 0.0034579611383378506, 0.0, 0.0, 0.0, 0.0, 0.0], [0.018741462379693985, 0.00013177553773857653, 0.0001151907054008916, 8.336372729900177e-07, 3.8734546592422703e-07, 4.034390804008581e-05, 8.927338058128953e-05, 6.5760018514993135e-06, 6.646589463343844e-05, 2.0145337487065262e-07, 0.00012498503201641142, 0.00022737719700671732, 0.0003596782626118511, 4.087373235961422e-05, 8.65406691445969e-05, 0.00017062197730410844, 0.9720672369003296, 0.004511029925197363, 0.0017741514602676034, 0.00033421185798943043, 0.0006673701573163271, 8.272354534710757e-06, 8.590857760282233e-05, 4.4451999769989925e-07, 1.5395192676237457e-08, 3.916235073120333e-06, 1.856171184044797e-05, 1.744039764162153e-06, 2.306476017110981e-05, 6.561277245964448e-07, 5.5365380831062794e-05, 1.002774115477223e-05, 0.0001100561858038418, 2.098819095408544e-05, 6.0086229495937005e-05, 4.435600567376241e-05, 0.0, 0.0, 0.0, 0.0], [0.021614333614706993, 6.699936784571037e-05, 0.00023382958897855133, 1.946084609016907e-07, 1.0567928256932646e-06, 2.5699444449855946e-05, 0.0002104660088662058, 1.7352494978695177e-06, 6.270136509556323e-06, 8.374804139066327e-08, 2.3547661385237006e-06, 1.8064512914861552e-05, 0.00023376515309792012, 0.001895317924208939, 0.00020409416174516082, 0.0004746883932966739, 0.0029953729826956987, 0.9625540971755981, 0.00691427756100893, 0.00019762477313634008, 0.00011761223140638322, 1.78101454366697e-05, 8.19376073195599e-05, 8.319892685904051e-08, 6.341040403867737e-08, 1.503461476204393e-06, 1.595173125679139e-05, 1.2851933206547983e-07, 7.935282724247372e-07, 1.268652596309039e-07, 5.140130951986066e-07, 3.882859900272706e-08, 5.8853103837464005e-05, 0.0011026777792721987, 9.716644126456231e-05, 8.231291576521471e-05, 0.0007721150759607553, 0.0, 0.0, 0.0], [0.036683231592178345, 5.292119567457121e-06, 1.6796273030195152e-06, 3.2259253601729654e-10, 1.7678923214248243e-08, 9.71175995800877e-06, 6.970066351641435e-06, 3.922034920833539e-06, 1.5272406017174944e-05, 6.423094873753143e-07, 3.0026106401237485e-07, 2.1527788703679107e-05, 8.620285143479123e-07, 2.371107621002011e-05, 1.1333961538184667e-06, 4.370046099211322e-06, 2.1794727217638865e-05, 0.0007244806620292366, 0.9565503597259521, 7.606112922076136e-05, 0.005361164920032024, 3.4096636227332056e-05, 1.4788588487135712e-06, 1.9675812090724776e-09, 6.515209260982147e-09, 7.016106451374071e-07, 1.9081969071521598e-07, 3.605064478051645e-07, 3.97335998059134e-06, 1.5304269709304208e-06, 1.0370927583380762e-07, 7.635036922692962e-07, 1.8985110727953725e-07, 6.1644395827897824e-06, 2.6138322937185876e-06, 1.3529084981200867e-06, 1.0274129635945428e-05, 0.00042383253457956016, 0.0, 0.0], [0.039370130747556686, 0.0003585830272641033, 7.41930998628959e-05, 4.9509686505189165e-05, 4.653078576666303e-06, 4.69761471322272e-05, 0.0002299233601661399, 1.250448349310318e-06, 3.7233094190014526e-05, 8.911907656283802e-08, 7.931947038741782e-05, 0.00013509126438293606, 1.8374801584286615e-05, 0.0001029744089464657, 8.208496728911996e-05, 2.753642911557108e-05, 0.0005808327696286142, 0.001175031648017466, 0.00090598821407184, 0.9545682072639465, 7.417640154017136e-05, 0.0005086685996502638, 0.0001944841060321778, 8.633135439595208e-05, 8.952758889790857e-07, 1.429008443665225e-05, 3.4452030376996845e-05, 2.1258705373838893e-07, 1.695069659035653e-05, 4.816184286937641e-07, 3.1853684049565345e-05, 1.3589491572929546e-05, 2.5087774702114984e-05, 5.98193691985216e-05, 0.00011690238170558587, 1.1342107427481096e-05, 0.0002713192661758512, 0.0002638357982505113, 0.00042731984285637736, 0.0], [0.02540118619799614, 7.441657317031058e-07, 1.083011466107564e-05, 2.249714858848506e-09, 9.22188214680375e-10, 8.20854529592907e-06, 2.5448052838328294e-06, 1.0004332295920904e-07, 3.16087098326534e-05, 2.427833578622085e-07, 5.28918860709382e-07, 1.4262905096984468e-05, 1.5345697192969965e-06, 1.87780551641481e-06, 0.0002028696471825242, 2.141229060725891e-06, 0.00010114459291798994, 0.0009309824672527611, 0.10166086256504059, 5.5514923587907106e-05, 0.8627561926841736, 2.250216311949771e-06, 3.0665501981275156e-05, 5.196882923996782e-09, 3.199170095502524e-11, 8.736409284892943e-08, 1.2241630997777975e-07, 1.2374229418909977e-09, 1.2507468454714399e-05, 4.6357610017366824e-07, 1.629777557354828e-07, 2.719423264352372e-07, 1.1941983757424168e-07, 1.4462457897934655e-07, 5.527898247237317e-05, 3.5639260431707953e-07, 4.93334409839008e-05, 0.00016947872063610703, 0.008456651121377945, 3.8713624235242605e-05]]]}\n",
              "    )\n",
              "    </script>"
            ],
            "text/plain": [
              "<circuitsvis.utils.render.RenderedHTML at 0xffff425c9fd0>"
            ]
          },
          "metadata": {
            "text/html": {
              "Content-Type": "text/html"
            }
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "\n",
        "induction_head_layer = 5\n",
        "induction_head_index = 5\n",
        "size = (1, 20)\n",
        "input_tensor = torch.randint(1000, 10000, size)\n",
        "\n",
        "single_random_sequence = input_tensor.to(model.cfg.device)\n",
        "repeated_random_sequence = einops.repeat(single_random_sequence, \"batch seq_len -> batch (2 seq_len)\")\n",
        "def visualize_pattern_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    display(\n",
        "        cv.attention.attention_patterns(\n",
        "            tokens=model.to_str_tokens(repeated_random_sequence),\n",
        "            attention=pattern[0, induction_head_index, :, :][None, :, :] # Add a dummy axis, as CircuitsVis expects 3D patterns.\n",
        "        )\n",
        "    )\n",
        "\n",
        "model.run_with_hooks(\n",
        "    repeated_random_sequence,\n",
        "    return_type=None,\n",
        "    fwd_hooks=[(\n",
        "        utils.get_act_name(\"pattern\", induction_head_layer),\n",
        "        visualize_pattern_hook\n",
        "    )]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3mDDsFKxw6V"
      },
      "source": [
        "## Available Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y3lZKYjvxw6V"
      },
      "source": [
        "TransformerLens comes with over 40 open source models available, all of which can be loaded into a consistent(-ish) architecture by just changing the name in `from_pretrained`. The open source models available are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=jHj79Pj58cgJKdq4t-ygK-4h), and a set of interpretability friendly models I've trained are [documented here](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=NCJ6zH_Okw_mUYAwGnMKsj2m), including a set of toy language models (tiny one to four layer models) and a set of [SoLU models](https://dynalist.io/d/n2ZWtnoYHrU1s4vnFSAQ519J#z=FZ5W6GGcy6OitPEaO733JLqf) up to GPT-2 Medium size (300M parameters). You can see [a table of the official alias and hyper-parameters of available models here](https://github.com/TransformerLensOrg/TransformerLens/blob/main/transformer_lens/model_properties_table.md).\n",
        "\n",
        "**Note:** TransformerLens does not currently support multi-GPU models (which you want for models above eg 7B parameters), but this feature is coming soon!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsmq-1EPxw6V"
      },
      "source": [
        "\n",
        "Notably, this means that analysis can be near immediately re-run on a different model by just changing the name - to see this, let's load in DistilGPT-2 (a distilled version of GPT-2, with half as many layers) and copy the code from above to see the induction heads in that model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4M-ninN5xw6V",
        "outputId": "c320be34-2c54-4951-e986-e08ae174b1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded pretrained model distilgpt2 into HookedTransformer\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "distilgpt2 = HookedTransformer.from_pretrained(\"distilgpt2\", device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "uKBe7GmBxw6V",
        "outputId": "c44412fd-ebc3-468f-d9f0-467b67024850",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"3a74edd9-8f84-4ebd-afcb-e311bdc3ff46\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3a74edd9-8f84-4ebd-afcb-e311bdc3ff46\")) {                    Plotly.newPlot(                        \"3a74edd9-8f84-4ebd-afcb-e311bdc3ff46\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.009367258287966251,0.00010438378376420587,0.011708439327776432,3.8638163459836505e-06,0.0007583936676383018,1.3383755685936194e-05,0.008663319982588291,0.001467836438678205,0.008613485842943192,0.009779772721230984,0.008780462667346,0.015617581084370613],[0.0026517496444284916,0.017314758151769638,0.0026012109592556953,0.0001308208447881043,0.014476257376372814,0.0019402836915105581,0.0054324958473443985,0.01572398468852043,0.001289502950385213,9.233372111339122e-05,0.003943198826164007,0.014749507419764996],[0.005348636768758297,0.006261143367737532,0.01357482559978962,0.0030336317140609026,0.019379867240786552,0.004881605505943298,0.01016234327107668,0.0013024633517488837,0.019212020561099052,0.01286319363862276,0.021832607686519623,1.6635392336653704e-13],[0.007531560026109219,0.23020458221435547,0.848582923412323,0.01586410216987133,0.01718829944729805,0.014494096860289574,0.020108850672841072,0.19733162224292755,0.01556345820426941,0.017081063240766525,0.9269858598709106,0.48904356360435486],[0.27462154626846313,0.23361429572105408,0.08995277434587479,0.010495610535144806,0.0835428312420845,0.024711867794394493,0.6315231323242188,0.025097377598285675,0.0645056813955307,0.6483469605445862,0.016907289624214172,0.05680852010846138],[0.02067071944475174,0.07998076826334,0.05387507751584053,0.012295888736844063,0.03557185083627701,0.19210484623908997,0.07827745378017426,0.10019882768392563,0.007260392419993877,0.4699220359325409,0.16978955268859863,0.03104964643716812]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0},\"title\":{\"text\":\"Induction Score by Head in Distil GPT-2\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3a74edd9-8f84-4ebd-afcb-e311bdc3ff46');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "# We make a tensor to store the induction score for each head. We put it on the model's device to avoid needing to move things between the GPU and CPU, which can be slow.\n",
        "distilgpt2_induction_score_store = torch.zeros((distilgpt2.cfg.n_layers, distilgpt2.cfg.n_heads), device=distilgpt2.cfg.device)\n",
        "def induction_score_hook(\n",
        "    pattern: Float[torch.Tensor, \"batch head_index dest_pos source_pos\"],\n",
        "    hook: HookPoint,\n",
        "):\n",
        "    # We take the diagonal of attention paid from each destination position to source positions seq_len-1 tokens back\n",
        "    # (This only has entries for tokens with index>=seq_len)\n",
        "    induction_stripe = pattern.diagonal(dim1=-2, dim2=-1, offset=1-seq_len)\n",
        "    # Get an average score per head\n",
        "    induction_score = einops.reduce(induction_stripe, \"batch head_index position -> head_index\", \"mean\")\n",
        "    # Store the result.\n",
        "    distilgpt2_induction_score_store[hook.layer(), :] = induction_score\n",
        "\n",
        "# We make a boolean filter on activation names, that's true only on attention pattern names.\n",
        "pattern_hook_names_filter = lambda name: name.endswith(\"pattern\")\n",
        "\n",
        "distilgpt2.run_with_hooks(\n",
        "    repeated_tokens,\n",
        "    return_type=None, # For efficiency, we don't need to calculate the logits\n",
        "    fwd_hooks=[(\n",
        "        pattern_hook_names_filter,\n",
        "        induction_score_hook\n",
        "    )]\n",
        ")\n",
        "\n",
        "imshow(distilgpt2_induction_score_store, xaxis=\"Head\", yaxis=\"Layer\", title=\"Induction Score by Head in Distil GPT-2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdHU3DQixw6W"
      },
      "source": [
        "\n",
        "### An overview of the important open source models in the library\n",
        "\n",
        "* **GPT-2** - the classic generative pre-trained models from OpenAI\n",
        "    * Sizes Small (85M), Medium (300M), Large (700M) and XL (1.5B).\n",
        "    * Trained on ~22B tokens of internet text. ([Open source replication](https://huggingface.co/datasets/openwebtext))\n",
        "* **GPT-Neo** - Eleuther's replication of GPT-2\n",
        "    * Sizes 125M, 1.3B, 2.7B\n",
        "    * Trained on 300B(ish?) tokens of [the Pile](https://pile.eleuther.ai/) a large and diverse dataset including a bunch of code (and weird stuff)\n",
        "* **[OPT](https://ai.facebook.com/blog/democratizing-access-to-large-scale-language-models-with-opt-175b/)** - Meta AI's series of open source models\n",
        "    * Trained on 180B tokens of diverse text.\n",
        "    * 125M, 1.3B, 2.7B, 6.7B, 13B, 30B, 66B\n",
        "* **GPT-J** - Eleuther's 6B parameter model, trained on the Pile\n",
        "* **GPT-NeoX** - Eleuther's 20B parameter model, trained on the Pile\n",
        "* **StableLM** - Stability AI's 3B and 7B models, with and without chat and instruction fine-tuning\n",
        "* **Stanford CRFM models** - a replication of GPT-2 Small and GPT-2 Medium, trained on 5 different random seeds.\n",
        "    * Notably, 600 checkpoints were taken during training per model, and these are available in the library with eg `HookedTransformer.from_pretrained(\"stanford-gpt2-small-a\", checkpoint_index=265)`.\n",
        "- **BERT** - Google's bidirectional encoder-only transformer.\n",
        "    - Size Base (108M), trained on English Wikipedia and BooksCorpus.\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhrF6cXPxw6W"
      },
      "source": [
        "\n",
        "### An overview of some interpretability-friendly models I've trained and included\n",
        "\n",
        "(Feel free to [reach out](mailto:neelnanda27@gmail.com) if you want more details on any of these models)\n",
        "\n",
        "Each of these models has about ~200 checkpoints taken during training that can also be loaded from TransformerLens, with the `checkpoint_index` argument to `from_pretrained`.\n",
        "\n",
        "Note that all models are trained with a Beginning of Sequence token, and will likely break if given inputs without that!\n",
        "\n",
        "* **Toy Models**: Inspired by [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), I've trained 12 tiny language models, of 1-4L and each of width 512. I think that interpreting these is likely to be far more tractable than larger models, and both serve as good practice and will likely contain motifs and circuits that generalise to far larger models (like induction heads):\n",
        "    * Attention-Only models (ie without MLPs): attn-only-1l, attn-only-2l, attn-only-3l, attn-only-4l\n",
        "    * GELU models (ie with MLP, and the standard GELU activations): gelu-1l, gelu-2l, gelu-3l, gelu-4l\n",
        "    * SoLU models (ie with MLP, and [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), designed to make MLP neurons more interpretable): solu-1l, solu-2l, solu-3l, solu-4l\n",
        "    * All models are trained on 22B tokens of data, 80% from C4 (web text) and 20% from Python Code\n",
        "    * Models of the same layer size were trained with the same weight initialization and data shuffle, to more directly compare the effect of different activation functions.\n",
        "* **SoLU** models: A larger scan of models trained with [Anthropic's SoLU activation](https://transformer-circuits.pub/2022/solu/index.html), in the hopes that it makes the MLP neuron interpretability easier.\n",
        "    * A scan up to GPT-2 Medium size, trained on 30B tokens of the same data as toy models, 80% from C4 and 20% from Python code.\n",
        "        * solu-6l (40M), solu-8l (100M), solu-10l (200M), solu-12l (340M)\n",
        "    * An older scan up to GPT-2 Medium size, trained on 15B tokens of [the Pile](https://pile.eleuther.ai/)\n",
        "        * solu-1l-pile (13M), solu-2l-pile (13M), solu-4l-pile (13M), solu-6l-pile (40M), solu-8l-pile (100M), solu-10l-pile (200M), solu-12l-pile (340M)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvJKDQVoxw6X"
      },
      "source": [
        "## Other Resources:\n",
        "\n",
        "* [Concrete Steps to Get Started in Mechanistic Interpretability](https://neelnanda.io/getting-started): A guide I wrote for how to get involved in mechanistic interpretability, and how to learn the basic skills\n",
        "* [A Comprehensive Mechanistic Interpretability Explainer](https://neelnanda.io/glossary): An overview of concepts in the field and surrounding ideas in ML and transformers, with long digressions to give context and build intuitions.\n",
        "* [Concrete Open Problems in Mechanistic Interpretability](https://neelnanda.io/concrete-open-problems), a doc I wrote giving a long list of open problems in mechanistic interpretability, and thoughts on how to get started on trying to work on them.\n",
        "    * There's a lot of low-hanging fruit in the field, and I expect that many people reading this could use TransformerLens to usefully make progress on some of these!\n",
        "* Other demos:\n",
        "    * **[Exploratory Analysis Demo](https://neelnanda.io/exploratory-analysis-demo)**, a demonstration of my standard toolkit for how to use TransformerLens to explore a mysterious behaviour in a language model.\n",
        "    * [Interpretability in the Wild](https://github.com/redwoodresearch/Easy-Transformer) a codebase from Arthur Conmy and Alex Variengien at Redwood research using this library to do a detailed and rigorous reverse engineering of the Indirect Object Identification circuit, to accompany their paper\n",
        "        * Note - this was based on an earlier version of this library, called EasyTransformer. It's pretty similar, but several breaking changes have been made since.\n",
        "    * A [recorded walkthrough](https://www.youtube.com/watch?v=yo4QvDn-vsU) of me doing research with TransformerLens on whether a tiny model can re-derive positional information, with [an accompanying Colab](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/main/No_Position_Experiment.ipynb)\n",
        "* [Neuroscope](https://neuroscope.io), a website showing the text in the dataset that most activates each neuron in some selected models. Good to explore to get a sense for what kind of features the model tends to represent, and as a \"wiki\" to get some info\n",
        "    * A tutorial on how to make an [Interactive Neuroscope](https://github.com/TransformerLensOrg/TransformerLens/blob/main/Hacky-Interactive-Lexoscope.ipynb), where you type in text and see the neuron activations over the text update live."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_f1JFBExw6X"
      },
      "source": [
        "## Transformer architecture\n",
        "\n",
        "HookedTransformer is a somewhat adapted GPT-2 architecture, but is computationally identical. The most significant changes are to the internal structure of the attention heads:\n",
        "* The weights (W_K, W_Q, W_V) mapping the residual stream to queries, keys and values are 3 separate matrices, rather than big concatenated one.\n",
        "* The weight matrices (W_K, W_Q, W_V, W_O) and activations (keys, queries, values, z (values mixed by attention pattern)) have separate head_index and d_head axes, rather than flattening them into one big axis.\n",
        "    * The activations all have shape `[batch, position, head_index, d_head]`\n",
        "    * W_K, W_Q, W_V have shape `[head_index, d_model, d_head]` and W_O has shape `[head_index, d_head, d_model]`\n",
        "\n",
        "The actual code is a bit of a mess, as there's a variety of Boolean flags to make it consistent with the various different model families in TransformerLens - to understand it and the internal structure, I instead recommend reading the code in [CleanTransformerDemo](https://colab.research.google.com/github/TransformerLensOrg/TransformerLens/blob/clean-transformer-demo/Clean_Transformer_Demo.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgZWMydIxw6X"
      },
      "source": [
        "### Parameter Names\n",
        "\n",
        "Here is a list of the parameters and shapes in the model. By convention, all weight matrices multiply on the right (ie `new_activation = old_activation @ weights + bias`).\n",
        "\n",
        "Reminder of the key hyper-params:\n",
        "* `n_layers`: 12. The number of transformer blocks in the model (a block contains an attention layer and an MLP layer)\n",
        "* `n_heads`: 12. The number of attention heads per attention layer\n",
        "* `d_model`: 768. The residual stream width.\n",
        "* `d_head`: 64. The internal dimension of an attention head activation.\n",
        "* `d_mlp`: 3072. The internal dimension of the MLP layers (ie the number of neurons).\n",
        "* `d_vocab`: 50267. The number of tokens in the vocabulary.\n",
        "* `n_ctx`: 1024. The maximum number of tokens in an input prompt.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wCVom4gxw6Y"
      },
      "source": [
        "**Transformer Block parameters:**\n",
        "Replace 0 with the relevant layer index."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "evTckdf7xw6Y",
        "outputId": "4114d461-dd67-4d37-9cc5-13482e7ac739",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "blocks.0.attn.W_Q torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_O torch.Size([12, 64, 768])\n",
            "blocks.0.attn.b_Q torch.Size([12, 64])\n",
            "blocks.0.attn.b_O torch.Size([768])\n",
            "blocks.0.attn.W_K torch.Size([12, 768, 64])\n",
            "blocks.0.attn.W_V torch.Size([12, 768, 64])\n",
            "blocks.0.attn.b_K torch.Size([12, 64])\n",
            "blocks.0.attn.b_V torch.Size([12, 64])\n",
            "blocks.0.mlp.W_in torch.Size([768, 3072])\n",
            "blocks.0.mlp.b_in torch.Size([3072])\n",
            "blocks.0.mlp.W_out torch.Size([3072, 768])\n",
            "blocks.0.mlp.b_out torch.Size([768])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if name.startswith(\"blocks.0.\"):\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-alr_4Mcxw6Z"
      },
      "source": [
        "**Embedding & Unembedding parameters:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "pWM3S__pxw6a",
        "outputId": "c01ee1a0-47ae-4bbe-e345-745a84dbaf9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.W_E torch.Size([50257, 768])\n",
            "pos_embed.W_pos torch.Size([1024, 768])\n",
            "unembed.W_U torch.Size([768, 50257])\n",
            "unembed.b_U torch.Size([50257])\n"
          ]
        }
      ],
      "source": [
        "for name, param in model.named_parameters():\n",
        "    if not name.startswith(\"blocks\"):\n",
        "        print(name, param.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRDpUJm5xw6a"
      },
      "source": [
        "### Activation + Hook Names\n",
        "\n",
        "Lets get out a list of the activation/hook names in the model and their shapes. In practice, I recommend using the `utils.get_act_name` function to get the names, but this is a useful fallback, and necessary to eg write a name filter function.\n",
        "\n",
        "Let's do this by entering in a short, 10 token prompt, and add a hook function to each activations to print its name and shape. To avoid spam, let's just add this to activations in the first block or not in a block.\n",
        "\n",
        "Note 1: Each LayerNorm has a hook for the scale factor (ie the standard deviation of the input activations for each token position & batch element) and for the normalized output (ie the input activation with mean 0 and standard deviation 1, but *before* applying scaling or translating with learned weights). LayerNorm is applied every time a layer reads from the residual stream: `ln1` is the LayerNorm before the attention layer in a block, `ln2` the one before the MLP layer, and `ln_final` is the LayerNorm before the unembed.\n",
        "\n",
        "Note 2: *Every* activation apart from the attention pattern and attention scores has shape beginning with `[batch, position]`. The attention pattern and scores have shape `[batch, head_index, dest_position, source_position]` (the numbers are the same, unless we're using caching)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "NYZEXW9oxw6a",
        "outputId": "69ffd3d6-2eb8-4287-cb89-653e7a52c3f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num tokens: 10\n",
            "hook_embed torch.Size([1, 10, 768])\n",
            "hook_pos_embed torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_pre torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.ln1.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln1.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.attn.hook_q torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_k torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_v torch.Size([1, 10, 12, 64])\n",
            "blocks.0.attn.hook_attn_scores torch.Size([1, 12, 10, 10])\n",
            "blocks.0.attn.hook_pattern torch.Size([1, 12, 10, 10])\n",
            "blocks.0.attn.hook_z torch.Size([1, 10, 12, 64])\n",
            "blocks.0.hook_attn_out torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_mid torch.Size([1, 10, 768])\n",
            "blocks.0.ln2.hook_scale torch.Size([1, 10, 1])\n",
            "blocks.0.ln2.hook_normalized torch.Size([1, 10, 768])\n",
            "blocks.0.mlp.hook_pre torch.Size([1, 10, 3072])\n",
            "blocks.0.mlp.hook_post torch.Size([1, 10, 3072])\n",
            "blocks.0.hook_mlp_out torch.Size([1, 10, 768])\n",
            "blocks.0.hook_resid_post torch.Size([1, 10, 768])\n",
            "ln_final.hook_scale torch.Size([1, 10, 1])\n",
            "ln_final.hook_normalized torch.Size([1, 10, 768])\n"
          ]
        }
      ],
      "source": [
        "test_prompt = \"The quick brown fox jumped over the lazy dog\"\n",
        "print(\"Num tokens:\", len(model.to_tokens(test_prompt)[0]))\n",
        "\n",
        "def print_name_shape_hook_function(activation, hook):\n",
        "    print(hook.name, activation.shape)\n",
        "\n",
        "not_in_late_block_filter = lambda name: name.startswith(\"blocks.0.\") or not name.startswith(\"blocks\")\n",
        "\n",
        "model.run_with_hooks(\n",
        "    test_prompt,\n",
        "    return_type=None,\n",
        "    fwd_hooks=[(not_in_late_block_filter, print_name_shape_hook_function)],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bAUdDR4Gxw6b"
      },
      "source": [
        "### Folding LayerNorm (For the Curious)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJno_MBLxw6b"
      },
      "source": [
        "(For the curious - this is an important technical detail that's worth understanding, especially if you have preconceptions about how transformers work, but not necessary to use TransformerLens)\n",
        "\n",
        "LayerNorm is a normalization technique used by transformers, analogous to BatchNorm but more friendly to massive parallelisation. No one *really* knows why it works, but it seems to improve model numerical stability. Unlike BatchNorm, LayerNorm actually changes the functional form of the model, which makes it a massive pain for interpretability!\n",
        "\n",
        "Folding LayerNorm is a technique to make it lower overhead to deal with, and the flags `center_writing_weights` and `fold_ln` in `HookedTransformer.from_pretrained` apply this automatically (they default to True). These simplify the internal structure without changing the weights.\n",
        "\n",
        "Intuitively, LayerNorm acts on each residual stream vector (ie for each batch element and token position) independently, sets their mean to 0 (centering) and standard deviation to 1 (normalizing) (*across* the residual stream dimension - very weird!), and then applies a learned elementwise scaling and translation to each vector.\n",
        "\n",
        "Mathematically, centering is a linear map, normalizing is *not* a linear map, and scaling and translation are linear maps.\n",
        "* **Centering:** LayerNorm is applied every time a layer reads from the residual stream, so the mean of any residual stream vector can never matter - `center_writing_weights` set every weight matrix writing to the residual to have zero mean.\n",
        "* **Normalizing:** Normalizing is not a linear map, and cannot be factored out. The `hook_scale` hook point lets you access and control for this.\n",
        "* **Scaling and Translation:** Scaling and translation are linear maps, and are always followed by another linear map. The composition of two linear maps is another linear map, so we can *fold* the scaling and translation weights into the weights of the subsequent layer, and simplify things without changing the underlying computation.\n",
        "\n",
        "[See the docs for more details](https://github.com/TransformerLensOrg/TransformerLens/blob/main/further_comments.md#what-is-layernorm-folding-fold_ln)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74VEMeOvxw6b"
      },
      "source": [
        "A fun consequence of LayerNorm folding is that it creates a bias across the unembed, a `d_vocab` length vector that is added to the output logits - GPT-2 is not trained with this, but it *is* trained with a final LayerNorm that contains a bias.\n",
        "\n",
        "Turns out, this LayerNorm bias learns structure of the data that we can only see after folding! In particular, it essentially learns **unigram statistics** - rare tokens get suppressed, common tokens get boosted, by pretty dramatic degrees! Let's list the top and bottom 20 - at the top we see common punctuation and words like \" the\" and \" and\", at the bottom we see weird-ass tokens like \" RandomRedditor\":"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "FdTsYu-Mxw6c"
      },
      "outputs": [],
      "source": [
        "unembed_bias = model.unembed.b_U\n",
        "bias_values, bias_indices = unembed_bias.sort(descending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "J9E2h1DDxw6c",
        "outputId": "1d0791fc-edaa-4d65-8518-fa3a15596d18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 values\n",
            "7.03 ','\n",
            "6.98 ' the'\n",
            "6.68 ' and'\n",
            "6.49 '.'\n",
            "6.48 '\\n'\n",
            "6.47 ' a'\n",
            "6.41 ' in'\n",
            "6.25 ' to'\n",
            "6.16 ' of'\n",
            "6.04 '-'\n",
            "6.03 ' ('\n",
            "5.88 ' \"'\n",
            "5.80 ' for'\n",
            "5.72 ' that'\n",
            "5.64 ' on'\n",
            "5.59 ' is'\n",
            "5.52 ' as'\n",
            "5.49 ' at'\n",
            "5.45 ' with'\n",
            "5.44 ' or'\n",
            "...\n",
            "Bottom 20 values\n",
            "-3.82 ' サーティ'\n",
            "-3.83 '\\x18'\n",
            "-3.83 '\\x14'\n",
            "-3.83 ' RandomRedditor'\n",
            "-3.83 '龍�'\n",
            "-3.83 '�'\n",
            "-3.83 '\\x1b'\n",
            "-3.83 '�'\n",
            "-3.83 '\\x05'\n",
            "-3.83 '\\x00'\n",
            "-3.83 '\\x06'\n",
            "-3.83 '\\x07'\n",
            "-3.83 '\\x0c'\n",
            "-3.83 '\\x02'\n",
            "-3.83 'oreAndOnline'\n",
            "-3.84 '\\x11'\n",
            "-3.84 '�'\n",
            "-3.84 '\\x10'\n",
            "-3.84 '�'\n",
            "-3.84 '�'\n"
          ]
        }
      ],
      "source": [
        "top_k = 20\n",
        "print(f\"Top {top_k} values\")\n",
        "for i in range(top_k):\n",
        "    print(f\"{bias_values[i].item():.2f} {repr(model.to_string(bias_indices[i]))}\")\n",
        "\n",
        "print(\"...\")\n",
        "print(f\"Bottom {top_k} values\")\n",
        "for i in range(top_k, 0, -1):\n",
        "    print(f\"{bias_values[-i].item():.2f} {repr(model.to_string(bias_indices[-i]))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iZVYgAuxw6c"
      },
      "source": [
        "This can have real consequences for interpretability - for example, this bias favours \" John\" over \" Mary\" by about 1.2, about 1/3 of the effect size of the Indirect Object Identification Circuit! All other things being the same, this makes the John token 3.6x times more likely than the Mary token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "N_uFJSGCxw6c",
        "outputId": "26b0fb45-dec4-4245-9b7d-d2687f7a017b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "John bias: 2.8995\n",
            "Mary bias: 1.6034\n",
            "Prob ratio bias: 3.6550x\n"
          ]
        }
      ],
      "source": [
        "john_bias = model.unembed.b_U[model.to_single_token(' John')]\n",
        "mary_bias = model.unembed.b_U[model.to_single_token(' Mary')]\n",
        "\n",
        "print(f\"John bias: {john_bias.item():.4f}\")\n",
        "print(f\"Mary bias: {mary_bias.item():.4f}\")\n",
        "print(f\"Prob ratio bias: {torch.exp(john_bias - mary_bias).item():.4f}x\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lM2QwpdJxw6d"
      },
      "source": [
        "# Features\n",
        "\n",
        "An overview of some other important features of the library. I recommend checking out the [Exploratory Analysis Demo](https://colab.research.google.com/github/TransformerLensOrg/Easy-Transformer/blob/main/Exploratory_Analysis_Demo.ipynb) for some other important features not mentioned here, and for a demo of what using the library in practice looks like."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hfHkbYmZxw6d"
      },
      "source": [
        "## Dealing with tokens\n",
        "\n",
        "**Tokenization** is one of the most annoying features of studying language models. We want language models to be able to take in arbitrary text as input, but the transformer architecture needs the inputs to be elements of a fixed, finite vocabulary. The solution to this is **tokens**, a fixed vocabulary of \"sub-words\", that any natural language can be broken down into with a **tokenizer**. This is invertible, and we can recover the original text, called **de-tokenization**.\n",
        "\n",
        "TransformerLens comes with a range of utility functions to deal with tokenization. Different models can have different tokenizers, so these are all methods on the model.\n",
        "\n",
        "get_token_position, to_tokens, to_string, to_str_tokens, prepend_bos, to_single_token"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxzzP28Mxw6e"
      },
      "source": [
        "The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n",
        "\n",
        "Some observations - there are a lot of arbitrary-ish details in here!\n",
        "* The tokenizer splits on spaces, so no token contains two words.\n",
        "* Tokens include the preceding space, and whether the first token is a capital letter. `how` and ` how` are different tokens!\n",
        "* Common words are single tokens, even if fairly long (` paragraph`) while uncommon words are split into multiple tokens (` token|ized`).\n",
        "* Tokens *mostly* split on punctuation characters (eg `*` and `.`), but eg `'s` is a single token."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Oc9VIeThxw6e",
        "outputId": "2dcb84a3-15d8-41e9-e458-ca2dc881e773",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<|endoftext|>', 'The', ' first', ' thing', ' you', ' need', ' to', ' figure', ' out', ' is', ' *', 'how', '*', ' things', ' are', ' token', 'ized', '.', ' `', 'model', '.', 'to', '_', 'str', '_', 't', 'ok', 'ens', '`', ' splits', ' a', ' string', ' into', ' the', ' tokens', ' *', 'as', ' a', ' list', ' of', ' sub', 'strings', '*,', ' and', ' so', ' lets', ' you', ' explore', ' what', ' the', ' text', ' looks', ' like', '.', ' To', ' demonstrate', ' this', ',', ' let', \"'s\", ' use', ' it', ' on', ' this', ' paragraph', '.']\n"
          ]
        }
      ],
      "source": [
        "example_text = \"The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\"\n",
        "example_text_str_tokens = model.to_str_tokens(example_text)\n",
        "print(example_text_str_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Av7l39wmxw6e"
      },
      "source": [
        "The transformer needs to take in a sequence of integers, not strings, so we need to convert these tokens into integers. `model.to_tokens` does this, and returns a tensor of integers on the model's device (shape `[batch, position]`). It maps a string to a batch of size 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "2NOLGHyGxw6f",
        "outputId": "3b17960f-537f-459d-81d9-2beb2b8420e6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[50256,   464,   717,  1517,   345,   761,   284,  3785,   503,   318,\n",
            "          1635,  4919,     9,  1243,   389, 11241,  1143,    13,  4600, 19849,\n",
            "            13,  1462,    62,  2536,    62,    83,   482,   641,    63, 30778,\n",
            "           257,  4731,   656,   262, 16326,  1635,   292,   257,  1351,   286,\n",
            "           850, 37336, 25666,   290,   523,  8781,   345,  7301,   644,   262,\n",
            "          2420,  3073,   588,    13,  1675, 10176,   428,    11,  1309,   338,\n",
            "           779,   340,   319,   428,  7322,    13]], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "example_text_tokens = model.to_tokens(example_text)\n",
        "print(example_text_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ei2DUVraxw6f"
      },
      "source": [
        "`to_tokens` can also take in a list of strings, and return a batch of size `len(strings)`. If the strings are different numbers of tokens, it adds a PAD token to the end of the shorter strings to make them the same length.\n",
        "\n",
        "(Note: In GPT-2, 50256 signifies both the beginning of sequence, end of sequence and padding token - see the `prepend_bos` section for details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7zP-KZhyxw6f",
        "outputId": "536be5bb-03f0-45dc-84aa-f1e0adca2030"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor([[50256,   464,  3797,  3332,   319,   262,  2603,    13, 50256, 50256],\n",
            "        [50256,   464,  3797,  3332,   319,   262,  2603,  1107,  1327,    13]])\n"
          ]
        }
      ],
      "source": [
        "example_multi_text = [\"The cat sat on the mat.\", \"The cat sat on the mat really hard.\"]\n",
        "example_multi_text_tokens = model.to_tokens(example_multi_text)\n",
        "print(example_multi_text_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtlZomVFxw6g"
      },
      "source": [
        "`model.to_single_token` is a convenience function that takes in a string corresponding to a *single* token and returns the corresponding integer. This is useful for eg looking up the logit corresponding to a single token.\n",
        "\n",
        "For example, let's input `The cat sat on the mat.` to GPT-2, and look at the log prob predicting that the next token is ` The`.\n",
        "\n",
        "<details><summary>Technical notes</summary>\n",
        "\n",
        "Note that if we input a string to the model, it's implicitly converted to a string with `to_tokens`.\n",
        "\n",
        "Note further that the log probs have shape `[batch, position, d_vocab]==[1, 8, 50257]`, with a vector of log probs predicting the next token for *every* token position. GPT-2 uses causal attention which means heads can only look backwards (equivalently, information can only move forwards in the model.), so the log probs at position k are only a function of the first k tokens, and it can't just cheat and look at the k+1 th token. This structure lets it generate text more efficiently, and lets it treat every *token* as a training example, rather than every *sequence*.\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "fy411KEOxw6g",
        "outputId": "52d75cb0-2dea-4add-d9a2-2496833ead84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability tensor shape [batch, position, d_vocab] == torch.Size([1, 8, 50257])\n",
            "| The| probability: 11.98%\n"
          ]
        }
      ],
      "source": [
        "cat_text = \"The cat sat on the mat.\"\n",
        "cat_logits = model(cat_text)\n",
        "cat_probs = cat_logits.softmax(dim=-1)\n",
        "print(f\"Probability tensor shape [batch, position, d_vocab] == {cat_probs.shape}\")\n",
        "\n",
        "capital_the_token_index = model.to_single_token(\" The\")\n",
        "print(f\"| The| probability: {cat_probs[0, -1, capital_the_token_index].item():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZhCVR-Rxw6h"
      },
      "source": [
        "`model.to_string` is the inverse of `to_tokens` and maps a tensor of integers to a string or list of strings. It also works on integers and lists of integers.\n",
        "\n",
        "For example, let's look up token 256 (due to technical details of tokenization, this will be the most common pair of ASCII characters!), and also verify that our tokens above map back to a string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "hgRMwProxw6h",
        "outputId": "a98e2c44-ac2e-45b1-eaff-8a509e594414",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token 256 - the most common pair of ASCII characters: | t|\n",
            "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
        "# Squeeze means to remove dimensions of length 1.\n",
        "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
        "# Rank 2 tensors map to a list of strings\n",
        "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQqvW-SAxw6i"
      },
      "source": [
        "A related annoyance of tokenization is that it's hard to figure out how many tokens a string will break into. `model.get_token_position(single_token, tokens)` returns the position of `single_token` in `tokens`. `tokens` can be either a string or a tensor of tokens.\n",
        "\n",
        "Note that position is zero-indexed, it's two (ie third) because there's a beginning of sequence token automatically prepended (see the next section for details)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "G_DMtBUdxw6i",
        "outputId": "c0199914-0e99-47a2-8bb6-26533ee84384",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "With BOS: 2\n",
            "Without BOS: 1\n"
          ]
        }
      ],
      "source": [
        "print(\"With BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\"))\n",
        "print(\"Without BOS:\", model.get_token_position(\" cat\", \"The cat sat on the mat\", prepend_bos=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSfmeQJMxw6i"
      },
      "source": [
        "If there are multiple copies of the token, we can set `mode=\"first\"` to find the first occurrence's position and `mode=\"last\"` to find the last"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "MadVZ_UVxw6j",
        "outputId": "cef1e8bc-e02c-4d61-cc7a-3f78c6fa383b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First occurrence 2\n",
            "Final occurrence 13\n"
          ]
        }
      ],
      "source": [
        "print(\"First occurrence\", model.get_token_position(\n",
        "    \" cat\",\n",
        "    \"The cat sat on the mat. The mat sat on the cat.\",\n",
        "    mode=\"first\"))\n",
        "print(\"Final occurrence\", model.get_token_position(\n",
        "    \" cat\",\n",
        "    \"The cat sat on the mat. The mat sat on the cat.\",\n",
        "    mode=\"last\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlE7nO3nxw6j"
      },
      "source": [
        "In general, tokenization is a pain, and full of gotchas. I highly recommend just playing around with different inputs and their tokenization and getting a feel for it. As another \"fun\" example, let's look at the tokenization of arithmetic expressions - tokens do *not* contain consistent numbers of digits. (This makes it even more impressive that GPT-3 can do arithmetic!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kvh0D2daxw6k",
        "outputId": "768ed9b6-2771-4624-818d-38ff7275c37c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['<|endoftext|>', '23', '42', '+', '2017', '=', '214', '45']\n",
            "['<|endoftext|>', '1000', '+', '1', '000000', '=', '9999', '99']\n"
          ]
        }
      ],
      "source": [
        "print(model.to_str_tokens(\"2342+2017=21445\"))\n",
        "print(model.to_str_tokens(\"1000+1000000=999999\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C0a8pzfxw6k"
      },
      "source": [
        "I also *highly* recommend investigating prompts with easy tokenization when starting out - ideally key words should form a single token, be in the same position in different prompts, have the same total length, etc. Eg study Indirect Object Identification with common English names like ` Tim` rather than ` Ne|el`. Transformers need to spend some parameters in early layers converting multi-token words to a single feature, and then de-converting this in the late layers, and unless this is what you're explicitly investigating, this will make the behaviour you're investigating be messier."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnQjsnHoxw6k"
      },
      "source": [
        "### Gotcha: `prepend_bos`\n",
        "\n",
        "Key Takeaway: **If you get weird off-by-one errors, check whether there's an unexpected `prepend_bos`!**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vuPY57qUxw6k"
      },
      "source": [
        "A weirdness you may have noticed in the above is that `to_tokens` and `to_str_tokens` added a weird `<|endoftext|>` to the start of each prompt. TransformerLens does this by default, and it can easily trip up new users. Notably, **this includes `model.forward`** (which is what's implicitly used when you do eg `model(\"Hello World\")`). This is called a **Beginning of Sequence (BOS)** token, and it's a special token used to mark the beginning of the sequence. Confusingly, in GPT-2, the End of Sequence (EOS), Beginning of Sequence (BOS) and Padding (PAD) tokens are all the same, `<|endoftext|>` with index `50256`.\n",
        "\n",
        "**Gotcha:** You only want to prepend a BOS token at the *start* of a prompt. If you, eg, want to input a question followed by an answer, and want to tokenize these separately, you do *not* want to prepend_bos on the answer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tWo3Hh2Vxw6l",
        "outputId": "86d79149-1f68-45cf-ce66-166521593db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logits shape by default (with BOS) torch.Size([1, 3, 50257])\n",
            "Logits shape with BOS torch.Size([1, 3, 50257])\n",
            "Logits shape without BOS - only 2 positions! torch.Size([1, 2, 50257])\n"
          ]
        }
      ],
      "source": [
        "print(\"Logits shape by default (with BOS)\", model(\"Hello World\").shape)\n",
        "print(\"Logits shape with BOS\", model(\"Hello World\", prepend_bos=True).shape)\n",
        "print(\"Logits shape without BOS - only 2 positions!\", model(\"Hello World\", prepend_bos=False).shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jk-IiFWixw6l"
      },
      "source": [
        "`prepend_bos` is a bit of a hack, and I've gone back and forth on what the correct default here is. The reason I do this is that transformers tend to treat the first token weirdly - this doesn't really matter in training (where all inputs are >1000 tokens), but this can be a big issue when investigating short prompts! The reason for this is that attention patterns are a probability distribution and so need to add up to one, so to simulate being \"off\" they normally look at the first token. Giving them a BOS token lets the heads rest by looking at that, preserving the information in the first \"real\" token.\n",
        "\n",
        "Further, *some* models are trained to need a BOS token (OPT and my interpretability-friendly models are, GPT-2 and GPT-Neo are not). But despite GPT-2 not being trained with this, empirically it seems to make interpretability easier.\n",
        "\n",
        "(However, if you want to change the default behaviour to *not* prepending a BOS token, pass `default_prepend_bos=False` when you instantiate the model, e.g., `model = HookedTransformer.from_pretrained('gpt2', default_prepend_bos=False)`.)\n",
        "\n",
        "For example, the model can get much worse at Indirect Object Identification without a BOS (and with a name as the first token):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FnDd4r8-xw6l",
        "outputId": "53294ba1-ff36-419e-88d7-2bbd957ecfdb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Logit difference with BOS: 6.754\n",
            "Logit difference without BOS: 2.782\n"
          ]
        }
      ],
      "source": [
        "ioi_logits_with_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=True)\n",
        "mary_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
        "claire_logit_with_bos = ioi_logits_with_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
        "print(f\"Logit difference with BOS: {(claire_logit_with_bos - mary_logit_with_bos):.3f}\")\n",
        "\n",
        "ioi_logits_without_bos = model(\"Claire and Mary went to the shops, then Mary gave a bottle of milk to\", prepend_bos=False)\n",
        "mary_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Mary\")].item()\n",
        "claire_logit_without_bos = ioi_logits_without_bos[0, -1, model.to_single_token(\" Claire\")].item()\n",
        "print(f\"Logit difference without BOS: {(claire_logit_without_bos - mary_logit_without_bos):.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXEuXbfLxw6l"
      },
      "source": [
        "Though, note that this also illustrates another gotcha - when `Claire` is at the start of a sentence (no preceding space), it's actually *two* tokens, not one, which probably confuses the relevant circuit. (Note - in this test we put `prepend_bos=False`, because we want to analyse the tokenization of a specific string, not to give an input to the model!)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRAjFuNsxw6m",
        "outputId": "98387883-2978-43c8-c03a-3210c244b6f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "| Claire| -> [' Claire']\n",
            "|Claire| -> ['Cl', 'aire']\n"
          ]
        }
      ],
      "source": [
        "print(f\"| Claire| -> {model.to_str_tokens(' Claire', prepend_bos=False)}\")\n",
        "print(f\"|Claire| -> {model.to_str_tokens('Claire', prepend_bos=False)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9etjVGt_xw6m"
      },
      "source": [
        "## Factored Matrix Class\n",
        "\n",
        "In transformer interpretability, we often need to analyse low rank factorized matrices - a matrix $M = AB$, where M is `[large, large]`, but A is `[large, small]` and B is `[small, large]`. This is a common structure in transformers, and the `FactoredMatrix` class is a convenient way to work with these. It implements efficient algorithms for various operations on these, such as computing the trace, eigenvalues, Frobenius norm, singular value decomposition, and products with other matrices. It can (approximately) act as a drop-in replacement for the original matrix, and supports leading batch dimensions to the factored matrix.\n",
        "\n",
        "<details><summary>Why are low-rank factorized matrices useful for transformer interpretability?</summary>\n",
        "\n",
        "As argued in [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html), an unexpected fact about transformer attention heads is that rather than being best understood as keys, queries and values (and the requisite weight matrices), they're actually best understood as two low rank factorized matrices.\n",
        "* **Where to move information from:** $W_QK = W_Q W_K^T$, used for determining the attention pattern - what source positions to move information from and what destination positions to move them to.\n",
        "    * Intuitively, residual stream -> query and residual stream -> key are linear maps, *and* `attention_score = query @ key.T` is a linear map, so the whole thing can be factored into one big bilinear form `residual @ W_QK @ residual.T`\n",
        "* **What information to move:** $W_OV = W_V W_O$, used to determine what information to copy from the source position to the destination position (weighted by the attention pattern weight from that destination to that source).\n",
        "    * Intuitively, the residual stream is a `[position, d_model]` tensor (ignoring batch). The attention pattern acts on the *position* dimension (where to move information from and to) and the value and output weights act on the *d_model* dimension - ie *what* information is contained at that source position. So we can factor it all into `attention_pattern @ residual @ W_V @ W_O`, and so only need to care about `W_OV = W_V @ W_O`\n",
        "* Note - the internal head dimension is smaller than the residual stream dimension, so the factorization is low rank. (here, `d_model=768` and `d_head=64`)\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfgZvxIzxw6m"
      },
      "source": [
        "### Basic Examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zXlBJvbxw6m"
      },
      "source": [
        "We can use the basic class directly - let's make a factored matrix directly and look at the basic operations:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_Ml_V6Hxw6m",
        "outputId": "ced2daa3-9c89-4397-9ae2-772c6e6b8c53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Norms:\n",
            "tensor(9.9105)\n",
            "tensor(9.9105)\n",
            "Right dimension: 5, Left dimension: 5, Hidden dimension: 2\n"
          ]
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "A = torch.randn(5, 2)\n",
        "B = torch.randn(2, 5)\n",
        "\n",
        "AB = A @ B\n",
        "AB_factor = FactoredMatrix(A, B)\n",
        "print(\"Norms:\")\n",
        "print(AB.norm())\n",
        "print(AB_factor.norm())\n",
        "\n",
        "print(f\"Right dimension: {AB_factor.rdim}, Left dimension: {AB_factor.ldim}, Hidden dimension: {AB_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIjyFkzMxw6n"
      },
      "source": [
        "We can also look at the eigenvalues and singular values of the matrix. Note that, because the matrix is rank 2 but 5 by 5, the final 3 eigenvalues and singular values are zero - the factored class omits the zeros."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5kFIuRAxw6n",
        "outputId": "eddefa4b-a6a6-417d-bbd2-ebd16c18d8c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eigenvalues:\n",
            "tensor([-6.2877e+00+0.j,  1.9337e-07+0.j,  2.3121e+00+0.j, -5.9987e-07+0.j,\n",
            "        -1.1409e-07+0.j])\n",
            "tensor([-6.2877+0.j,  2.3121+0.j])\n",
            "\n",
            "Singular Values:\n",
            "tensor([8.3126e+00, 5.3963e+00, 1.4519e-07, 7.4293e-08, 2.1726e-09])\n",
            "tensor([8.3126, 5.3963])\n"
          ]
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "print(\"Eigenvalues:\")\n",
        "print(torch.linalg.eig(AB).eigenvalues)\n",
        "print(AB_factor.eigenvalues)\n",
        "print()\n",
        "print(\"Singular Values:\")\n",
        "print(torch.linalg.svd(AB).S)\n",
        "print(AB_factor.S)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-tJ7qOSxw6n"
      },
      "source": [
        "We can multiply with other matrices - it automatically chooses the smallest possible dimension to factor along (here it's 2, rather than 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_JBIrw9xw6n",
        "outputId": "b804662a-444d-445c-f8d1-8ab876c3a141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Unfactored: torch.Size([5, 300]) tensor(160.0830)\n",
            "Factored: torch.Size([5, 300]) tensor(160.0830)\n",
            "Right dimension: 300, Left dimension: 5, Hidden dimension: 2\n"
          ]
        }
      ],
      "source": [
        "if IN_GITHUB:\n",
        "    torch.manual_seed(50)\n",
        "\n",
        "C = torch.randn(5, 300)\n",
        "\n",
        "ABC = AB @ C\n",
        "ABC_factor = AB_factor @ C\n",
        "print(\"Unfactored:\", ABC.shape, ABC.norm().round(decimals=3))\n",
        "print(\"Factored:\", ABC_factor.shape, ABC_factor.norm().round(decimals=3))\n",
        "print(f\"Right dimension: {ABC_factor.rdim}, Left dimension: {ABC_factor.ldim}, Hidden dimension: {ABC_factor.mdim}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIplqfWkxw6o"
      },
      "source": [
        "If we want to collapse this back to an unfactored matrix, we can use the AB property to get the product:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h61XECFExw6o",
        "outputId": "321dcb93-a1f8-4517-b448-ff37aafea57e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(True)\n"
          ]
        }
      ],
      "source": [
        "AB_unfactored = AB_factor.AB\n",
        "print(torch.isclose(AB_unfactored, AB).all())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyyX-sP5xw6p"
      },
      "source": [
        "### Medium Example: Eigenvalue Copying Scores\n",
        "\n",
        "(This is a more involved example of how to use the factored matrix class, skip it if you aren't following)\n",
        "\n",
        "For a more involved example, let's look at the eigenvalue copying score from [A Mathematical Framework](https://transformer-circuits.pub/2021/framework/index.html) of the OV circuit for various heads. The OV Circuit for a head (the factorised matrix $W_OV = W_V W_O$) is a linear map that determines what information is moved from the source position to the destination position. Because this is low rank, it can be thought of as *reading in* some low rank subspace of the source residual stream and *writing to* some low rank subspace of the destination residual stream (with maybe some processing happening in the middle).\n",
        "\n",
        "A common operation for this will just be to *copy*, ie to have the same reading and writing subspace, and to do minimal processing in the middle. Empirically, this tends to coincide with the OV Circuit having (approximately) positive real eigenvalues. I mostly assert this as an empirical fact, but intuitively, operations that involve mapping eigenvectors to different directions (eg rotations) tend to have complex eigenvalues. And operations that preserve eigenvector direction but negate it tend to have negative real eigenvalues. And \"what happens to the eigenvectors\" is a decent proxy for what happens to an arbitrary vector.\n",
        "\n",
        "We can get a score for \"how positive real the OV circuit eigenvalues are\" with $\\frac{\\sum \\lambda_i}{\\sum |\\lambda_i|}$, where $\\lambda_i$ are the eigenvalues of the OV circuit. This is a bit of a hack, but it seems to work well in practice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_NIHrGUxw6p"
      },
      "source": [
        "Let's use FactoredMatrix to compute this for every head in the model! We use the helper `model.OV` to get the concatenated OV circuits for all heads across all layers in the model. This has the shape `[n_layers, n_heads, d_model, d_model]`, where `n_layers` and `n_heads` are batch dimensions and the final two dimensions are factorised as `[n_layers, n_heads, d_model, d_head]` and `[n_layers, n_heads, d_head, d_model]` matrices.\n",
        "\n",
        "We can then get the eigenvalues for this, where there are separate eigenvalues for each element of the batch (a `[n_layers, n_heads, d_head]` tensor of complex numbers), and calculate the copying score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PcXEqfHixw6p",
        "outputId": "e6bc6872-e96b-44a1-b2f7-743390589410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FactoredMatrix: Shape(torch.Size([12, 12, 768, 768])), Hidden Dim(64)\n"
          ]
        }
      ],
      "source": [
        "OV_circuit_all_heads = model.OV\n",
        "print(OV_circuit_all_heads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49ycKGIgxw6q",
        "outputId": "12dc947c-a063-4e30-fcad-5b3bc679b339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12, 12, 64])\n",
            "torch.complex64\n"
          ]
        }
      ],
      "source": [
        "OV_circuit_all_heads_eigenvalues = OV_circuit_all_heads.eigenvalues\n",
        "print(OV_circuit_all_heads_eigenvalues.shape)\n",
        "print(OV_circuit_all_heads_eigenvalues.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DybZBT15xw6q",
        "outputId": "9300a541-f6ce-4112-e6c9-fd293aabfd38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"a09834af-1357-479f-b958-ca36d205cbf8\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a09834af-1357-479f-b958-ca36d205cbf8\")) {                    Plotly.newPlot(                        \"a09834af-1357-479f-b958-ca36d205cbf8\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.7775010466575623,0.3527269959449768,0.25961846113204956,0.6670257449150085,0.8384260535240173,0.5584430694580078,0.8444744944572449,0.4137910008430481,0.24488940834999084,0.028157662600278854,0.3584098219871521,0.16288265585899353],[-0.45419126749038696,-0.6529328227043152,-0.5484569072723389,-0.7990369200706482,-0.7736425995826721,-0.8522581458091736,0.9774324893951416,0.6626249551773071,-0.7303224205970764,-0.7007019519805908,-0.6946625709533691,-0.9996722340583801],[-0.7837163805961609,0.8967759013175964,0.4750954806804657,-0.667197585105896,0.7881461977958679,-0.8547751307487488,-0.9054184556007385,-0.5749384760856628,-0.32175111770629883,-0.028594352304935455,-0.9247617721557617,-0.9699268341064453],[0.5864037275314331,-0.7614347338676453,0.5971695780754089,0.7854393720626831,-0.8788883686065674,0.3908745050430298,0.044738516211509705,0.11028008162975311,-0.8169988989830017,0.22129566967487335,-0.9939578771591187,0.5774399042129517],[0.525479257106781,0.3049013912677765,-0.10729152709245682,0.9433151483535767,-0.9314428567886353,0.5273632407188416,-0.4264712631702423,-0.9984429478645325,0.5296756029129028,0.8604294061660767,-0.8895052075386047,0.9556970596313477],[0.6629186868667603,0.42956963181495667,0.9736858010292053,0.6555483937263489,0.12201889604330063,0.7442770004272461,0.5037952661514282,0.9525359272956848,-0.6507164239883423,-0.9316279292106628,0.9791510105133057,-0.9972584843635559],[0.9613031148910522,0.7501779794692993,-0.3806658685207367,0.6429786682128906,0.9557769298553467,-0.9428839683532715,-0.9948079586029053,0.785298764705658,0.9657301306724548,0.707301676273346,0.3687230050563812,0.8128011226654053],[0.9659481644630432,0.9730121493339539,0.31900617480278015,-0.30290520191192627,0.9790953397750854,0.9357923269271851,-0.5550313591957092,-0.005466493312269449,0.9867776036262512,0.8249565958976746,0.566429615020752,0.1000526174902916],[-0.9464486837387085,-0.25471997261047363,0.6522327661514282,0.1415255218744278,0.9884140491485596,0.9860583543777466,0.6949270367622375,0.9901810884475708,0.9791202545166016,-0.2359553426504135,-0.9820711612701416,0.6506689190864563],[0.9895943999290466,-0.29178157448768616,0.9714024662971497,0.9951602220535278,0.18783769011497498,-0.9460937976837158,0.47801902890205383,-0.2489192932844162,0.9437097907066345,0.11866245418787003,0.9941242933273315,-0.38088178634643555],[0.9564487934112549,0.5542725920677185,0.42118048667907715,0.6628789901733398,0.8659590482711792,0.9937117695808411,0.9069075584411621,0.39811065793037415,-0.4134220480918884,0.9971913695335388,0.34596705436706543,0.9938657283782959],[0.5891268849372864,0.9313740134239197,0.9268401861190796,0.9993564486503601,0.6227539777755737,0.8463947772979736,0.6584346294403076,0.8423126339912415,0.2978496253490448,0.8728679418563843,0.9963144659996033,0.986752450466156]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a09834af-1357-479f-b958-ca36d205cbf8');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "OV_copying_score = OV_circuit_all_heads_eigenvalues.sum(dim=-1).real / OV_circuit_all_heads_eigenvalues.abs().sum(dim=-1)\n",
        "imshow(utils.to_numpy(OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkuG58z0xw6q"
      },
      "source": [
        "Head 11 in Layer 11 (L11H11) has a high copying score, and if we plot the eigenvalues they look approximately as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KCBhcUjbxw6r",
        "outputId": "b698d786-d7b6-45fd-bcc0-9f7672a22836"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\")) {                    Plotly.newPlot(                        \"1e3711f8-c7bc-42a1-aea4-6c909a93f24e\",                        [{\"hovertemplate\":\"Real=%{x}\\u003cbr\\u003eImaginary=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[-2.1397297382354736,1.4152636528015137,3.444455146789551,4.027669906616211,8.882655143737793,4.866769790649414,4.866769790649414,4.843714714050293,4.843714714050293,8.477535247802734,8.216809272766113,8.216809272766113,5.07860803604126,7.855461120605469,7.855461120605469,5.365756034851074,5.365756034851074,5.563426971435547,5.563426971435547,5.4217329025268555,7.769133567810059,7.769133567810059,7.0422773361206055,7.0422773361206055,5.675145626068115,5.675145626068115,7.678577423095703,7.678577423095703,6.573329925537109,6.573329925537109,7.67294979095459,7.17219877243042,7.17219877243042,7.423620223999023,7.423620223999023,7.470810413360596,6.089095115661621,6.089095115661621,6.306834697723389,6.306834697723389,6.511750221252441,6.511750221252441,5.955246448516846,5.955246448516846,5.858811378479004,5.858811378479004,7.147887229919434,7.147887229919434,7.185712814331055,7.185712814331055,6.670608043670654,6.670608043670654,6.735983848571777,6.735983848571777,6.149757385253906,6.149757385253906,6.288776874542236,6.288776874542236,6.344796657562256,6.625571250915527,6.625571250915527,6.8991899490356445,6.8991899490356445,6.85640811920166],\"xaxis\":\"x\",\"y\":[0.0,0.0,0.0,0.0,0.0,0.4185231328010559,-0.4185231328010559,0.09079001098871231,-0.09079001098871231,0.0,0.40868881344795227,-0.40868881344795227,0.0,0.7007214426994324,-0.7007214426994324,0.46421411633491516,-0.46421411633491516,0.5558239817619324,-0.5558239817619324,0.0,0.4705662131309509,-0.4705662131309509,1.0298681259155273,-1.0298681259155273,0.48253530263900757,-0.48253530263900757,0.3356489837169647,-0.3356489837169647,0.9988697171211243,-0.9988697171211243,0.0,0.7531778812408447,-0.7531778812408447,0.4257569909095764,-0.4257569909095764,0.0,0.643626868724823,-0.643626868724823,0.7701709270477295,-0.7701709270477295,0.7558017373085022,-0.7558017373085022,0.25911131501197815,-0.25911131501197815,0.013043955899775028,-0.013043955899775028,0.40166252851486206,-0.40166252851486206,0.28192126750946045,-0.28192126750946045,0.6146255135536194,-0.6146255135536194,0.5391282439231873,-0.5391282439231873,0.28234055638313293,-0.28234055638313293,0.3528330624103546,-0.3528330624103546,0.0,0.24867765605449677,-0.24867765605449677,0.15545639395713806,-0.15545639395713806,0.0],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Real\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Imaginary\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Eigenvalues of Head L11H11 of GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1e3711f8-c7bc-42a1-aea4-6c909a93f24e');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scatter(x=OV_circuit_all_heads_eigenvalues[-1, -1, :].real, y=OV_circuit_all_heads_eigenvalues[-1, -1, :].imag, title=\"Eigenvalues of Head L11H11 of GPT-2 Small\", xaxis=\"Real\", yaxis=\"Imaginary\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OI7IfEeBxw6r"
      },
      "source": [
        "We can even look at the full OV circuit, from the input tokens to output tokens: $W_E W_V W_O W_U$. This is a `[d_vocab, d_vocab]==[50257, 50257]` matrix, so absolutely enormous, even for a single head. But with the FactoredMatrix class, we can compute the full eigenvalue copying score of every head in a few seconds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTk6GWeAxw6r",
        "outputId": "f8d00b2b-1ed2-484c-c0ac-45f2a660c1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "FactoredMatrix: Shape(torch.Size([12, 12, 50257, 50257])), Hidden Dim(64)\n"
          ]
        }
      ],
      "source": [
        "full_OV_circuit = model.embed.W_E @ OV_circuit_all_heads @ model.unembed.W_U\n",
        "print(full_OV_circuit)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwEJoiUaxw6r",
        "outputId": "c338ef04-226a-44ec-9497-e6414773df6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([12, 12, 64])\n",
            "torch.complex64\n"
          ]
        }
      ],
      "source": [
        "full_OV_circuit_eigenvalues = full_OV_circuit.eigenvalues\n",
        "print(full_OV_circuit_eigenvalues.shape)\n",
        "print(full_OV_circuit_eigenvalues.dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5EDl6HTLxw6s",
        "outputId": "2ed8f329-a518-4f03-c7d5-0d1082aee3a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\")) {                    Plotly.newPlot(                        \"c709dad6-6ca6-4c75-8231-0ee7b1e7e752\",                        [{\"coloraxis\":\"coloraxis\",\"name\":\"0\",\"z\":[[0.8356368541717529,0.5853535532951355,0.5105839967727661,0.7843376398086548,0.8644158840179443,0.7026588320732117,0.8969924449920654,0.5868821740150452,0.4248652160167694,-0.16337503492832184,0.4626856744289398,0.2760537266731262],[-0.05292005464434624,-0.3177315592765808,-0.4810580015182495,-0.783806562423706,-0.6360208988189697,-0.7758680582046509,0.9681803584098816,0.8119115233421326,-0.7510465383529663,-0.6878446340560913,-0.6429886221885681,-0.9985855221748352],[-0.6598327159881592,0.9152501821517944,0.5461500883102417,-0.4874398708343506,0.7720565795898438,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510942220688,0.24442273378372192,-0.9106623530387878,-0.9439151287078857],[0.6486894488334656,-0.5592910647392273,0.5935594439506531,0.7843042016029358,-0.8150346875190735,0.6130048036575317,0.16785870492458344,0.35195884108543396,-0.6837263107299805,0.22237683832645416,-0.9929219484329224,0.6535818576812744],[0.5740951299667358,0.3640132546424866,0.09609055519104004,0.9359623193740845,-0.9228774309158325,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448631286621094,0.8468661308288574,-0.7557657361030579,0.9527971148490906],[0.7326545715332031,0.532416820526123,0.9732668995857239,0.7239248752593994,0.25538960099220276,0.815841555595398,0.6655788421630859,0.9287101030349731,-0.5660438537597656,-0.890874445438385,0.9834234118461609,-0.9981180429458618],[0.9698693156242371,0.7439671158790588,-0.35639339685440063,0.6022988557815552,0.9708116054534912,-0.9278276562690735,-0.996231734752655,0.8345208168029785,0.9714328050613403,0.8158544898033142,0.5902576446533203,0.8199342489242554],[0.9820225834846497,0.9859328269958496,0.5152459144592285,-0.5610516667366028,0.9663665890693665,0.9495159983634949,-0.5204814076423645,0.3104749917984009,0.9859084486961365,0.7797460556030273,0.6738530397415161,0.3919741213321686],[-0.906204104423523,0.11750980466604233,0.8077875375747681,0.4169303774833679,0.9829014539718628,0.9902303218841553,0.7847102880477905,0.994563102722168,0.9868024587631226,-0.26804423332214355,-0.9908866882324219,0.745792806148529],[0.9906191825866699,-0.18231149017810822,0.97578364610672,0.9986749887466431,0.2544330358505249,-0.954406201839447,0.5869243144989014,-0.23537996411323547,0.9550502896308899,0.25511977076530457,0.9929870963096619,0.09052591770887375],[0.9707273244857788,0.6956093311309814,0.6280022263526917,0.7902867794036865,0.9343841075897217,0.989579439163208,0.9436283707618713,-0.10834993422031403,-0.3431112766265869,0.9986708760261536,0.5086739659309387,0.9949507713317871],[0.8283133506774902,0.9432437419891357,0.9491766095161438,0.9995352029800415,0.5712319612503052,0.8055234551429749,0.6781864166259766,0.8272571563720703,0.8314797282218933,0.8778656721115112,0.9944958686828613,0.9973865151405334]],\"type\":\"heatmap\",\"xaxis\":\"x\",\"yaxis\":\"y\",\"hovertemplate\":\"Head: %{x}\\u003cbr\\u003eLayer: %{y}\\u003cbr\\u003ecolor: %{z}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"scaleanchor\":\"y\",\"constrain\":\"domain\",\"title\":{\"text\":\"Head\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"autorange\":\"reversed\",\"constrain\":\"domain\",\"title\":{\"text\":\"Layer\"}},\"coloraxis\":{\"colorscale\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"cmid\":0.0,\"cmin\":-1.0,\"cmax\":1.0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c709dad6-6ca6-4c75-8231-0ee7b1e7e752');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "full_OV_copying_score = full_OV_circuit_eigenvalues.sum(dim=-1).real / full_OV_circuit_eigenvalues.abs().sum(dim=-1)\n",
        "imshow(utils.to_numpy(full_OV_copying_score), xaxis=\"Head\", yaxis=\"Layer\", title=\"OV Copying Score for each head in GPT-2 Small\", zmax=1.0, zmin=-1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQ0pnEXFxw6s"
      },
      "source": [
        "Interestingly, these are highly (but not perfectly!) correlated. I'm not sure what to read from this, or what's up with the weird outlier heads!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yp7IyZksxw6s",
        "outputId": "93759d87-792e-4841-b302-28e276fd9f17"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"3e59929d-31e9-49b1-ad1a-9d9811d4801d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"3e59929d-31e9-49b1-ad1a-9d9811d4801d\")) {                    Plotly.newPlot(                        \"3e59929d-31e9-49b1-ad1a-9d9811d4801d\",                        [{\"hovertemplate\":\"\\u003cb\\u003e%{hovertext}\\u003c\\u002fb\\u003e\\u003cbr\\u003e\\u003cbr\\u003eFull OV Copying Score=%{x}\\u003cbr\\u003eOV Copying Score=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"hovertext\":[\"L0H0\",\"L0H1\",\"L0H2\",\"L0H3\",\"L0H4\",\"L0H5\",\"L0H6\",\"L0H7\",\"L0H8\",\"L0H9\",\"L0H10\",\"L0H11\",\"L1H0\",\"L1H1\",\"L1H2\",\"L1H3\",\"L1H4\",\"L1H5\",\"L1H6\",\"L1H7\",\"L1H8\",\"L1H9\",\"L1H10\",\"L1H11\",\"L2H0\",\"L2H1\",\"L2H2\",\"L2H3\",\"L2H4\",\"L2H5\",\"L2H6\",\"L2H7\",\"L2H8\",\"L2H9\",\"L2H10\",\"L2H11\",\"L3H0\",\"L3H1\",\"L3H2\",\"L3H3\",\"L3H4\",\"L3H5\",\"L3H6\",\"L3H7\",\"L3H8\",\"L3H9\",\"L3H10\",\"L3H11\",\"L4H0\",\"L4H1\",\"L4H2\",\"L4H3\",\"L4H4\",\"L4H5\",\"L4H6\",\"L4H7\",\"L4H8\",\"L4H9\",\"L4H10\",\"L4H11\",\"L5H0\",\"L5H1\",\"L5H2\",\"L5H3\",\"L5H4\",\"L5H5\",\"L5H6\",\"L5H7\",\"L5H8\",\"L5H9\",\"L5H10\",\"L5H11\",\"L6H0\",\"L6H1\",\"L6H2\",\"L6H3\",\"L6H4\",\"L6H5\",\"L6H6\",\"L6H7\",\"L6H8\",\"L6H9\",\"L6H10\",\"L6H11\",\"L7H0\",\"L7H1\",\"L7H2\",\"L7H3\",\"L7H4\",\"L7H5\",\"L7H6\",\"L7H7\",\"L7H8\",\"L7H9\",\"L7H10\",\"L7H11\",\"L8H0\",\"L8H1\",\"L8H2\",\"L8H3\",\"L8H4\",\"L8H5\",\"L8H6\",\"L8H7\",\"L8H8\",\"L8H9\",\"L8H10\",\"L8H11\",\"L9H0\",\"L9H1\",\"L9H2\",\"L9H3\",\"L9H4\",\"L9H5\",\"L9H6\",\"L9H7\",\"L9H8\",\"L9H9\",\"L9H10\",\"L9H11\",\"L10H0\",\"L10H1\",\"L10H2\",\"L10H3\",\"L10H4\",\"L10H5\",\"L10H6\",\"L10H7\",\"L10H8\",\"L10H9\",\"L10H10\",\"L10H11\",\"L11H0\",\"L11H1\",\"L11H2\",\"L11H3\",\"L11H4\",\"L11H5\",\"L11H6\",\"L11H7\",\"L11H8\",\"L11H9\",\"L11H10\",\"L11H11\"],\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"symbol\":\"circle\"},\"mode\":\"markers\",\"name\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"x\":[0.8356368541717529,0.5853535532951355,0.5105839967727661,0.7843376398086548,0.8644158840179443,0.7026588320732117,0.8969924449920654,0.5868821740150452,0.4248652160167694,-0.16337503492832184,0.4626856744289398,0.2760537266731262,-0.05292005464434624,-0.3177315592765808,-0.4810580015182495,-0.783806562423706,-0.6360208988189697,-0.7758680582046509,0.9681803584098816,0.8119115233421326,-0.7510465383529663,-0.6878446340560913,-0.6429886221885681,-0.9985855221748352,-0.6598327159881592,0.9152501821517944,0.5461500883102417,-0.4874398708343506,0.7720565795898438,-0.7541061639785767,-0.8472450971603394,-0.6948987245559692,-0.1557510942220688,0.24442273378372192,-0.9106623530387878,-0.9439151287078857,0.6486894488334656,-0.5592910647392273,0.5935594439506531,0.7843042016029358,-0.8150346875190735,0.6130048036575317,0.16785870492458344,0.35195884108543396,-0.6837263107299805,0.22237683832645416,-0.9929219484329224,0.6535818576812744,0.5740951299667358,0.3640132546424866,0.09609055519104004,0.9359623193740845,-0.9228774309158325,0.6191076636314392,-0.33572638034820557,-0.998464822769165,0.6448631286621094,0.8468661308288574,-0.7557657361030579,0.9527971148490906,0.7326545715332031,0.532416820526123,0.9732668995857239,0.7239248752593994,0.25538960099220276,0.815841555595398,0.6655788421630859,0.9287101030349731,-0.5660438537597656,-0.890874445438385,0.9834234118461609,-0.9981180429458618,0.9698693156242371,0.7439671158790588,-0.35639339685440063,0.6022988557815552,0.9708116054534912,-0.9278276562690735,-0.996231734752655,0.8345208168029785,0.9714328050613403,0.8158544898033142,0.5902576446533203,0.8199342489242554,0.9820225834846497,0.9859328269958496,0.5152459144592285,-0.5610516667366028,0.9663665890693665,0.9495159983634949,-0.5204814076423645,0.3104749917984009,0.9859084486961365,0.7797460556030273,0.6738530397415161,0.3919741213321686,-0.906204104423523,0.11750980466604233,0.8077875375747681,0.4169303774833679,0.9829014539718628,0.9902303218841553,0.7847102880477905,0.994563102722168,0.9868024587631226,-0.26804423332214355,-0.9908866882324219,0.745792806148529,0.9906191825866699,-0.18231149017810822,0.97578364610672,0.9986749887466431,0.2544330358505249,-0.954406201839447,0.5869243144989014,-0.23537996411323547,0.9550502896308899,0.25511977076530457,0.9929870963096619,0.09052591770887375,0.9707273244857788,0.6956093311309814,0.6280022263526917,0.7902867794036865,0.9343841075897217,0.989579439163208,0.9436283707618713,-0.10834993422031403,-0.3431112766265869,0.9986708760261536,0.5086739659309387,0.9949507713317871,0.8283133506774902,0.9432437419891357,0.9491766095161438,0.9995352029800415,0.5712319612503052,0.8055234551429749,0.6781864166259766,0.8272571563720703,0.8314797282218933,0.8778656721115112,0.9944958686828613,0.9973865151405334],\"xaxis\":\"x\",\"y\":[0.7775010466575623,0.3527269959449768,0.25961846113204956,0.6670257449150085,0.8384260535240173,0.5584430694580078,0.8444744944572449,0.4137910008430481,0.24488940834999084,0.028157662600278854,0.3584098219871521,0.16288265585899353,-0.45419126749038696,-0.6529328227043152,-0.5484569072723389,-0.7990369200706482,-0.7736425995826721,-0.8522581458091736,0.9774324893951416,0.6626249551773071,-0.7303224205970764,-0.7007019519805908,-0.6946625709533691,-0.9996722340583801,-0.7837163805961609,0.8967759013175964,0.4750954806804657,-0.667197585105896,0.7881461977958679,-0.8547751307487488,-0.9054184556007385,-0.5749384760856628,-0.32175111770629883,-0.028594352304935455,-0.9247617721557617,-0.9699268341064453,0.5864037275314331,-0.7614347338676453,0.5971695780754089,0.7854393720626831,-0.8788883686065674,0.3908745050430298,0.044738516211509705,0.11028008162975311,-0.8169988989830017,0.22129566967487335,-0.9939578771591187,0.5774399042129517,0.525479257106781,0.3049013912677765,-0.10729152709245682,0.9433151483535767,-0.9314428567886353,0.5273632407188416,-0.4264712631702423,-0.9984429478645325,0.5296756029129028,0.8604294061660767,-0.8895052075386047,0.9556970596313477,0.6629186868667603,0.42956963181495667,0.9736858010292053,0.6555483937263489,0.12201889604330063,0.7442770004272461,0.5037952661514282,0.9525359272956848,-0.6507164239883423,-0.9316279292106628,0.9791510105133057,-0.9972584843635559,0.9613031148910522,0.7501779794692993,-0.3806658685207367,0.6429786682128906,0.9557769298553467,-0.9428839683532715,-0.9948079586029053,0.785298764705658,0.9657301306724548,0.707301676273346,0.3687230050563812,0.8128011226654053,0.9659481644630432,0.9730121493339539,0.31900617480278015,-0.30290520191192627,0.9790953397750854,0.9357923269271851,-0.5550313591957092,-0.005466493312269449,0.9867776036262512,0.8249565958976746,0.566429615020752,0.1000526174902916,-0.9464486837387085,-0.25471997261047363,0.6522327661514282,0.1415255218744278,0.9884140491485596,0.9860583543777466,0.6949270367622375,0.9901810884475708,0.9791202545166016,-0.2359553426504135,-0.9820711612701416,0.6506689190864563,0.9895943999290466,-0.29178157448768616,0.9714024662971497,0.9951602220535278,0.18783769011497498,-0.9460937976837158,0.47801902890205383,-0.2489192932844162,0.9437097907066345,0.11866245418787003,0.9941242933273315,-0.38088178634643555,0.9564487934112549,0.5542725920677185,0.42118048667907715,0.6628789901733398,0.8659590482711792,0.9937117695808411,0.9069075584411621,0.39811065793037415,-0.4134220480918884,0.9971913695335388,0.34596705436706543,0.9938657283782959,0.5891268849372864,0.9313740134239197,0.9268401861190796,0.9993564486503601,0.6227539777755737,0.8463947772979736,0.6584346294403076,0.8423126339912415,0.2978496253490448,0.8728679418563843,0.9963144659996033,0.986752450466156],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Full OV Copying Score\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"OV Copying Score\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"OV Copying Score for each head in GPT-2 Small\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('3e59929d-31e9-49b1-ad1a-9d9811d4801d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "scatter(x=full_OV_copying_score.flatten(), y=OV_copying_score.flatten(), hover_name=[f\"L{layer}H{head}\" for layer in range(12) for head in range(12)], title=\"OV Copying Score for each head in GPT-2 Small\", xaxis=\"Full OV Copying Score\", yaxis=\"OV Copying Score\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3T4KE67xw6t",
        "outputId": "0d6cb016-c826-4cb5-bbd4-d83171818bb2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token 256 - the most common pair of ASCII characters: | t|\n",
            "De-Tokenizing the example tokens: <|endoftext|>The first thing you need to figure out is *how* things are tokenized. `model.to_str_tokens` splits a string into the tokens *as a list of substrings*, and so lets you explore what the text looks like. To demonstrate this, let's use it on this paragraph.\n"
          ]
        }
      ],
      "source": [
        "print(f\"Token 256 - the most common pair of ASCII characters: |{model.to_string(256)}|\")\n",
        "# Squeeze means to remove dimensions of length 1.\n",
        "# Here, that removes the dummy batch dimension so it's a rank 1 tensor and returns a string\n",
        "# Rank 2 tensors map to a list of strings\n",
        "print(f\"De-Tokenizing the example tokens: {model.to_string(example_text_tokens.squeeze())}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zU-pVqKxw6u"
      },
      "source": [
        "## Generating Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKMqkHCvxw6u"
      },
      "source": [
        "TransformerLens also has basic text generation functionality, which can be useful for generally exploring what the model is capable of (thanks to Ansh Radhakrishnan for adding this!). This is pretty rough functionality, and where possible I recommend using more established libraries like HuggingFace for this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJgpibBPxw6u",
        "outputId": "5c681769-fe7f-4070-c3b5-2b707f5730ce",
        "colab": {
          "referenced_widgets": [
            "f16e699caef243e3bd730cd876600c4a"
          ]
        }
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f16e699caef243e3bd730cd876600c4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/50 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "'(CNN) President Barack Obama caught in embarrassing new scandal\\n\\nAmerican voters who backed Hillary Clinton gave President Barack Obama a 9.5-point lead over Republican Mitt Romney in the latest CNN/ORC International poll, his lowest level since the last CNN-ORC poll in 2006.\\n\\nRepublican voters'"
            ]
          },
          "execution_count": 344,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# NBVAL_IGNORE_OUTPUT\n",
        "model.generate(\"(CNN) President Barack Obama caught in embarrassing new scandal\\n\", max_new_tokens=50, temperature=0.7, prepend_bos=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtT8v8QUxw6v"
      },
      "source": [
        "## Hook Points\n",
        "\n",
        "The key part of TransformerLens that lets us access and edit intermediate activations are the HookPoints around every model activation. Importantly, this technique will work for *any* model architecture, not just transformers, so long as you're able to edit the model code to add in HookPoints! This is essentially a lightweight library bundled with TransformerLens that should let you take an arbitrary model and make it easier to study."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PTt6Nt4xw6v"
      },
      "source": [
        "This is implemented by having a HookPoint layer. Each transformer component has a HookPoint for every activation, which wraps around that activation. The HookPoint acts as an identity function, but has a variety of helper functions that allows us to put PyTorch hooks in to edit and access the relevant activation.\n",
        "\n",
        "There is also a `HookedRootModule` class - this is a utility class that the root module should inherit from (root module = the model we run) - it has several utility functions for using hooks well, notably `reset_hooks`, `run_with_cache` and `run_with_hooks`.\n",
        "\n",
        "The default interface is the `run_with_hooks` function on the root module, which lets us run a forwards pass on the model, and pass on a list of hooks paired with layer names to run on that pass.\n",
        "\n",
        "The syntax for a hook is `function(activation, hook)` where `activation` is the activation the hook is wrapped around, and `hook` is the `HookPoint` class the function is attached to. If the function returns a new activation or edits the activation in-place, that replaces the old one, if it returns None then the activation remains as is.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpRd3n35xw6v"
      },
      "source": [
        "### Toy Example"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cY_C7GxAxw6v"
      },
      "source": [
        "\n",
        "Here's a simple example of defining a small network with HookPoints:\n",
        "\n",
        "We define a basic network with two layers that each take a scalar input $x$, square it, and add a constant:\n",
        "$x_0=x$, $x_1=x_0^2+3$, $x_2=x_1^2-4$.\n",
        "\n",
        "We wrap the input, each layer's output, and the intermediate value of each layer (the square) in a hook point.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOsSg-4Yxw6w"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformer_lens.hook_points import HookedRootModule, HookPoint\n",
        "\n",
        "\n",
        "class SquareThenAdd(nn.Module):\n",
        "    def __init__(self, offset):\n",
        "        super().__init__()\n",
        "        self.offset = nn.Parameter(torch.tensor(offset))\n",
        "        self.hook_square = HookPoint()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The hook_square doesn't change the value, but lets us access it\n",
        "        square = self.hook_square(x * x)\n",
        "        return self.offset + square\n",
        "\n",
        "\n",
        "class TwoLayerModel(HookedRootModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layer1 = SquareThenAdd(3.0)\n",
        "        self.layer2 = SquareThenAdd(-4.0)\n",
        "        self.hook_in = HookPoint()\n",
        "        self.hook_mid = HookPoint()\n",
        "        self.hook_out = HookPoint()\n",
        "\n",
        "        # We need to call the setup function of HookedRootModule to build an\n",
        "        # internal dictionary of modules and hooks, and to give each hook a name\n",
        "        super().setup()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # We wrap the input and each layer's output in a hook - they leave the\n",
        "        # value unchanged (unless there's a hook added to explicitly change it),\n",
        "        # but allow us to access it.\n",
        "        x_in = self.hook_in(x)\n",
        "        x_mid = self.hook_mid(self.layer1(x_in))\n",
        "        x_out = self.hook_out(self.layer2(x_mid))\n",
        "        return x_out\n",
        "\n",
        "\n",
        "model = TwoLayerModel()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbLpxhmVxw6w"
      },
      "source": [
        "\n",
        "We can add a cache, to save the activation at each hook point\n",
        "\n",
        "(There's a custom `run_with_cache` function on the root module as a convenience, which is a wrapper around model.forward that return model_out, cache_object - we could also manually add hooks with `run_with_hooks` that store activations in a global caching dictionary. This is often useful if we only want to store, eg, subsets or functions of some activations.)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVi6iV9jxw6w",
        "outputId": "028404da-b4cc-4b6b-f31a-7ca9901fbe55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model output: 780.0\n",
            "Value cached at hook hook_in 5.0\n",
            "Value cached at hook layer1.hook_square 25.0\n",
            "Value cached at hook hook_mid 28.0\n",
            "Value cached at hook layer2.hook_square 784.0\n",
            "Value cached at hook hook_out 780.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "out, cache = model.run_with_cache(torch.tensor(5.0))\n",
        "print(\"Model output:\", out.item())\n",
        "for key in cache:\n",
        "    print(f\"Value cached at hook {key}\", cache[key].item())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c83YMmzuxw6w"
      },
      "source": [
        "\n",
        "We can also use hooks to intervene on activations - eg, we can set the intermediate value in layer 2 to zero to change the output to -5\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1TzuYhAwxw6x",
        "outputId": "7b23a4f7-d09e-4ea7-9a2d-8ccffe1897bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "layer2.hook_square\n",
            "Output after intervening on layer2.hook_scaled -4.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "def set_to_zero_hook(tensor, hook):\n",
        "    print(hook.name)\n",
        "    return torch.tensor(0.0)\n",
        "\n",
        "\n",
        "print(\n",
        "    \"Output after intervening on layer2.hook_scaled\",\n",
        "    model.run_with_hooks(\n",
        "        torch.tensor(5.0), fwd_hooks=[(\"layer2.hook_square\", set_to_zero_hook)]\n",
        "    ).item(),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXawteGQxw6x"
      },
      "source": [
        "## Loading Pre-Trained Checkpoints\n",
        "\n",
        "There are a lot of interesting questions combining mechanistic interpretability and training dynamics - analysing model capabilities and the underlying circuits that make them possible, and how these change as we train the model.\n",
        "\n",
        "TransformerLens supports these by having several model families with checkpoints throughout training. `HookedTransformer.from_pretrained` can load a checkpoint of a model with the `checkpoint_index` (the label 0 to `num_checkpoints-1`) or `checkpoint_value` (the step or token number, depending on how the checkpoints were labelled)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Un_OBqIWxw6x"
      },
      "source": [
        "\n",
        "Available models:\n",
        "* All of my interpretability-friendly models have checkpoints available, including:\n",
        "    * The toy models - `attn-only`, `solu`, `gelu` 1L to 4L\n",
        "        * These have ~200 checkpoints, taken on a piecewise linear schedule (more checkpoints near the start of training), up to 22B tokens. Labelled by number of tokens seen.\n",
        "    * The SoLU models trained on 80% Web Text and 20% Python Code (`solu-6l` to `solu-12l`)\n",
        "        * Same checkpoint schedule as the toy models, this time up to 30B tokens\n",
        "    * The SoLU models trained on the pile (`solu-1l-pile` to `solu-12l-pile`)\n",
        "        * These have ~100 checkpoints, taken on a linear schedule, up to 15B tokens. Labelled by number of steps.\n",
        "        * The 12L training crashed around 11B tokens, so is truncated.\n",
        "* The Stanford Centre for Research of Foundation Models trained 5 GPT-2 Small sized and 5 GPT-2 Medium sized models (`stanford-gpt2-small-a` to `e` and `stanford-gpt2-medium-a` to `e`)\n",
        "    * 600 checkpoints, taken on a piecewise linear schedule, labelled by the number of steps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4Jq1N_cxw6y"
      },
      "source": [
        "The checkpoint structure and labels is somewhat messy and ad-hoc, so I mostly recommend using the `checkpoint_index` syntax (where you can just count from 0 to the number of checkpoints) rather than `checkpoint_value` syntax (where you need to know the checkpoint schedule, and whether it was labelled with the number of tokens or steps). The helper function `get_checkpoint_labels` tells you the checkpoint schedule for a given model - ie what point was each checkpoint taken at, and what type of label was used.\n",
        "\n",
        "Here are graphs of the schedules for several checkpointed models: (note that the first 3 use a log scale, latter 2 use a linear scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-umXUh8Pxw6y",
        "outputId": "9043dcd0-1dec-4f09-8126-8d541f258784"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"9670aaf8-c497-4268-aefd-f91bf035117f\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9670aaf8-c497-4268-aefd-f91bf035117f\")) {                    Plotly.newPlot(                        \"9670aaf8-c497-4268-aefd-f91bf035117f\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[262144,2621440,4718592,7077888,9175040,11272192,13631488,15728640,18087936,20185088,22282240,33292288,44302336,55312384,66322432,77332480,88342528,99352576,110362624,121372672,132382720,143392768,154402816,165412864,176422912,187432960,198443008,209453056,220463104,264503296,308281344,352321536,396361728,440401920,484442112,528482304,572522496,616300544,660340736,704380928,748421120,792461312,836501504,880279552,924319744,968359936,1012400128,1056440320,1100480512,1144520704,1188298752,1232338944,1276379136,1320419328,1364459520,1408499712,1452277760,1496317952,1540358144,1584398336,1628438528,1672478720,1716518912,1760296960,1804337152,1848377344,1892417536,1936457728,1980497920,2024275968,2068316160,2112356352,2156396544,2200436736,2420375552,2640314368,2860515328,3080454144,3300392960,3520331776,3740270592,3960471552,4180410368,4400349184,4620288000,4840488960,5060427776,5280366592,5500305408,5720506368,5940445184,6160384000,6380322816,6600523776,6820462592,7040401408,7260340224,7480279040,7700480000,7920418816,8140357632,8360296448,8580497408,8800436224,9020375040,9240313856,9460514816,9680453632,9900392448,10120331264,10340270080,10560471040,10780409856,11000348672,11220287488,11440488448,11660427264,11880366080,12100304896,12320505856,12540444672,12760383488,12980322304,13200523264,13420462080,13640400896,13860339712,14080278528,14300479488,14520418304,14740357120,14960295936,15180496896,15400435712,15620374528,15840313344,16060514304,16280453120,16500391936,16720330752,16940269568,17160470528,17380409344,17600348160,17820286976,18040487936,18260426752,18480365568,18700304384,18920505344,19140444160,19360382976,19580321792,19800522752,20020461568,20240400384,20460339200,20680278016,20900478976,21120417792,21340356608,21560295424,21780496384],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for attn-only-2l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9670aaf8-c497-4268-aefd-f91bf035117f');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"87db2943-c842-478c-8c64-5289a60ba868\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"87db2943-c842-478c-8c64-5289a60ba868\")) {                    Plotly.newPlot(                        \"87db2943-c842-478c-8c64-5289a60ba868\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162],\"xaxis\":\"x\",\"y\":[196608,3342336,6291456,9240576,12386304,15335424,18284544,21233664,24379392,27328512,30277632,45219840,60358656,75300864,90243072,105381888,120324096,135266304,150208512,165347328,180289536,195231744,210370560,225312768,240254976,255197184,270336000,285278208,300220416,360382464,420347904,480313344,540278784,600244224,660209664,720371712,780337152,840302592,900268032,960233472,1020198912,1080360960,1140326400,1200291840,1260257280,1320222720,1380384768,1440350208,1500315648,1560281088,1620246528,1680211968,1740374016,1800339456,1860304896,1920270336,1980235776,2040201216,2100363264,2160328704,2220294144,2280259584,2340225024,2400387072,2460352512,2520317952,2580283392,2640248832,2700214272,2760376320,2820341760,2880307200,2940272640,3000238080,3300261888,3600285696,3900309504,4200333312,4500357120,4800380928,5100208128,5400231936,5700255744,6000279552,6300303360,6600327168,6900350976,7200374784,7500201984,7800225792,8100249600,8400273408,8700297216,9000321024,9300344832,9600368640,9900392448,10200219648,10500243456,10800267264,11100291072,11400314880,11700338688,12000362496,12300386304,12600213504,12900237312,13200261120,13500284928,13800308736,14100332544,14400356352,14700380160,15000207360,15300231168,15600254976,15900278784,16200302592,16500326400,16800350208,17100374016,17400201216,17700225024,18000248832,18300272640,18600296448,18900320256,19200344064,19500367872,19800391680,20100218880,20400242688,20700266496,21000290304,21300314112,21600337920,21900361728,22200385536,22500212736,22800236544,23100260352,23400284160,23700307968,24000331776,24300355584,24600379392,24900206592,25200230400,25500254208,25800278016,26100301824,26400325632,26700349440,27000373248,27300200448,27600224256,27900248064,28200271872,28500295680,28800319488,29100343296,29400367104,29700390912],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-12l (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('87db2943-c842-478c-8c64-5289a60ba868');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"a5b83399-2637-48e9-980b-098ce30dc2fd\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a5b83399-2637-48e9-980b-098ce30dc2fd\")) {                    Plotly.newPlot(                        \"a5b83399-2637-48e9-980b-098ce30dc2fd\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518,519,520,521,522,523,524,525,526,527,528,529,530,531,532,533,534,535,536,537,538,539,540,541,542,543,544,545,546,547,548,549,550,551,552,553,554,555,556,557,558,559,560,561,562,563,564,565,566,567,568,569,570,571,572,573,574,575,576,577,578,579,580,581,582,583,584,585,586,587,588,589,590,591,592,593,594,595,596,597,598,599,600,601,602,603,604,605,606,607,608],\"xaxis\":\"x\",\"y\":[0,10,20,30,40,50,60,70,80,90,100,150,200,250,300,350,400,450,500,550,600,650,700,750,800,850,900,950,1000,1050,1100,1150,1200,1250,1300,1350,1400,1450,1500,1550,1600,1650,1700,1750,1800,1850,1900,1950,2000,2100,2200,2300,2400,2500,2600,2700,2800,2900,3000,3100,3200,3300,3400,3500,3600,3700,3800,3900,4000,4100,4200,4300,4400,4500,4600,4700,4800,4900,5000,5100,5200,5300,5400,5500,5600,5700,5800,5900,6000,6100,6200,6300,6400,6500,6600,6700,6800,6900,7000,7100,7200,7300,7400,7500,7600,7700,7800,7900,8000,8100,8200,8300,8400,8500,8600,8700,8800,8900,9000,9100,9200,9300,9400,9500,9600,9700,9800,9900,10000,10100,10200,10300,10400,10500,10600,10700,10800,10900,11000,11100,11200,11300,11400,11500,11600,11700,11800,11900,12000,12100,12200,12300,12400,12500,12600,12700,12800,12900,13000,13100,13200,13300,13400,13500,13600,13700,13800,13900,14000,14100,14200,14300,14400,14500,14600,14700,14800,14900,15000,15100,15200,15300,15400,15500,15600,15700,15800,15900,16000,16100,16200,16300,16400,16500,16600,16700,16800,16900,17000,17100,17200,17300,17400,17500,17600,17700,17800,17900,18000,18100,18200,18300,18400,18500,18600,18700,18800,18900,19000,19100,19200,19300,19400,19500,19600,19700,19800,19900,20000,21000,22000,23000,24000,25000,26000,27000,28000,29000,30000,31000,32000,33000,34000,35000,36000,37000,38000,39000,40000,41000,42000,43000,44000,45000,46000,47000,48000,49000,50000,51000,52000,53000,54000,55000,56000,57000,58000,59000,60000,61000,62000,63000,64000,65000,66000,67000,68000,69000,70000,71000,72000,73000,74000,75000,76000,77000,78000,79000,80000,81000,82000,83000,84000,85000,86000,87000,88000,89000,90000,91000,92000,93000,94000,95000,96000,97000,98000,99000,100000,101000,102000,103000,104000,105000,106000,107000,108000,109000,110000,111000,112000,113000,114000,115000,116000,117000,118000,119000,120000,121000,122000,123000,124000,125000,126000,127000,128000,129000,130000,131000,132000,133000,134000,135000,136000,137000,138000,139000,140000,141000,142000,143000,144000,145000,146000,147000,148000,149000,150000,151000,152000,153000,154000,155000,156000,157000,158000,159000,160000,161000,162000,163000,164000,165000,166000,167000,168000,169000,170000,171000,172000,173000,174000,175000,176000,177000,178000,179000,180000,181000,182000,183000,184000,185000,186000,187000,188000,189000,190000,191000,192000,193000,194000,195000,196000,197000,198000,199000,200000,201000,202000,203000,204000,205000,206000,207000,208000,209000,210000,211000,212000,213000,214000,215000,216000,217000,218000,219000,220000,221000,222000,223000,224000,225000,226000,227000,228000,229000,230000,231000,232000,233000,234000,235000,236000,237000,238000,239000,240000,241000,242000,243000,244000,245000,246000,247000,248000,249000,250000,251000,252000,253000,254000,255000,256000,257000,258000,259000,260000,261000,262000,263000,264000,265000,266000,267000,268000,269000,270000,271000,272000,273000,274000,275000,276000,277000,278000,279000,280000,281000,282000,283000,284000,285000,286000,287000,288000,289000,290000,291000,292000,293000,294000,295000,296000,297000,298000,299000,300000,301000,302000,303000,304000,305000,306000,307000,308000,309000,310000,311000,312000,313000,314000,315000,316000,317000,318000,319000,320000,321000,322000,323000,324000,325000,326000,327000,328000,329000,330000,331000,332000,333000,334000,335000,336000,337000,338000,339000,340000,341000,342000,343000,344000,345000,346000,347000,348000,349000,350000,351000,352000,353000,354000,355000,356000,357000,358000,359000,360000,361000,362000,363000,364000,365000,366000,367000,368000,369000,370000,371000,372000,373000,374000,375000,376000,377000,378000,379000,380000,381000,382000,383000,384000,385000,386000,387000,388000,389000,390000,391000,392000,393000,394000,395000,396000,397000,398000,399000,400000],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for stanford-gpt2-small-a (Log scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a5b83399-2637-48e9-980b-098ce30dc2fd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"4c28ffe1-8565-4e92-babd-d57cc8bc847d\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"4c28ffe1-8565-4e92-babd-d57cc8bc847d\")) {                    Plotly.newPlot(                        \"4c28ffe1-8565-4e92-babd-d57cc8bc847d\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49],\"xaxis\":\"x\",\"y\":[832,1664,2496,3328,4160,4992,5824,6656,7488,8320,9152,9984,10816,11648,12480,13312,14144,14976,15808,16640,17472,18304,19136,19968,20800,21632,22464,23296,24128,24960,25792,26624,27456,28288,29120,29952,30784,31616,32448,33280,34112,34944,35776,36608,37440,38272,39104,39936,40768,41600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-1l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('4c28ffe1-8565-4e92-babd-d57cc8bc847d');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"d92c9f04-9700-4de1-9237-9cba28fcdafb\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d92c9f04-9700-4de1-9237-9cba28fcdafb\")) {                    Plotly.newPlot(                        \"d92c9f04-9700-4de1-9237-9cba28fcdafb\",                        [{\"hovertemplate\":\"variable=0\\u003cbr\\u003eindex=%{x}\\u003cbr\\u003evalue=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"0\",\"line\":{\"color\":\"#636efa\",\"dash\":\"solid\"},\"marker\":{\"symbol\":\"circle\"},\"mode\":\"lines+markers\",\"name\":\"0\",\"orientation\":\"v\",\"showlegend\":true,\"x\":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99],\"xaxis\":\"x\",\"y\":[326,652,978,1304,1630,1956,2282,2608,2934,3260,3586,3912,4238,4564,4890,5216,5542,5868,6194,6520,6846,7172,7498,7824,8150,8476,8802,9128,9454,9780,10106,10432,10758,11084,11410,11736,12062,12388,12714,13040,13366,13692,14018,14344,14670,14996,15322,15648,15974,16300,16626,16952,17278,17604,17930,18256,18582,18908,19234,19560,19886,20212,20538,20864,21190,21516,21842,22168,22494,22820,23146,23472,23798,24124,24450,24776,25102,25428,25754,26080,26406,26732,27058,27384,27710,28036,28362,28688,29014,29340,29666,29992,30318,30644,30970,31296,31622,31948,32274,32600],\"yaxis\":\"y\",\"type\":\"scatter\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"}},\"legend\":{\"title\":{\"text\":\"variable\"},\"tracegroupgap\":0},\"title\":{\"text\":\"Checkpoint Values for solu-6l-pile (Linear scale)\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d92c9f04-9700-4de1-9237-9cba28fcdafb');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformer_lens.loading_from_pretrained import get_checkpoint_labels\n",
        "for model_name in [\"attn-only-2l\", \"solu-12l\", \"stanford-gpt2-small-a\"]:\n",
        "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
        "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Log scale)\", log_y=True, markers=True)\n",
        "for model_name in [\"solu-1l-pile\", \"solu-6l-pile\"]:\n",
        "    checkpoint_labels, checkpoint_label_type = get_checkpoint_labels(model_name)\n",
        "    line(checkpoint_labels, xaxis=\"Checkpoint Index\", yaxis=f\"Checkpoint Value ({checkpoint_label_type})\", title=f\"Checkpoint Values for {model_name} (Linear scale)\", log_y=False, markers=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rjnj1MeHxw6z"
      },
      "source": [
        "### Example: Induction Head Phase Transition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JA81xcAxw6z"
      },
      "source": [
        "One of the more interesting results analysing circuit formation during training is the [induction head phase transition](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html). They find a pretty dramatic shift in models during training - there's a brief period where models go from not having induction heads to having them, which leads to the models suddenly becoming much better at in-context learning (using far back tokens to predict the next token, eg over 500 words back). This is enough of a big deal that it leads to a visible *bump* in the loss curve, where the model's rate of improvement briefly increases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHpjVhZ3xw6z"
      },
      "source": [
        "As a brief demonstration of the existence of the phase transition, let's load some checkpoints of a two layer model, and see whether they have induction heads. An easy test, as we used above, is to give the model a repeated sequence of random tokens, and to check how good its loss is on the second half. `evals.induction_loss` is a rough util that runs this test on a model.\n",
        "(Note - this is deliberately a rough, non-rigorous test for the purposes of demonstration, eg `evals.induction_loss` by default just runs it on 4 sequences of 384 tokens repeated twice. These results totally don't do the paper justice - go check it out if you want to see the full results!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzDvjpQQxw60"
      },
      "source": [
        "In the interests of time and memory, let's look at a handful of checkpoints (chosen to be around the phase change), indices `[10, 25, 35, 60, -1]`. These are roughly 22M, 200M, 500M, 1.6B and 21.8B tokens through training, respectively. (I generally recommend looking things up based on indices, rather than checkpoint value!)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K1DSr-Aixw60"
      },
      "outputs": [],
      "source": [
        "from transformer_lens import evals\n",
        "# We use the two layer model with SoLU activations, chosen fairly arbitrarily as being both small (so fast to download and keep in memory) and pretty good at the induction task.\n",
        "model_name = \"solu-2l\"\n",
        "# We can load a model from a checkpoint by specifying the checkpoint_index, -1 means the final checkpoint\n",
        "checkpoint_indices = [10, 25, 35, 60, -1]\n",
        "checkpointed_models = []\n",
        "tokens_trained_on = []\n",
        "induction_losses = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTEe893bxw60"
      },
      "source": [
        "We load the models, cache them in a list, and"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvSDcwhGxw60"
      },
      "outputs": [],
      "source": [
        "if not IN_GITHUB:\n",
        "    for index in checkpoint_indices:\n",
        "        # Load the model from the relevant checkpoint by index\n",
        "        model_for_this_checkpoint = HookedTransformer.from_pretrained(model_name, checkpoint_index=index, device=device)\n",
        "        checkpointed_models.append(model_for_this_checkpoint)\n",
        "\n",
        "        tokens_seen_for_this_checkpoint = model_for_this_checkpoint.cfg.checkpoint_value\n",
        "        tokens_trained_on.append(tokens_seen_for_this_checkpoint)\n",
        "\n",
        "        induction_loss_for_this_checkpoint = evals.induction_loss(model_for_this_checkpoint, device=device).item()\n",
        "        induction_losses.append(induction_loss_for_this_checkpoint)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0KBo1CDxw61"
      },
      "source": [
        "We can plot this, and see there's a sharp shift from ~200-500M tokens trained on (note the log scale on the x axis). Interestingly, this is notably earlier than the phase transition in the paper, I'm not sure what's up with that.\n",
        "\n",
        "(To contextualise the numbers, the tokens in the random sequence are uniformly chosen from the first 20,000 tokens (out of ~48,000 total), so random performance is at least $\\ln(20000)\\approx 10$. A naive strategy like \"randomly choose a token that's already appeared in the first half of the sequence (384 elements)\" would get $\\ln(384)\\approx 5.95$, so the model is doing pretty well here.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8QQ624xxw61",
        "outputId": "6f8e9883-1689-4ce7-9bfc-e96953dd06e0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.26.0.min.js\"></script>                <div id=\"1b82f6dc-4619-4786-ac45-c3cf11921de0\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"1b82f6dc-4619-4786-ac45-c3cf11921de0\")) {                    Plotly.newPlot(                        \"1b82f6dc-4619-4786-ac45-c3cf11921de0\",                        [],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"value\"},\"type\":\"log\"},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"index\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Induction Loss over training: solu-2l\"}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('1b82f6dc-4619-4786-ac45-c3cf11921de0');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "line(induction_losses, x=tokens_trained_on, xaxis=\"Tokens Trained On\", yaxis=\"Induction Loss\", title=\"Induction Loss over training: solu-2l\", markers=True, log_x=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "eb812820b5094695c8a581672e17220e30dd2c15d704c018326e3cc2e1a566f1"
      }
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6976b97b57b4416ab0c9329067b6afe1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6584bf80c7e84a7a9ed846cb8f1a0cb7",
              "IPY_MODEL_7754870511e54c8b9658279c887c491e",
              "IPY_MODEL_1eccf31488ae411f9b04d41211d7470a"
            ],
            "layout": "IPY_MODEL_8bcb79174ca74a028d8817f5d973471d"
          }
        },
        "6584bf80c7e84a7a9ed846cb8f1a0cb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b1e212ab56b4da69d0eecfb0960a744",
            "placeholder": "​",
            "style": "IPY_MODEL_4f1626d6d6c24ef3b71c17f21f50754a",
            "value": "config.json: 100%"
          }
        },
        "7754870511e54c8b9658279c887c491e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08bb275b3feb47cfbee470e2cb6bdf27",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9accb8b4df984689894bb5f14fba3eec",
            "value": 665
          }
        },
        "1eccf31488ae411f9b04d41211d7470a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9b40c1a69494c8294303e3106307cca",
            "placeholder": "​",
            "style": "IPY_MODEL_6be4269bc72749eebf73700a031e3967",
            "value": " 665/665 [00:00&lt;00:00, 49.4kB/s]"
          }
        },
        "8bcb79174ca74a028d8817f5d973471d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b1e212ab56b4da69d0eecfb0960a744": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f1626d6d6c24ef3b71c17f21f50754a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08bb275b3feb47cfbee470e2cb6bdf27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9accb8b4df984689894bb5f14fba3eec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9b40c1a69494c8294303e3106307cca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6be4269bc72749eebf73700a031e3967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be8432dd6d73454093c622887643a2b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b073f96034048fabfdb5a36b4edf6ad",
              "IPY_MODEL_731ef4285fc440abb434151ede21d1fa",
              "IPY_MODEL_308859b69928415db02b091860b42fb5"
            ],
            "layout": "IPY_MODEL_70bbad51773b44c1b35ef4c98054e290"
          }
        },
        "2b073f96034048fabfdb5a36b4edf6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf4277b9d44402b8f8a20a068f686e6",
            "placeholder": "​",
            "style": "IPY_MODEL_4a004b3c591e45fc9d220d86376a181b",
            "value": "model.safetensors: 100%"
          }
        },
        "731ef4285fc440abb434151ede21d1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aea234f4a73b458d8e9dfe4d8b87d48a",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c095c849a85844d28fe4b2d0811f23e5",
            "value": 548105171
          }
        },
        "308859b69928415db02b091860b42fb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6175776618ae4419bb69d61aef42b717",
            "placeholder": "​",
            "style": "IPY_MODEL_d9dbc6c8cba549cb88303a463bcd9b88",
            "value": " 548M/548M [00:02&lt;00:00, 211MB/s]"
          }
        },
        "70bbad51773b44c1b35ef4c98054e290": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbf4277b9d44402b8f8a20a068f686e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a004b3c591e45fc9d220d86376a181b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aea234f4a73b458d8e9dfe4d8b87d48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c095c849a85844d28fe4b2d0811f23e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6175776618ae4419bb69d61aef42b717": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9dbc6c8cba549cb88303a463bcd9b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20f98c63ca6d44989dee31c84a6e8e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9a2bb2eace2478387f823df86511884",
              "IPY_MODEL_d69cf458f9064c0199271aa957f55e78",
              "IPY_MODEL_aa9a23373f0a45febd4212eec3ea3a3e"
            ],
            "layout": "IPY_MODEL_66dcaea4dcdf4108bb6a77aa1f72e28b"
          }
        },
        "d9a2bb2eace2478387f823df86511884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_708b232fc6e2486eacb9becc9dbf735a",
            "placeholder": "​",
            "style": "IPY_MODEL_002fa5aef4e6476897e948acc2d3211b",
            "value": "generation_config.json: 100%"
          }
        },
        "d69cf458f9064c0199271aa957f55e78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95b9c5f69c534358b9c456ae0efbec05",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a5dcafaaf6114830ade522bcf78bffd5",
            "value": 124
          }
        },
        "aa9a23373f0a45febd4212eec3ea3a3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6fdfd16817ba4964a7f592542c281711",
            "placeholder": "​",
            "style": "IPY_MODEL_9a68fb9d16cb4b6f8cd9e9cc23f45300",
            "value": " 124/124 [00:00&lt;00:00, 8.97kB/s]"
          }
        },
        "66dcaea4dcdf4108bb6a77aa1f72e28b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "708b232fc6e2486eacb9becc9dbf735a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "002fa5aef4e6476897e948acc2d3211b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95b9c5f69c534358b9c456ae0efbec05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5dcafaaf6114830ade522bcf78bffd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6fdfd16817ba4964a7f592542c281711": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a68fb9d16cb4b6f8cd9e9cc23f45300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e702633318344d9a881f3876725e15c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69c1f16350c24877a43909c5f8146c24",
              "IPY_MODEL_f68cc18fadb640c49249cfeff7c542ae",
              "IPY_MODEL_74edbe2b983e448b9f49a78f589ca264"
            ],
            "layout": "IPY_MODEL_2cce22c56cc0468fa88ced2213a43991"
          }
        },
        "69c1f16350c24877a43909c5f8146c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97802f97ee4e40c4932a594625dcd6ea",
            "placeholder": "​",
            "style": "IPY_MODEL_89bd8138dc204604b6a64afb6253e73e",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f68cc18fadb640c49249cfeff7c542ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_40caec6ab0dd4bb19cf734e9f332160c",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0abe827706924b44a03041a0b0fbf3e1",
            "value": 26
          }
        },
        "74edbe2b983e448b9f49a78f589ca264": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_053ef18e36f04fa09090324482e1b07c",
            "placeholder": "​",
            "style": "IPY_MODEL_e3c59b8a992942f5adb293af184ec414",
            "value": " 26.0/26.0 [00:00&lt;00:00, 1.76kB/s]"
          }
        },
        "2cce22c56cc0468fa88ced2213a43991": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97802f97ee4e40c4932a594625dcd6ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89bd8138dc204604b6a64afb6253e73e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "40caec6ab0dd4bb19cf734e9f332160c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0abe827706924b44a03041a0b0fbf3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "053ef18e36f04fa09090324482e1b07c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3c59b8a992942f5adb293af184ec414": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3b03f837ceb4584a67da116b0f01878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af031d2591b6412db3021f13dc9c9ab9",
              "IPY_MODEL_f68009d4ccac4c33b31d380155b62887",
              "IPY_MODEL_8852417c1b2e4b98a0655809ea1e9bb6"
            ],
            "layout": "IPY_MODEL_cc159dd2ac944a398ebd53cba04052bf"
          }
        },
        "af031d2591b6412db3021f13dc9c9ab9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b8cad9989b224ee386b8790a56b3f45d",
            "placeholder": "​",
            "style": "IPY_MODEL_698bf9671c36498caccbd9149922c9af",
            "value": "vocab.json: 100%"
          }
        },
        "f68009d4ccac4c33b31d380155b62887": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8fcafdd50d94769a0c4321334456a64",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d232bfeaec944ce08c4271dacf4e9262",
            "value": 1042301
          }
        },
        "8852417c1b2e4b98a0655809ea1e9bb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1185f61651ac4545bcb92df59961bc5e",
            "placeholder": "​",
            "style": "IPY_MODEL_7f8532ef15774fa19ca6a1ce96f94f9c",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 40.9MB/s]"
          }
        },
        "cc159dd2ac944a398ebd53cba04052bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8cad9989b224ee386b8790a56b3f45d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "698bf9671c36498caccbd9149922c9af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d8fcafdd50d94769a0c4321334456a64": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d232bfeaec944ce08c4271dacf4e9262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1185f61651ac4545bcb92df59961bc5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8532ef15774fa19ca6a1ce96f94f9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5066357d505841408fb8f0a9ea703757": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5909654f81dc4b3ca797d952a5283080",
              "IPY_MODEL_f61479a84e30431ebaf9e348c132aeaf",
              "IPY_MODEL_478b30389cd746fdb6df48cc06df8667"
            ],
            "layout": "IPY_MODEL_d56fcb45a6294fafa9f2d87a1b04c872"
          }
        },
        "5909654f81dc4b3ca797d952a5283080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8702c826c67456d949666717da4d5ec",
            "placeholder": "​",
            "style": "IPY_MODEL_032e5471df0f476fade43c7853f30e62",
            "value": "merges.txt: 100%"
          }
        },
        "f61479a84e30431ebaf9e348c132aeaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_135dfd356acd444b88c66e2f4ac8768a",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1641ba5633064faebf0967a89916a9e0",
            "value": 456318
          }
        },
        "478b30389cd746fdb6df48cc06df8667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478d2c51935a4efb95681c7359ad9a88",
            "placeholder": "​",
            "style": "IPY_MODEL_c1f506f6adf74272a852ced0dc372013",
            "value": " 456k/456k [00:00&lt;00:00, 2.13MB/s]"
          }
        },
        "d56fcb45a6294fafa9f2d87a1b04c872": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8702c826c67456d949666717da4d5ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "032e5471df0f476fade43c7853f30e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "135dfd356acd444b88c66e2f4ac8768a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1641ba5633064faebf0967a89916a9e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "478d2c51935a4efb95681c7359ad9a88": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1f506f6adf74272a852ced0dc372013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2470eb850edd4d1f8daf587fec6cc832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7485e525aabd4ee597067e4bb187600b",
              "IPY_MODEL_a147b2bc69924582ab21a772d142c11e",
              "IPY_MODEL_edbb04213d4048569938e3631b679103"
            ],
            "layout": "IPY_MODEL_cc32380590aa4c41aeba3db47a5fa11b"
          }
        },
        "7485e525aabd4ee597067e4bb187600b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d4628f4262e04bccbe8a666044e9cf6b",
            "placeholder": "​",
            "style": "IPY_MODEL_28a5b81ec1104cddb8c962e6dddc2ac4",
            "value": "tokenizer.json: 100%"
          }
        },
        "a147b2bc69924582ab21a772d142c11e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_340a4c41ce4c4ebc821435ae964d16f9",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_401c5457171d4de2b6739ad68eaaaeb4",
            "value": 1355256
          }
        },
        "edbb04213d4048569938e3631b679103": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48632d4bf6434681ba493ccec4faad70",
            "placeholder": "​",
            "style": "IPY_MODEL_5c9253da246f4f229982620d55208094",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 1.59MB/s]"
          }
        },
        "cc32380590aa4c41aeba3db47a5fa11b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d4628f4262e04bccbe8a666044e9cf6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28a5b81ec1104cddb8c962e6dddc2ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "340a4c41ce4c4ebc821435ae964d16f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "401c5457171d4de2b6739ad68eaaaeb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "48632d4bf6434681ba493ccec4faad70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9253da246f4f229982620d55208094": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac7606cb16bf44559715f401eeaf7c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36f4233a7b9148aaa19bdde280fa36de",
              "IPY_MODEL_44f2bb66fd344523b70bf9763af47b9c",
              "IPY_MODEL_bfa4c8b8bc39427399873df843c5f252"
            ],
            "layout": "IPY_MODEL_eab9ede2e2a646e5aadc70d98b57b978"
          }
        },
        "36f4233a7b9148aaa19bdde280fa36de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_984890a40a62468d850aeec8a1f96b94",
            "placeholder": "​",
            "style": "IPY_MODEL_f0be004de1504e529cdb3fe30013bab8",
            "value": "100%"
          }
        },
        "44f2bb66fd344523b70bf9763af47b9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6007cab1c704b2a805a9e8e7214187e",
            "max": 12,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_945b70c9bbee4fc0a2c3afc914b3e297",
            "value": 12
          }
        },
        "bfa4c8b8bc39427399873df843c5f252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12e3bd8f408c4d98bae34f54da9a7c0a",
            "placeholder": "​",
            "style": "IPY_MODEL_7487cacba3524818b479bac823036791",
            "value": " 12/12 [00:06&lt;00:00,  1.74it/s]"
          }
        },
        "eab9ede2e2a646e5aadc70d98b57b978": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984890a40a62468d850aeec8a1f96b94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0be004de1504e529cdb3fe30013bab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a6007cab1c704b2a805a9e8e7214187e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "945b70c9bbee4fc0a2c3afc914b3e297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "12e3bd8f408c4d98bae34f54da9a7c0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7487cacba3524818b479bac823036791": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}